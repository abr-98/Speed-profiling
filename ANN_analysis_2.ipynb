{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "WARNING:tensorflow:From /home/abhijit/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/abhijit/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/160\n",
      "4263/4263 [==============================] - 2s 522us/step - loss: 0.4578 - acc: 0.7843\n",
      "Epoch 2/160\n",
      " 500/4263 [==>...........................] - ETA: 1s - loss: 0.4427 - acc: 0.7920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4263/4263 [==============================] - 1s 246us/step - loss: 0.4009 - acc: 0.8106\n",
      "Epoch 3/160\n",
      "4263/4263 [==============================] - 1s 229us/step - loss: 0.3867 - acc: 0.8138\n",
      "Epoch 4/160\n",
      "4263/4263 [==============================] - 1s 228us/step - loss: 0.3801 - acc: 0.8157\n",
      "Epoch 5/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3784 - acc: 0.8208\n",
      "Epoch 6/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3778 - acc: 0.8191\n",
      "Epoch 7/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3716 - acc: 0.8217\n",
      "Epoch 8/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3693 - acc: 0.8234\n",
      "Epoch 9/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3685 - acc: 0.8251\n",
      "Epoch 10/160\n",
      "4263/4263 [==============================] - 1s 226us/step - loss: 0.3670 - acc: 0.8239\n",
      "Epoch 11/160\n",
      "4263/4263 [==============================] - 1s 228us/step - loss: 0.3688 - acc: 0.8233\n",
      "Epoch 12/160\n",
      "4263/4263 [==============================] - 1s 260us/step - loss: 0.3676 - acc: 0.8252\n",
      "Epoch 13/160\n",
      "4263/4263 [==============================] - 1s 217us/step - loss: 0.3642 - acc: 0.8264\n",
      "Epoch 14/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.3617 - acc: 0.8291\n",
      "Epoch 15/160\n",
      "4263/4263 [==============================] - 1s 316us/step - loss: 0.3661 - acc: 0.8259\n",
      "Epoch 16/160\n",
      "4263/4263 [==============================] - 2s 355us/step - loss: 0.3602 - acc: 0.8271\n",
      "Epoch 17/160\n",
      "4263/4263 [==============================] - 2s 382us/step - loss: 0.3573 - acc: 0.8319\n",
      "Epoch 18/160\n",
      "4263/4263 [==============================] - 1s 331us/step - loss: 0.3563 - acc: 0.8300\n",
      "Epoch 19/160\n",
      "4263/4263 [==============================] - 1s 225us/step - loss: 0.3541 - acc: 0.8314\n",
      "Epoch 20/160\n",
      "4263/4263 [==============================] - 1s 264us/step - loss: 0.3530 - acc: 0.8329\n",
      "Epoch 21/160\n",
      "4263/4263 [==============================] - 1s 340us/step - loss: 0.3550 - acc: 0.8340\n",
      "Epoch 22/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3556 - acc: 0.8310\n",
      "Epoch 23/160\n",
      "4263/4263 [==============================] - 1s 270us/step - loss: 0.3523 - acc: 0.8314\n",
      "Epoch 24/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3545 - acc: 0.8337\n",
      "Epoch 25/160\n",
      "4263/4263 [==============================] - 1s 235us/step - loss: 0.3521 - acc: 0.8347\n",
      "Epoch 26/160\n",
      " 300/4263 [=>............................] - ETA: 1s - loss: 0.3137 - acc: 0.8617"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2eed42877b9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping_monitor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df=pd.read_csv('6mar.csv')\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "    #print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    if k_1_i==1:\n",
    "        prediction_l.append('Fast')\n",
    "    if k_2_i==1:\n",
    "        prediction_l.append('Normal')\n",
    "    if k_3_i==1:\n",
    "        prediction_l.append('Slow')\n",
    "    if k_4_i==1:\n",
    "        prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "    if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "    j=j+1\n",
    "    #print(i)\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/160\n",
      "4263/4263 [==============================] - 2s 459us/step - loss: 0.4419 - acc: 0.7977\n",
      "Epoch 2/160\n",
      "4263/4263 [==============================] - 2s 375us/step - loss: 0.3963 - acc: 0.8103\n",
      "Epoch 3/160\n",
      "4263/4263 [==============================] - 1s 327us/step - loss: 0.3832 - acc: 0.8164\n",
      "Epoch 4/160\n",
      "4263/4263 [==============================] - 1s 295us/step - loss: 0.3796 - acc: 0.8171\n",
      "Epoch 5/160\n",
      "4263/4263 [==============================] - 1s 347us/step - loss: 0.3762 - acc: 0.8195\n",
      "Epoch 6/160\n",
      "4263/4263 [==============================] - 1s 295us/step - loss: 0.3744 - acc: 0.8202\n",
      "Epoch 7/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3737 - acc: 0.8190\n",
      "Epoch 8/160\n",
      "4263/4263 [==============================] - 1s 251us/step - loss: 0.3726 - acc: 0.8189\n",
      "Epoch 9/160\n",
      "4263/4263 [==============================] - 1s 198us/step - loss: 0.3680 - acc: 0.8252\n",
      "Epoch 10/160\n",
      "4263/4263 [==============================] - 1s 203us/step - loss: 0.3696 - acc: 0.8262\n",
      "Epoch 11/160\n",
      "4263/4263 [==============================] - 1s 203us/step - loss: 0.3672 - acc: 0.8259\n",
      "Epoch 12/160\n",
      "4263/4263 [==============================] - 1s 190us/step - loss: 0.3672 - acc: 0.8240\n",
      "Epoch 13/160\n",
      "4263/4263 [==============================] - 1s 212us/step - loss: 0.3665 - acc: 0.8254\n",
      "Epoch 14/160\n",
      "4263/4263 [==============================] - 1s 312us/step - loss: 0.3595 - acc: 0.8302\n",
      "Epoch 15/160\n",
      "4263/4263 [==============================] - 1s 347us/step - loss: 0.3576 - acc: 0.8325\n",
      "Epoch 16/160\n",
      "4263/4263 [==============================] - 2s 354us/step - loss: 0.3588 - acc: 0.8303\n",
      "Epoch 17/160\n",
      "4263/4263 [==============================] - 2s 353us/step - loss: 0.3580 - acc: 0.8345\n",
      "Epoch 18/160\n",
      "4263/4263 [==============================] - 1s 248us/step - loss: 0.3597 - acc: 0.8300\n",
      "Epoch 19/160\n",
      "4263/4263 [==============================] - 1s 302us/step - loss: 0.3554 - acc: 0.8332\n",
      "Epoch 20/160\n",
      "4263/4263 [==============================] - 1s 205us/step - loss: 0.3553 - acc: 0.8286\n",
      "Epoch 21/160\n",
      "4263/4263 [==============================] - 1s 207us/step - loss: 0.3529 - acc: 0.8314\n",
      "Epoch 22/160\n",
      "4263/4263 [==============================] - 1s 205us/step - loss: 0.3553 - acc: 0.8323\n",
      "Epoch 23/160\n",
      "4263/4263 [==============================] - 1s 188us/step - loss: 0.3566 - acc: 0.8295\n",
      "Epoch 24/160\n",
      "4263/4263 [==============================] - 1s 191us/step - loss: 0.3535 - acc: 0.8321\n",
      "Epoch 25/160\n",
      "4263/4263 [==============================] - 1s 260us/step - loss: 0.3515 - acc: 0.8343\n",
      "Epoch 26/160\n",
      "4263/4263 [==============================] - 1s 186us/step - loss: 0.3502 - acc: 0.8351\n",
      "Epoch 27/160\n",
      "4263/4263 [==============================] - 1s 195us/step - loss: 0.3493 - acc: 0.8342\n",
      "Epoch 28/160\n",
      "4263/4263 [==============================] - 1s 190us/step - loss: 0.3536 - acc: 0.8301\n",
      "Epoch 29/160\n",
      "4263/4263 [==============================] - 1s 297us/step - loss: 0.3484 - acc: 0.8346\n",
      "Epoch 30/160\n",
      "4263/4263 [==============================] - 1s 200us/step - loss: 0.3496 - acc: 0.8344\n",
      "Epoch 31/160\n",
      "4263/4263 [==============================] - 1s 185us/step - loss: 0.3521 - acc: 0.8349\n",
      "Epoch 32/160\n",
      "4263/4263 [==============================] - 1s 185us/step - loss: 0.3491 - acc: 0.8349\n",
      "Epoch 33/160\n",
      "4263/4263 [==============================] - 1s 232us/step - loss: 0.3501 - acc: 0.8332\n",
      "Epoch 34/160\n",
      "4263/4263 [==============================] - 1s 259us/step - loss: 0.3486 - acc: 0.8357\n",
      "Epoch 35/160\n",
      "4263/4263 [==============================] - 1s 203us/step - loss: 0.3500 - acc: 0.8356\n",
      "Epoch 36/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.3467 - acc: 0.8370\n",
      "Epoch 37/160\n",
      "4263/4263 [==============================] - 1s 204us/step - loss: 0.3531 - acc: 0.8321\n",
      "Epoch 38/160\n",
      "4263/4263 [==============================] - 1s 208us/step - loss: 0.3465 - acc: 0.8364\n",
      "Epoch 39/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3444 - acc: 0.8362\n",
      "Epoch 40/160\n",
      "4263/4263 [==============================] - 1s 327us/step - loss: 0.3435 - acc: 0.8357\n",
      "Epoch 41/160\n",
      "4263/4263 [==============================] - 1s 230us/step - loss: 0.3482 - acc: 0.8357\n",
      "Epoch 42/160\n",
      "4263/4263 [==============================] - 1s 186us/step - loss: 0.3481 - acc: 0.8351\n",
      "Epoch 43/160\n",
      "4263/4263 [==============================] - 1s 185us/step - loss: 0.3469 - acc: 0.8350\n",
      "Epoch 44/160\n",
      "4263/4263 [==============================] - 1s 183us/step - loss: 0.3485 - acc: 0.8354\n",
      "Epoch 45/160\n",
      "4263/4263 [==============================] - 1s 293us/step - loss: 0.3465 - acc: 0.8349\n",
      "Epoch 46/160\n",
      "4263/4263 [==============================] - 1s 247us/step - loss: 0.3465 - acc: 0.8370\n",
      "Epoch 47/160\n",
      "4263/4263 [==============================] - 1s 275us/step - loss: 0.3456 - acc: 0.8334\n",
      "Epoch 48/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3441 - acc: 0.8363\n",
      "Epoch 49/160\n",
      "4263/4263 [==============================] - 1s 238us/step - loss: 0.3429 - acc: 0.8377\n",
      "Epoch 50/160\n",
      "4263/4263 [==============================] - 1s 191us/step - loss: 0.3456 - acc: 0.8362\n",
      "Epoch 51/160\n",
      "4263/4263 [==============================] - 1s 207us/step - loss: 0.3399 - acc: 0.8367\n",
      "Epoch 52/160\n",
      "4263/4263 [==============================] - 1s 231us/step - loss: 0.3432 - acc: 0.8384\n",
      "Epoch 53/160\n",
      "4263/4263 [==============================] - 1s 244us/step - loss: 0.3425 - acc: 0.8360\n",
      "Epoch 54/160\n",
      "4263/4263 [==============================] - 1s 270us/step - loss: 0.3429 - acc: 0.8378\n",
      "Epoch 55/160\n",
      "4263/4263 [==============================] - 1s 211us/step - loss: 0.3411 - acc: 0.8372\n",
      "Epoch 56/160\n",
      "4263/4263 [==============================] - 1s 193us/step - loss: 0.3425 - acc: 0.8416\n",
      "Epoch 57/160\n",
      "4263/4263 [==============================] - 1s 264us/step - loss: 0.3423 - acc: 0.8397\n",
      "Epoch 58/160\n",
      "4263/4263 [==============================] - 1s 255us/step - loss: 0.3423 - acc: 0.8380\n",
      "Epoch 59/160\n",
      "4263/4263 [==============================] - 1s 262us/step - loss: 0.3399 - acc: 0.8392\n",
      "Epoch 60/160\n",
      "4263/4263 [==============================] - 1s 247us/step - loss: 0.3406 - acc: 0.8399\n",
      "Epoch 61/160\n",
      "4263/4263 [==============================] - 1s 253us/step - loss: 0.3404 - acc: 0.8405\n",
      "Epoch 62/160\n",
      "4263/4263 [==============================] - 1s 258us/step - loss: 0.3388 - acc: 0.8412\n",
      "Epoch 63/160\n",
      "4263/4263 [==============================] - 1s 256us/step - loss: 0.3445 - acc: 0.8379\n",
      "Epoch 64/160\n",
      "4263/4263 [==============================] - 1s 249us/step - loss: 0.3414 - acc: 0.8396\n",
      "Epoch 65/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3410 - acc: 0.8396\n",
      "Epoch 66/160\n",
      "4263/4263 [==============================] - 1s 248us/step - loss: 0.3408 - acc: 0.8403\n",
      "Epoch 67/160\n",
      "4263/4263 [==============================] - 1s 189us/step - loss: 0.3357 - acc: 0.8420\n",
      "Epoch 68/160\n",
      "4263/4263 [==============================] - 1s 186us/step - loss: 0.3384 - acc: 0.8411\n",
      "Epoch 69/160\n",
      "4263/4263 [==============================] - 1s 185us/step - loss: 0.3407 - acc: 0.8405\n",
      "Epoch 70/160\n",
      "4263/4263 [==============================] - 1s 184us/step - loss: 0.3371 - acc: 0.8424\n",
      "Epoch 71/160\n",
      "4263/4263 [==============================] - 1s 278us/step - loss: 0.3360 - acc: 0.8448\n",
      "Epoch 72/160\n",
      "4263/4263 [==============================] - 1s 298us/step - loss: 0.3374 - acc: 0.8403\n",
      "Epoch 73/160\n",
      "4263/4263 [==============================] - 1s 302us/step - loss: 0.3415 - acc: 0.8404\n",
      "Epoch 74/160\n",
      "4263/4263 [==============================] - 1s 303us/step - loss: 0.3374 - acc: 0.8428\n",
      "Epoch 75/160\n",
      "4263/4263 [==============================] - 1s 338us/step - loss: 0.3358 - acc: 0.8418\n",
      "Epoch 76/160\n",
      "4263/4263 [==============================] - 1s 334us/step - loss: 0.3363 - acc: 0.8437\n",
      "Epoch 77/160\n",
      "4263/4263 [==============================] - 1s 256us/step - loss: 0.3376 - acc: 0.8413\n",
      "Epoch 78/160\n",
      "4263/4263 [==============================] - 2s 378us/step - loss: 0.3409 - acc: 0.8378\n",
      "Epoch 79/160\n",
      "4263/4263 [==============================] - 1s 272us/step - loss: 0.3355 - acc: 0.8431\n",
      "Epoch 80/160\n",
      "4263/4263 [==============================] - 1s 237us/step - loss: 0.3342 - acc: 0.8438\n",
      "Epoch 81/160\n",
      "4263/4263 [==============================] - 1s 237us/step - loss: 0.3358 - acc: 0.8442\n",
      "Epoch 82/160\n",
      "4263/4263 [==============================] - 1s 232us/step - loss: 0.3334 - acc: 0.8468\n",
      "Epoch 83/160\n",
      "4263/4263 [==============================] - 1s 251us/step - loss: 0.3350 - acc: 0.8432\n",
      "Epoch 84/160\n",
      "4263/4263 [==============================] - 1s 315us/step - loss: 0.3335 - acc: 0.8464\n",
      "Epoch 85/160\n",
      "4263/4263 [==============================] - 1s 250us/step - loss: 0.3365 - acc: 0.8439\n",
      "Epoch 86/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3361 - acc: 0.8411\n",
      "Epoch 87/160\n",
      "4263/4263 [==============================] - 1s 265us/step - loss: 0.3324 - acc: 0.8444\n",
      "Epoch 88/160\n",
      "4263/4263 [==============================] - 1s 249us/step - loss: 0.3341 - acc: 0.8477\n",
      "Epoch 89/160\n",
      "4263/4263 [==============================] - 1s 325us/step - loss: 0.3332 - acc: 0.8451\n",
      "Epoch 90/160\n",
      "4263/4263 [==============================] - 1s 291us/step - loss: 0.3315 - acc: 0.8434\n",
      "Epoch 91/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3355 - acc: 0.8437\n",
      "Epoch 92/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3316 - acc: 0.8454\n",
      "Epoch 93/160\n",
      "4263/4263 [==============================] - 1s 310us/step - loss: 0.3326 - acc: 0.8419\n",
      "Epoch 94/160\n",
      "4263/4263 [==============================] - 1s 236us/step - loss: 0.3303 - acc: 0.8458\n",
      "Epoch 95/160\n",
      "4263/4263 [==============================] - 1s 215us/step - loss: 0.3346 - acc: 0.8420\n",
      "Epoch 96/160\n",
      "4263/4263 [==============================] - 1s 213us/step - loss: 0.3314 - acc: 0.8454\n",
      "Epoch 97/160\n",
      "4263/4263 [==============================] - 1s 258us/step - loss: 0.3384 - acc: 0.8408\n",
      "Epoch 98/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3333 - acc: 0.8467\n",
      "Epoch 99/160\n",
      "4263/4263 [==============================] - 1s 226us/step - loss: 0.3319 - acc: 0.8447\n",
      "Epoch 100/160\n",
      "4263/4263 [==============================] - 1s 255us/step - loss: 0.3326 - acc: 0.8434\n",
      "Epoch 101/160\n",
      "4263/4263 [==============================] - 1s 281us/step - loss: 0.3313 - acc: 0.8461\n",
      "Epoch 102/160\n",
      "4263/4263 [==============================] - 1s 291us/step - loss: 0.3297 - acc: 0.8461\n",
      "Epoch 103/160\n",
      "4263/4263 [==============================] - 1s 238us/step - loss: 0.3282 - acc: 0.8459\n",
      "Epoch 104/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3289 - acc: 0.8465\n",
      "Epoch 105/160\n",
      "4263/4263 [==============================] - 1s 257us/step - loss: 0.3284 - acc: 0.8462\n",
      "Epoch 106/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.3296 - acc: 0.8456\n",
      "Epoch 107/160\n",
      "4263/4263 [==============================] - 1s 272us/step - loss: 0.3287 - acc: 0.8459\n",
      "Epoch 108/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3276 - acc: 0.8481\n",
      "Epoch 109/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3307 - acc: 0.8459\n",
      "Epoch 110/160\n",
      "4263/4263 [==============================] - 1s 263us/step - loss: 0.3260 - acc: 0.8497\n",
      "Epoch 111/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3285 - acc: 0.8484\n",
      "Epoch 112/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3266 - acc: 0.8486\n",
      "Epoch 113/160\n",
      "4263/4263 [==============================] - 1s 217us/step - loss: 0.3254 - acc: 0.8491\n",
      "Epoch 114/160\n",
      "4263/4263 [==============================] - 1s 248us/step - loss: 0.3289 - acc: 0.8472\n",
      "Epoch 115/160\n",
      "4263/4263 [==============================] - 1s 327us/step - loss: 0.3270 - acc: 0.8484\n",
      "Epoch 116/160\n",
      "4263/4263 [==============================] - 1s 246us/step - loss: 0.3270 - acc: 0.8485\n",
      "Epoch 117/160\n",
      "4263/4263 [==============================] - 1s 345us/step - loss: 0.3264 - acc: 0.8463\n",
      "Epoch 118/160\n",
      "4263/4263 [==============================] - 1s 338us/step - loss: 0.3246 - acc: 0.8488\n",
      "Epoch 119/160\n",
      "4263/4263 [==============================] - 1s 336us/step - loss: 0.3217 - acc: 0.8516\n",
      "Epoch 120/160\n",
      "4263/4263 [==============================] - 1s 334us/step - loss: 0.3258 - acc: 0.8483\n",
      "Epoch 121/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.3238 - acc: 0.8493\n",
      "Epoch 122/160\n",
      "4263/4263 [==============================] - 1s 265us/step - loss: 0.3237 - acc: 0.8475\n",
      "Epoch 123/160\n",
      "4263/4263 [==============================] - 1s 258us/step - loss: 0.3227 - acc: 0.8496\n",
      "Epoch 124/160\n",
      "4263/4263 [==============================] - 1s 249us/step - loss: 0.3225 - acc: 0.8510\n",
      "Epoch 125/160\n",
      "4263/4263 [==============================] - 1s 259us/step - loss: 0.3230 - acc: 0.8476\n",
      "Epoch 126/160\n",
      "4263/4263 [==============================] - 1s 264us/step - loss: 0.3217 - acc: 0.8493\n",
      "Epoch 127/160\n",
      "4263/4263 [==============================] - 1s 264us/step - loss: 0.3219 - acc: 0.8487\n",
      "Epoch 128/160\n",
      "4263/4263 [==============================] - 1s 291us/step - loss: 0.3188 - acc: 0.8530\n",
      "Epoch 129/160\n",
      "4263/4263 [==============================] - 1s 321us/step - loss: 0.3196 - acc: 0.8517\n",
      "Epoch 130/160\n",
      "4263/4263 [==============================] - 1s 246us/step - loss: 0.3199 - acc: 0.8513\n",
      "Epoch 131/160\n",
      "4263/4263 [==============================] - 1s 222us/step - loss: 0.3172 - acc: 0.8527\n",
      "Epoch 132/160\n",
      "4263/4263 [==============================] - 1s 236us/step - loss: 0.3189 - acc: 0.8520\n",
      "Epoch 133/160\n",
      "4263/4263 [==============================] - 1s 347us/step - loss: 0.3256 - acc: 0.8491\n",
      "Epoch 134/160\n",
      "4263/4263 [==============================] - 1s 244us/step - loss: 0.3197 - acc: 0.8500\n",
      "Epoch 135/160\n",
      "4263/4263 [==============================] - 1s 242us/step - loss: 0.3219 - acc: 0.8493\n",
      "Epoch 136/160\n",
      "4263/4263 [==============================] - 1s 254us/step - loss: 0.3189 - acc: 0.8510\n",
      "Epoch 137/160\n",
      "4263/4263 [==============================] - 1s 275us/step - loss: 0.3236 - acc: 0.8482\n",
      "Epoch 138/160\n",
      "4263/4263 [==============================] - 1s 223us/step - loss: 0.3159 - acc: 0.8517\n",
      "Epoch 139/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3148 - acc: 0.8527\n",
      "Epoch 140/160\n",
      "4263/4263 [==============================] - 1s 254us/step - loss: 0.3142 - acc: 0.8506\n",
      "Epoch 141/160\n",
      "4263/4263 [==============================] - 1s 257us/step - loss: 0.3145 - acc: 0.8530\n",
      "Epoch 142/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3159 - acc: 0.8520\n",
      "Epoch 143/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3141 - acc: 0.8536\n",
      "Epoch 144/160\n",
      "4263/4263 [==============================] - 1s 253us/step - loss: 0.3122 - acc: 0.8550\n",
      "Epoch 145/160\n",
      "4263/4263 [==============================] - 1s 262us/step - loss: 0.3143 - acc: 0.8542\n",
      "Epoch 146/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3126 - acc: 0.8542\n",
      "Epoch 147/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3189 - acc: 0.8521\n",
      "Epoch 148/160\n",
      "4263/4263 [==============================] - 1s 257us/step - loss: 0.3154 - acc: 0.8522\n",
      "Epoch 149/160\n",
      "4263/4263 [==============================] - 1s 266us/step - loss: 0.3118 - acc: 0.8556\n",
      "Epoch 150/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3105 - acc: 0.8533\n",
      "Epoch 151/160\n",
      "4263/4263 [==============================] - 1s 217us/step - loss: 0.3119 - acc: 0.8529\n",
      "Epoch 152/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3149 - acc: 0.8525\n",
      "Epoch 153/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3131 - acc: 0.8543\n",
      "Epoch 154/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3152 - acc: 0.8532\n",
      "Epoch 155/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3109 - acc: 0.8538\n",
      "Epoch 156/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3132 - acc: 0.8544\n",
      "Epoch 157/160\n",
      "4263/4263 [==============================] - 1s 217us/step - loss: 0.3086 - acc: 0.8544\n",
      "Epoch 158/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3076 - acc: 0.8583\n",
      "Epoch 159/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3098 - acc: 0.8573\n",
      "Epoch 160/160\n",
      "4263/4263 [==============================] - 1s 302us/step - loss: 0.3041 - acc: 0.8587\n",
      "1066/1066 [==============================] - 0s 331us/step\n",
      "4263/4263 [==============================] - 0s 65us/step\n",
      "\n",
      "acc: 83.77%\n",
      "[[126  91   0  32]\n",
      " [ 57 502  13   8]\n",
      " [  4  49  38   0]\n",
      " [ 14   3   0  53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.63      0.51      0.56       249\n",
      "      Normal       0.78      0.87      0.82       580\n",
      "        Slow       0.75      0.42      0.54        91\n",
      "   Very Fast       0.57      0.76      0.65        70\n",
      "\n",
      "    accuracy                           0.73       990\n",
      "   macro avg       0.68      0.64      0.64       990\n",
      "weighted avg       0.72      0.73      0.72       990\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7262626262626263"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df=pd.read_csv('6mar.csv')\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "    #print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    if k_1_i==1:\n",
    "        prediction_l.append('Fast')\n",
    "    if k_2_i==1:\n",
    "        prediction_l.append('Normal')\n",
    "    if k_3_i==1:\n",
    "        prediction_l.append('Slow')\n",
    "    if k_4_i==1:\n",
    "        prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "    if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "    j=j+1\n",
    "    #print(i)\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0        1\n",
      "1323     Normal  32.8906\n",
      "1839     Normal  27.1147\n",
      "798      Normal  25.3206\n",
      "3855     Normal  22.1571\n",
      "4552     Normal  26.8351\n",
      "856      Normal   34.532\n",
      "2333  Very Fast  67.2025\n",
      "2499     Normal  30.2745\n",
      "5010     Normal  29.9627\n",
      "4379     Normal  27.2221\n",
      "4733     Normal  20.7327\n",
      "655      Normal  30.5468\n",
      "2101  Very Fast  65.8472\n",
      "893      Normal  30.4039\n",
      "373      Normal  31.9208\n",
      "297      Normal  29.7434\n",
      "3817       Slow  17.4819\n",
      "1808     Normal  28.2495\n",
      "4392     Normal  20.8796\n",
      "3585       Slow  11.3372\n",
      "240      Normal  29.7452\n",
      "4650     Normal   23.261\n",
      "2951     Normal  33.9055\n",
      "2860       Fast  48.8663\n",
      "465      Normal  34.0504\n",
      "3685       Fast  40.2017\n",
      "4316     Normal  20.5973\n",
      "84       Normal   26.149\n",
      "1498     Normal  33.2387\n",
      "803      Normal  28.6815\n",
      "...         ...      ...\n",
      "1700       Fast  40.7511\n",
      "745      Normal  30.0088\n",
      "5074  Very Fast  56.1609\n",
      "1815     Normal  33.6603\n",
      "1611     Normal  27.8781\n",
      "195      Normal  32.8014\n",
      "4898     Normal  28.6067\n",
      "3039     Normal  26.1896\n",
      "802      Normal   32.394\n",
      "3437       Slow  19.1137\n",
      "1717       Fast  45.5117\n",
      "1103     Normal  27.7598\n",
      "3463     Normal  28.8778\n",
      "3358     Normal  23.2036\n",
      "3326       Fast  40.3134\n",
      "1747     Normal  33.0536\n",
      "1740       Fast  38.8713\n",
      "644        Fast  38.3068\n",
      "4145       Fast  42.3307\n",
      "3916       Slow  18.7451\n",
      "120      Normal  29.9765\n",
      "3196     Normal  22.7978\n",
      "1881     Normal   29.029\n",
      "3999     Normal  27.9225\n",
      "4293     Normal  29.5863\n",
      "2841       Fast  35.7972\n",
      "5207       Slow  13.0979\n",
      "1965       Slow  18.8104\n",
      "4537  Very Fast  64.4044\n",
      "134      Normal  31.7407\n",
      "\n",
      "[1066 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fast  Normal  Slow  Very Fast\n",
      "1323     0       1     0          0\n",
      "1839     0       1     0          0\n",
      "798      0       1     0          0\n",
      "3855     0       1     0          0\n",
      "4552     0       1     0          0\n",
      "856      0       1     0          0\n",
      "2333     0       0     0          1\n",
      "2499     0       1     0          0\n",
      "5010     0       1     0          0\n",
      "4379     0       1     0          0\n",
      "4733     0       1     0          0\n",
      "655      0       1     0          0\n",
      "2101     0       0     0          1\n",
      "893      0       1     0          0\n",
      "373      0       1     0          0\n",
      "297      0       1     0          0\n",
      "3817     0       0     1          0\n",
      "1808     0       1     0          0\n",
      "4392     0       1     0          0\n",
      "3585     0       0     1          0\n",
      "240      0       1     0          0\n",
      "4650     0       1     0          0\n",
      "2951     0       1     0          0\n",
      "2860     1       0     0          0\n",
      "465      0       1     0          0\n",
      "3685     1       0     0          0\n",
      "4316     0       1     0          0\n",
      "84       0       1     0          0\n",
      "1498     0       1     0          0\n",
      "803      0       1     0          0\n",
      "...    ...     ...   ...        ...\n",
      "1700     1       0     0          0\n",
      "745      0       1     0          0\n",
      "5074     0       0     0          1\n",
      "1815     0       1     0          0\n",
      "1611     0       1     0          0\n",
      "195      0       1     0          0\n",
      "4898     0       1     0          0\n",
      "3039     0       1     0          0\n",
      "802      0       1     0          0\n",
      "3437     0       0     1          0\n",
      "1717     1       0     0          0\n",
      "1103     0       1     0          0\n",
      "3463     0       1     0          0\n",
      "3358     0       1     0          0\n",
      "3326     1       0     0          0\n",
      "1747     0       1     0          0\n",
      "1740     1       0     0          0\n",
      "644      1       0     0          0\n",
      "4145     1       0     0          0\n",
      "3916     0       0     1          0\n",
      "120      0       1     0          0\n",
      "3196     0       1     0          0\n",
      "1881     0       1     0          0\n",
      "3999     0       1     0          0\n",
      "4293     0       1     0          0\n",
      "2841     1       0     0          0\n",
      "5207     0       0     1          0\n",
      "1965     0       0     1          0\n",
      "4537     0       0     0          1\n",
      "134      0       1     0          0\n",
      "\n",
      "[1066 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/160\n",
      "4263/4263 [==============================] - 2s 381us/step - loss: 0.4433 - acc: 0.7988\n",
      "Epoch 2/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.4011 - acc: 0.8099\n",
      "Epoch 3/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3892 - acc: 0.8123\n",
      "Epoch 4/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3821 - acc: 0.8181\n",
      "Epoch 5/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.3783 - acc: 0.8182\n",
      "Epoch 6/160\n",
      "4263/4263 [==============================] - 1s 268us/step - loss: 0.3769 - acc: 0.8189\n",
      "Epoch 7/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3741 - acc: 0.8218\n",
      "Epoch 8/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3740 - acc: 0.8221\n",
      "Epoch 9/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3729 - acc: 0.8245\n",
      "Epoch 10/160\n",
      "4263/4263 [==============================] - 1s 222us/step - loss: 0.3670 - acc: 0.8271\n",
      "Epoch 11/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3741 - acc: 0.8222\n",
      "Epoch 12/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3686 - acc: 0.8251\n",
      "Epoch 13/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3653 - acc: 0.8268\n",
      "Epoch 14/160\n",
      "4263/4263 [==============================] - 1s 217us/step - loss: 0.3625 - acc: 0.8262\n",
      "Epoch 15/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3673 - acc: 0.8238\n",
      "Epoch 16/160\n",
      "4263/4263 [==============================] - 1s 265us/step - loss: 0.3620 - acc: 0.8278\n",
      "Epoch 17/160\n",
      "4263/4263 [==============================] - 1s 259us/step - loss: 0.3609 - acc: 0.8271\n",
      "Epoch 18/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3587 - acc: 0.8276\n",
      "Epoch 19/160\n",
      "4263/4263 [==============================] - 1s 215us/step - loss: 0.3545 - acc: 0.8318\n",
      "Epoch 20/160\n",
      "4263/4263 [==============================] - 1s 267us/step - loss: 0.3558 - acc: 0.8325\n",
      "Epoch 21/160\n",
      "4263/4263 [==============================] - 1s 255us/step - loss: 0.3562 - acc: 0.8313\n",
      "Epoch 22/160\n",
      "4263/4263 [==============================] - 1s 222us/step - loss: 0.3549 - acc: 0.8342\n",
      "Epoch 23/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3561 - acc: 0.8320\n",
      "Epoch 24/160\n",
      "4263/4263 [==============================] - 1s 270us/step - loss: 0.3531 - acc: 0.8322\n",
      "Epoch 25/160\n",
      "4263/4263 [==============================] - 1s 250us/step - loss: 0.3550 - acc: 0.8349\n",
      "Epoch 26/160\n",
      "4263/4263 [==============================] - 1s 222us/step - loss: 0.3540 - acc: 0.8298\n",
      "Epoch 27/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3480 - acc: 0.8349\n",
      "Epoch 28/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.3490 - acc: 0.8370\n",
      "Epoch 29/160\n",
      "4263/4263 [==============================] - 1s 295us/step - loss: 0.3526 - acc: 0.8340\n",
      "Epoch 30/160\n",
      "4263/4263 [==============================] - 1s 290us/step - loss: 0.3483 - acc: 0.8375\n",
      "Epoch 31/160\n",
      "4263/4263 [==============================] - 1s 349us/step - loss: 0.3547 - acc: 0.8311\n",
      "Epoch 32/160\n",
      "4263/4263 [==============================] - 1s 293us/step - loss: 0.3540 - acc: 0.8317\n",
      "Epoch 33/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.3512 - acc: 0.8340\n",
      "Epoch 34/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3507 - acc: 0.8326\n",
      "Epoch 35/160\n",
      "4263/4263 [==============================] - 1s 295us/step - loss: 0.3464 - acc: 0.8346\n",
      "Epoch 36/160\n",
      "4263/4263 [==============================] - 1s 214us/step - loss: 0.3496 - acc: 0.8335\n",
      "Epoch 37/160\n",
      "4263/4263 [==============================] - 1s 232us/step - loss: 0.3473 - acc: 0.8346\n",
      "Epoch 38/160\n",
      "4263/4263 [==============================] - 1s 251us/step - loss: 0.3475 - acc: 0.8360\n",
      "Epoch 39/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3450 - acc: 0.8387\n",
      "Epoch 40/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3464 - acc: 0.8351\n",
      "Epoch 41/160\n",
      "4263/4263 [==============================] - 1s 248us/step - loss: 0.3462 - acc: 0.8330\n",
      "Epoch 42/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.3457 - acc: 0.8371\n",
      "Epoch 43/160\n",
      "4263/4263 [==============================] - 1s 258us/step - loss: 0.3460 - acc: 0.8342\n",
      "Epoch 44/160\n",
      "4263/4263 [==============================] - 1s 225us/step - loss: 0.3475 - acc: 0.8332\n",
      "Epoch 45/160\n",
      "4263/4263 [==============================] - 1s 239us/step - loss: 0.3452 - acc: 0.8347\n",
      "Epoch 46/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.3426 - acc: 0.8384\n",
      "Epoch 47/160\n",
      "4263/4263 [==============================] - 1s 225us/step - loss: 0.3412 - acc: 0.8394\n",
      "Epoch 48/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3458 - acc: 0.8370\n",
      "Epoch 49/160\n",
      "4263/4263 [==============================] - 1s 242us/step - loss: 0.3448 - acc: 0.8369\n",
      "Epoch 50/160\n",
      "4263/4263 [==============================] - 1s 279us/step - loss: 0.3402 - acc: 0.8381\n",
      "Epoch 51/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3423 - acc: 0.8393\n",
      "Epoch 52/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3408 - acc: 0.8401\n",
      "Epoch 53/160\n",
      "4263/4263 [==============================] - 1s 252us/step - loss: 0.3427 - acc: 0.8378\n",
      "Epoch 54/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3407 - acc: 0.8390\n",
      "Epoch 55/160\n",
      "4263/4263 [==============================] - 1s 222us/step - loss: 0.3395 - acc: 0.8383\n",
      "Epoch 56/160\n",
      "4263/4263 [==============================] - 1s 226us/step - loss: 0.3420 - acc: 0.8412\n",
      "Epoch 57/160\n",
      "4263/4263 [==============================] - 1s 265us/step - loss: 0.3419 - acc: 0.8388\n",
      "Epoch 58/160\n",
      "4263/4263 [==============================] - 1s 260us/step - loss: 0.3423 - acc: 0.8377\n",
      "Epoch 59/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3400 - acc: 0.8400\n",
      "Epoch 60/160\n",
      "4263/4263 [==============================] - 1s 229us/step - loss: 0.3408 - acc: 0.8378\n",
      "Epoch 61/160\n",
      "4263/4263 [==============================] - 1s 278us/step - loss: 0.3452 - acc: 0.8387\n",
      "Epoch 62/160\n",
      "4263/4263 [==============================] - 1s 251us/step - loss: 0.3417 - acc: 0.8401\n",
      "Epoch 63/160\n",
      "4263/4263 [==============================] - 1s 223us/step - loss: 0.3377 - acc: 0.8407\n",
      "Epoch 64/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3429 - acc: 0.8361\n",
      "Epoch 65/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3412 - acc: 0.8386\n",
      "Epoch 66/160\n",
      "4263/4263 [==============================] - 1s 241us/step - loss: 0.3407 - acc: 0.8386\n",
      "Epoch 67/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3390 - acc: 0.8395\n",
      "Epoch 68/160\n",
      "4263/4263 [==============================] - 1s 223us/step - loss: 0.3373 - acc: 0.8407\n",
      "Epoch 69/160\n",
      "4263/4263 [==============================] - 1s 225us/step - loss: 0.3367 - acc: 0.8401\n",
      "Epoch 70/160\n",
      "4263/4263 [==============================] - 1s 229us/step - loss: 0.3378 - acc: 0.8383\n",
      "Epoch 71/160\n",
      "4263/4263 [==============================] - 1s 240us/step - loss: 0.3369 - acc: 0.8413\n",
      "Epoch 72/160\n",
      "4263/4263 [==============================] - 1s 272us/step - loss: 0.3369 - acc: 0.8402\n",
      "Epoch 73/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.3378 - acc: 0.8412\n",
      "Epoch 74/160\n",
      "4263/4263 [==============================] - 1s 243us/step - loss: 0.3378 - acc: 0.8424\n",
      "Epoch 75/160\n",
      "4263/4263 [==============================] - 1s 232us/step - loss: 0.3390 - acc: 0.8397\n",
      "Epoch 76/160\n",
      "4263/4263 [==============================] - 1s 295us/step - loss: 0.3367 - acc: 0.8437\n",
      "Epoch 77/160\n",
      "4263/4263 [==============================] - 1s 222us/step - loss: 0.3357 - acc: 0.8427\n",
      "Epoch 78/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3348 - acc: 0.8414\n",
      "Epoch 79/160\n",
      "4263/4263 [==============================] - 1s 231us/step - loss: 0.3402 - acc: 0.8417\n",
      "Epoch 80/160\n",
      "4263/4263 [==============================] - 1s 300us/step - loss: 0.3332 - acc: 0.8431\n",
      "Epoch 81/160\n",
      "4263/4263 [==============================] - 1s 225us/step - loss: 0.3363 - acc: 0.8433\n",
      "Epoch 82/160\n",
      "4263/4263 [==============================] - 1s 214us/step - loss: 0.3383 - acc: 0.8388\n",
      "Epoch 83/160\n",
      "4263/4263 [==============================] - 1s 228us/step - loss: 0.3332 - acc: 0.8440\n",
      "Epoch 84/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.3352 - acc: 0.8413\n",
      "Epoch 85/160\n",
      "4263/4263 [==============================] - 1s 215us/step - loss: 0.3323 - acc: 0.8469\n",
      "Epoch 86/160\n",
      "4263/4263 [==============================] - 1s 213us/step - loss: 0.3372 - acc: 0.8426\n",
      "Epoch 87/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3373 - acc: 0.8409\n",
      "Epoch 88/160\n",
      "4263/4263 [==============================] - 1s 300us/step - loss: 0.3336 - acc: 0.8413\n",
      "Epoch 89/160\n",
      "4263/4263 [==============================] - 1s 215us/step - loss: 0.3330 - acc: 0.8447\n",
      "Epoch 90/160\n",
      "4263/4263 [==============================] - 1s 212us/step - loss: 0.3328 - acc: 0.8441\n",
      "Epoch 91/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3348 - acc: 0.8436\n",
      "Epoch 92/160\n",
      "4263/4263 [==============================] - 1s 285us/step - loss: 0.3355 - acc: 0.8435\n",
      "Epoch 93/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3335 - acc: 0.8433\n",
      "Epoch 94/160\n",
      "4263/4263 [==============================] - 1s 217us/step - loss: 0.3320 - acc: 0.8436\n",
      "Epoch 95/160\n",
      "4263/4263 [==============================] - 1s 218us/step - loss: 0.3329 - acc: 0.8459\n",
      "Epoch 96/160\n",
      "4263/4263 [==============================] - 1s 293us/step - loss: 0.3299 - acc: 0.8447\n",
      "Epoch 97/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3294 - acc: 0.8454\n",
      "Epoch 98/160\n",
      "4263/4263 [==============================] - 1s 217us/step - loss: 0.3346 - acc: 0.8446\n",
      "Epoch 99/160\n",
      "4263/4263 [==============================] - 1s 214us/step - loss: 0.3329 - acc: 0.8443\n",
      "Epoch 100/160\n",
      "4263/4263 [==============================] - 1s 215us/step - loss: 0.3293 - acc: 0.8448\n",
      "Epoch 101/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3288 - acc: 0.8469\n",
      "Epoch 102/160\n",
      "4263/4263 [==============================] - 1s 215us/step - loss: 0.3317 - acc: 0.8469\n",
      "Epoch 103/160\n",
      "4263/4263 [==============================] - 1s 214us/step - loss: 0.3302 - acc: 0.8471\n",
      "Epoch 104/160\n",
      "4263/4263 [==============================] - 1s 213us/step - loss: 0.3319 - acc: 0.8446\n",
      "Epoch 105/160\n",
      "4263/4263 [==============================] - 1s 216us/step - loss: 0.3303 - acc: 0.8441\n",
      "Epoch 106/160\n",
      "4263/4263 [==============================] - 1s 213us/step - loss: 0.3323 - acc: 0.8465\n",
      "Epoch 107/160\n",
      "4263/4263 [==============================] - 1s 235us/step - loss: 0.3320 - acc: 0.8451\n",
      "Epoch 108/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.3300 - acc: 0.8447\n",
      "Epoch 109/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3304 - acc: 0.8456\n",
      "Epoch 110/160\n",
      "4263/4263 [==============================] - 1s 256us/step - loss: 0.3248 - acc: 0.8486\n",
      "Epoch 111/160\n",
      "4263/4263 [==============================] - 2s 357us/step - loss: 0.3281 - acc: 0.8472\n",
      "Epoch 112/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3283 - acc: 0.8467\n",
      "Epoch 113/160\n",
      "4263/4263 [==============================] - 1s 236us/step - loss: 0.3239 - acc: 0.8493\n",
      "Epoch 114/160\n",
      "4263/4263 [==============================] - 1s 252us/step - loss: 0.3297 - acc: 0.8453\n",
      "Epoch 115/160\n",
      "4263/4263 [==============================] - 1s 350us/step - loss: 0.3303 - acc: 0.8483\n",
      "Epoch 116/160\n",
      "4263/4263 [==============================] - 1s 249us/step - loss: 0.3278 - acc: 0.8478\n",
      "Epoch 117/160\n",
      "4263/4263 [==============================] - 1s 230us/step - loss: 0.3287 - acc: 0.8472\n",
      "Epoch 118/160\n",
      "4263/4263 [==============================] - 1s 291us/step - loss: 0.3239 - acc: 0.8491\n",
      "Epoch 119/160\n",
      "4263/4263 [==============================] - 1s 243us/step - loss: 0.3274 - acc: 0.8454\n",
      "Epoch 120/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3258 - acc: 0.8467\n",
      "Epoch 121/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3238 - acc: 0.8488\n",
      "Epoch 122/160\n",
      "4263/4263 [==============================] - 1s 305us/step - loss: 0.3258 - acc: 0.8488\n",
      "Epoch 123/160\n",
      "4263/4263 [==============================] - 1s 281us/step - loss: 0.3226 - acc: 0.8490\n",
      "Epoch 124/160\n",
      "4263/4263 [==============================] - 1s 238us/step - loss: 0.3256 - acc: 0.8482\n",
      "Epoch 125/160\n",
      "4263/4263 [==============================] - 1s 288us/step - loss: 0.3216 - acc: 0.8504\n",
      "Epoch 126/160\n",
      "4263/4263 [==============================] - 1s 312us/step - loss: 0.3227 - acc: 0.8496\n",
      "Epoch 127/160\n",
      "4263/4263 [==============================] - 1s 256us/step - loss: 0.3271 - acc: 0.8476\n",
      "Epoch 128/160\n",
      "4263/4263 [==============================] - 1s 250us/step - loss: 0.3244 - acc: 0.8477\n",
      "Epoch 129/160\n",
      "4263/4263 [==============================] - 1s 257us/step - loss: 0.3239 - acc: 0.8500\n",
      "Epoch 130/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.3223 - acc: 0.8508\n",
      "Epoch 131/160\n",
      "4263/4263 [==============================] - 1s 275us/step - loss: 0.3230 - acc: 0.8511\n",
      "Epoch 132/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.3196 - acc: 0.8501\n",
      "Epoch 133/160\n",
      "4263/4263 [==============================] - 1s 237us/step - loss: 0.3216 - acc: 0.8512\n",
      "Epoch 134/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3218 - acc: 0.8518\n",
      "Epoch 135/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.3220 - acc: 0.8510\n",
      "Epoch 136/160\n",
      "4263/4263 [==============================] - 1s 252us/step - loss: 0.3183 - acc: 0.8527\n",
      "Epoch 137/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3219 - acc: 0.8479\n",
      "Epoch 138/160\n",
      "4263/4263 [==============================] - 1s 225us/step - loss: 0.3198 - acc: 0.8539\n",
      "Epoch 139/160\n",
      "4263/4263 [==============================] - 1s 297us/step - loss: 0.3194 - acc: 0.8513\n",
      "Epoch 140/160\n",
      "4263/4263 [==============================] - 1s 241us/step - loss: 0.3246 - acc: 0.8504\n",
      "Epoch 141/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3184 - acc: 0.8520\n",
      "Epoch 142/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3192 - acc: 0.8529\n",
      "Epoch 143/160\n",
      "4263/4263 [==============================] - 1s 307us/step - loss: 0.3162 - acc: 0.8522\n",
      "Epoch 144/160\n",
      "4263/4263 [==============================] - 1s 226us/step - loss: 0.3267 - acc: 0.8488\n",
      "Epoch 145/160\n",
      "4263/4263 [==============================] - 1s 223us/step - loss: 0.3233 - acc: 0.8478\n",
      "Epoch 146/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3202 - acc: 0.8508\n",
      "Epoch 147/160\n",
      "4263/4263 [==============================] - 1s 308us/step - loss: 0.3164 - acc: 0.8531\n",
      "Epoch 148/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3178 - acc: 0.8528\n",
      "Epoch 149/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3159 - acc: 0.8518\n",
      "Epoch 150/160\n",
      "4263/4263 [==============================] - 1s 228us/step - loss: 0.3136 - acc: 0.8551\n",
      "Epoch 151/160\n",
      "4263/4263 [==============================] - 1s 303us/step - loss: 0.3189 - acc: 0.8523\n",
      "Epoch 152/160\n",
      "4263/4263 [==============================] - 1s 227us/step - loss: 0.3121 - acc: 0.8550\n",
      "Epoch 153/160\n",
      "4263/4263 [==============================] - 1s 219us/step - loss: 0.3177 - acc: 0.8505\n",
      "Epoch 154/160\n",
      "4263/4263 [==============================] - 1s 243us/step - loss: 0.3175 - acc: 0.8535\n",
      "Epoch 155/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.3165 - acc: 0.8524\n",
      "Epoch 156/160\n",
      "4263/4263 [==============================] - 1s 224us/step - loss: 0.3186 - acc: 0.8513\n",
      "Epoch 157/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3144 - acc: 0.8561\n",
      "Epoch 158/160\n",
      "4263/4263 [==============================] - 1s 220us/step - loss: 0.3150 - acc: 0.8525\n",
      "Epoch 159/160\n",
      "4263/4263 [==============================] - 1s 221us/step - loss: 0.3149 - acc: 0.8564\n",
      "Epoch 160/160\n",
      "4263/4263 [==============================] - 1s 222us/step - loss: 0.3336 - acc: 0.8444\n",
      "1066/1066 [==============================] - 0s 170us/step\n",
      "4263/4263 [==============================] - 0s 43us/step\n",
      "\n",
      "acc: 83.42%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prdiction_l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-42847fc9372f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk_1_i\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk_2_i\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk_3_i\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mk_4_i\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mall_zero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mprdiction_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prdiction_l' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df=pd.read_csv('6mar.csv')\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    #print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "[[177  75   0  27]\n",
      " [ 24 566  11   9]\n",
      " [  1  24  70   1]\n",
      " [  8   8   0  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.84      0.63      0.72       279\n",
      "      Normal       0.84      0.93      0.88       610\n",
      "        Slow       0.86      0.73      0.79        96\n",
      "   Very Fast       0.64      0.80      0.71        81\n",
      "\n",
      "    accuracy                           0.82      1066\n",
      "   macro avg       0.80      0.77      0.78      1066\n",
      "weighted avg       0.83      0.82      0.82      1066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8236397748592871"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "4263/4263 [==============================] - 2s 461us/step - loss: 0.4371 - acc: 0.7967\n",
      "Epoch 2/160\n",
      " 650/4263 [===>..........................] - ETA: 1s - loss: 0.3989 - acc: 0.8108"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.4006 - acc: 0.8068\n",
      "Epoch 3/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.3886 - acc: 0.8142\n",
      "Epoch 4/160\n",
      "4263/4263 [==============================] - 1s 265us/step - loss: 0.3828 - acc: 0.8172\n",
      "Epoch 5/160\n",
      "4263/4263 [==============================] - 1s 278us/step - loss: 0.3820 - acc: 0.8194\n",
      "Epoch 6/160\n",
      "4263/4263 [==============================] - 1s 301us/step - loss: 0.3771 - acc: 0.8198\n",
      "Epoch 7/160\n",
      "4263/4263 [==============================] - 1s 315us/step - loss: 0.3811 - acc: 0.8147\n",
      "Epoch 8/160\n",
      "4263/4263 [==============================] - 1s 326us/step - loss: 0.3748 - acc: 0.8204\n",
      "Epoch 9/160\n",
      "4263/4263 [==============================] - 2s 360us/step - loss: 0.3755 - acc: 0.8216\n",
      "Epoch 10/160\n",
      "4263/4263 [==============================] - 2s 362us/step - loss: 0.3726 - acc: 0.8230\n",
      "Epoch 11/160\n",
      "4263/4263 [==============================] - 2s 358us/step - loss: 0.3686 - acc: 0.8242\n",
      "Epoch 12/160\n",
      "4263/4263 [==============================] - 1s 290us/step - loss: 0.3679 - acc: 0.8248\n",
      "Epoch 13/160\n",
      "4263/4263 [==============================] - 1s 291us/step - loss: 0.3656 - acc: 0.8265\n",
      "Epoch 14/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3671 - acc: 0.8243\n",
      "Epoch 15/160\n",
      "4263/4263 [==============================] - 1s 292us/step - loss: 0.3635 - acc: 0.8275\n",
      "Epoch 16/160\n",
      "4263/4263 [==============================] - 1s 294us/step - loss: 0.3624 - acc: 0.8268\n",
      "Epoch 17/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.3621 - acc: 0.8269\n",
      "Epoch 18/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.3624 - acc: 0.8271\n",
      "Epoch 19/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3579 - acc: 0.8312\n",
      "Epoch 20/160\n",
      "4263/4263 [==============================] - 1s 292us/step - loss: 0.3564 - acc: 0.8317\n",
      "Epoch 21/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.3570 - acc: 0.8340\n",
      "Epoch 22/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3566 - acc: 0.8297\n",
      "Epoch 23/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.3511 - acc: 0.8335\n",
      "Epoch 24/160\n",
      "4263/4263 [==============================] - 1s 281us/step - loss: 0.3574 - acc: 0.8296\n",
      "Epoch 25/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3520 - acc: 0.8328\n",
      "Epoch 26/160\n",
      "4263/4263 [==============================] - 1s 288us/step - loss: 0.3474 - acc: 0.8366\n",
      "Epoch 27/160\n",
      "4263/4263 [==============================] - 1s 285us/step - loss: 0.3503 - acc: 0.8327\n",
      "Epoch 28/160\n",
      "4263/4263 [==============================] - 1s 280us/step - loss: 0.3479 - acc: 0.8343\n",
      "Epoch 29/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3448 - acc: 0.8370\n",
      "Epoch 30/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3469 - acc: 0.8387\n",
      "Epoch 31/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3430 - acc: 0.8373\n",
      "Epoch 32/160\n",
      "4263/4263 [==============================] - 1s 285us/step - loss: 0.3452 - acc: 0.8391\n",
      "Epoch 33/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.3425 - acc: 0.8402\n",
      "Epoch 34/160\n",
      "4263/4263 [==============================] - 1s 280us/step - loss: 0.3428 - acc: 0.8405\n",
      "Epoch 35/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.3456 - acc: 0.8374\n",
      "Epoch 36/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3388 - acc: 0.8394\n",
      "Epoch 37/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.3383 - acc: 0.8397\n",
      "Epoch 38/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3434 - acc: 0.8369\n",
      "Epoch 39/160\n",
      "4263/4263 [==============================] - 1s 281us/step - loss: 0.3395 - acc: 0.8403\n",
      "Epoch 40/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.3391 - acc: 0.8408\n",
      "Epoch 41/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3366 - acc: 0.8402\n",
      "Epoch 42/160\n",
      "4263/4263 [==============================] - 1s 292us/step - loss: 0.3368 - acc: 0.8403\n",
      "Epoch 43/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.3368 - acc: 0.8413\n",
      "Epoch 44/160\n",
      "4263/4263 [==============================] - 1s 292us/step - loss: 0.3347 - acc: 0.8411\n",
      "Epoch 45/160\n",
      "4263/4263 [==============================] - 1s 285us/step - loss: 0.3382 - acc: 0.8392\n",
      "Epoch 46/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3348 - acc: 0.8381\n",
      "Epoch 47/160\n",
      "4263/4263 [==============================] - 1s 280us/step - loss: 0.3314 - acc: 0.8461\n",
      "Epoch 48/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3338 - acc: 0.8427\n",
      "Epoch 49/160\n",
      "4263/4263 [==============================] - 1s 285us/step - loss: 0.3312 - acc: 0.8425\n",
      "Epoch 50/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.3323 - acc: 0.8405\n",
      "Epoch 51/160\n",
      "4263/4263 [==============================] - 1s 288us/step - loss: 0.3302 - acc: 0.8421\n",
      "Epoch 52/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3304 - acc: 0.8417\n",
      "Epoch 53/160\n",
      "4263/4263 [==============================] - 1s 279us/step - loss: 0.3310 - acc: 0.8430\n",
      "Epoch 54/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.3291 - acc: 0.8442\n",
      "Epoch 55/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3283 - acc: 0.8449\n",
      "Epoch 56/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.3283 - acc: 0.8430\n",
      "Epoch 57/160\n",
      "4263/4263 [==============================] - 1s 290us/step - loss: 0.3261 - acc: 0.8438\n",
      "Epoch 58/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3287 - acc: 0.8447\n",
      "Epoch 59/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3254 - acc: 0.8468\n",
      "Epoch 60/160\n",
      "4263/4263 [==============================] - 1s 291us/step - loss: 0.3259 - acc: 0.8471\n",
      "Epoch 61/160\n",
      "4263/4263 [==============================] - 1s 292us/step - loss: 0.3298 - acc: 0.8434\n",
      "Epoch 62/160\n",
      "4263/4263 [==============================] - 1s 285us/step - loss: 0.3263 - acc: 0.8472\n",
      "Epoch 63/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.3264 - acc: 0.8469\n",
      "Epoch 64/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3239 - acc: 0.8465\n",
      "Epoch 65/160\n",
      "4263/4263 [==============================] - 2s 369us/step - loss: 0.3297 - acc: 0.8415\n",
      "Epoch 66/160\n",
      "4263/4263 [==============================] - 1s 312us/step - loss: 0.3245 - acc: 0.8481\n",
      "Epoch 67/160\n",
      "4263/4263 [==============================] - 1s 301us/step - loss: 0.3246 - acc: 0.8467\n",
      "Epoch 68/160\n",
      "4263/4263 [==============================] - 1s 298us/step - loss: 0.3210 - acc: 0.8468\n",
      "Epoch 69/160\n",
      "4263/4263 [==============================] - 1s 328us/step - loss: 0.3241 - acc: 0.8451\n",
      "Epoch 70/160\n",
      "4263/4263 [==============================] - 2s 380us/step - loss: 0.3222 - acc: 0.8485\n",
      "Epoch 71/160\n",
      "4263/4263 [==============================] - 1s 344us/step - loss: 0.3179 - acc: 0.8478\n",
      "Epoch 72/160\n",
      "4263/4263 [==============================] - 2s 377us/step - loss: 0.3191 - acc: 0.8458\n",
      "Epoch 73/160\n",
      "4263/4263 [==============================] - 1s 319us/step - loss: 0.3246 - acc: 0.8443\n",
      "Epoch 74/160\n",
      "4263/4263 [==============================] - 1s 306us/step - loss: 0.3211 - acc: 0.8476\n",
      "Epoch 75/160\n",
      "4263/4263 [==============================] - 2s 382us/step - loss: 0.3198 - acc: 0.8473\n",
      "Epoch 76/160\n",
      "4263/4263 [==============================] - 2s 371us/step - loss: 0.3167 - acc: 0.8530\n",
      "Epoch 77/160\n",
      "4263/4263 [==============================] - 1s 295us/step - loss: 0.3202 - acc: 0.8458\n",
      "Epoch 78/160\n",
      "4263/4263 [==============================] - 1s 291us/step - loss: 0.3148 - acc: 0.8498\n",
      "Epoch 79/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.3140 - acc: 0.8517\n",
      "Epoch 80/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.3178 - acc: 0.8478\n",
      "Epoch 81/160\n",
      "4263/4263 [==============================] - 1s 280us/step - loss: 0.3143 - acc: 0.8523\n",
      "Epoch 82/160\n",
      "4263/4263 [==============================] - 1s 293us/step - loss: 0.3154 - acc: 0.8507\n",
      "Epoch 83/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.3131 - acc: 0.8539\n",
      "Epoch 84/160\n",
      "4263/4263 [==============================] - 1s 272us/step - loss: 0.3162 - acc: 0.8516\n",
      "Epoch 85/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.3169 - acc: 0.8522\n",
      "Epoch 86/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3105 - acc: 0.8520\n",
      "Epoch 87/160\n",
      "4263/4263 [==============================] - 1s 276us/step - loss: 0.3152 - acc: 0.8503\n",
      "Epoch 88/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3140 - acc: 0.8548\n",
      "Epoch 89/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.3129 - acc: 0.8516\n",
      "Epoch 90/160\n",
      "4263/4263 [==============================] - 1s 266us/step - loss: 0.3133 - acc: 0.8530\n",
      "Epoch 91/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3118 - acc: 0.8530\n",
      "Epoch 92/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3127 - acc: 0.8512\n",
      "Epoch 93/160\n",
      "4263/4263 [==============================] - 1s 275us/step - loss: 0.3100 - acc: 0.8517\n",
      "Epoch 94/160\n",
      "4263/4263 [==============================] - 1s 278us/step - loss: 0.3131 - acc: 0.8499\n",
      "Epoch 95/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.3104 - acc: 0.8525\n",
      "Epoch 96/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.3078 - acc: 0.8553\n",
      "Epoch 97/160\n",
      "4263/4263 [==============================] - 1s 279us/step - loss: 0.3059 - acc: 0.8534\n",
      "Epoch 98/160\n",
      "4263/4263 [==============================] - 1s 278us/step - loss: 0.3046 - acc: 0.8543\n",
      "Epoch 99/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3084 - acc: 0.8530\n",
      "Epoch 100/160\n",
      "4263/4263 [==============================] - 1s 280us/step - loss: 0.3086 - acc: 0.8543\n",
      "Epoch 101/160\n",
      "4263/4263 [==============================] - 1s 272us/step - loss: 0.3078 - acc: 0.8547\n",
      "Epoch 102/160\n",
      "4263/4263 [==============================] - 1s 279us/step - loss: 0.3051 - acc: 0.8534\n",
      "Epoch 103/160\n",
      "4263/4263 [==============================] - 1s 280us/step - loss: 0.3044 - acc: 0.8534\n",
      "Epoch 104/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.3079 - acc: 0.8532\n",
      "Epoch 105/160\n",
      "4263/4263 [==============================] - 1s 276us/step - loss: 0.3088 - acc: 0.8517\n",
      "Epoch 106/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.3037 - acc: 0.8563\n",
      "Epoch 107/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.3058 - acc: 0.8536\n",
      "Epoch 108/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.2991 - acc: 0.8555\n",
      "Epoch 109/160\n",
      "4263/4263 [==============================] - 1s 284us/step - loss: 0.3041 - acc: 0.8566\n",
      "Epoch 110/160\n",
      "4263/4263 [==============================] - 1s 279us/step - loss: 0.3031 - acc: 0.8578\n",
      "Epoch 111/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.2981 - acc: 0.8587\n",
      "Epoch 112/160\n",
      "4263/4263 [==============================] - 1s 276us/step - loss: 0.3006 - acc: 0.8596\n",
      "Epoch 113/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.2993 - acc: 0.8592\n",
      "Epoch 114/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.2978 - acc: 0.8577\n",
      "Epoch 115/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.2988 - acc: 0.8594\n",
      "Epoch 116/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3017 - acc: 0.8552\n",
      "Epoch 117/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.2996 - acc: 0.8568\n",
      "Epoch 118/160\n",
      "4263/4263 [==============================] - 1s 278us/step - loss: 0.2967 - acc: 0.8591\n",
      "Epoch 119/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.2914 - acc: 0.8598\n",
      "Epoch 120/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.2941 - acc: 0.8567\n",
      "Epoch 121/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.3016 - acc: 0.8584\n",
      "Epoch 122/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.3000 - acc: 0.8584\n",
      "Epoch 123/160\n",
      "4263/4263 [==============================] - 1s 288us/step - loss: 0.2915 - acc: 0.8603\n",
      "Epoch 124/160\n",
      "4263/4263 [==============================] - 1s 273us/step - loss: 0.2908 - acc: 0.8613\n",
      "Epoch 125/160\n",
      "4263/4263 [==============================] - 1s 270us/step - loss: 0.2957 - acc: 0.8591\n",
      "Epoch 126/160\n",
      "4263/4263 [==============================] - 1s 271us/step - loss: 0.2952 - acc: 0.8581\n",
      "Epoch 127/160\n",
      "4263/4263 [==============================] - 1s 270us/step - loss: 0.2906 - acc: 0.8619\n",
      "Epoch 128/160\n",
      "4263/4263 [==============================] - 1s 268us/step - loss: 0.2883 - acc: 0.8618\n",
      "Epoch 129/160\n",
      "4263/4263 [==============================] - 1s 270us/step - loss: 0.2916 - acc: 0.8593\n",
      "Epoch 130/160\n",
      "4263/4263 [==============================] - 1s 286us/step - loss: 0.2868 - acc: 0.8624\n",
      "Epoch 131/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.2859 - acc: 0.8614\n",
      "Epoch 132/160\n",
      "4263/4263 [==============================] - 1s 269us/step - loss: 0.2909 - acc: 0.8616\n",
      "Epoch 133/160\n",
      "4263/4263 [==============================] - 1s 277us/step - loss: 0.2932 - acc: 0.8618\n",
      "Epoch 134/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.2855 - acc: 0.8617\n",
      "Epoch 135/160\n",
      "4263/4263 [==============================] - 1s 274us/step - loss: 0.2921 - acc: 0.8597\n",
      "Epoch 136/160\n",
      "4263/4263 [==============================] - 1s 289us/step - loss: 0.2939 - acc: 0.8584\n",
      "Epoch 137/160\n",
      "4263/4263 [==============================] - 1s 281us/step - loss: 0.2871 - acc: 0.8617\n",
      "Epoch 138/160\n",
      "4263/4263 [==============================] - 1s 283us/step - loss: 0.2838 - acc: 0.8649\n",
      "Epoch 139/160\n",
      "4263/4263 [==============================] - 1s 268us/step - loss: 0.2844 - acc: 0.8627\n",
      "Epoch 140/160\n",
      "4263/4263 [==============================] - 1s 317us/step - loss: 0.2812 - acc: 0.8652\n",
      "Epoch 141/160\n",
      "4263/4263 [==============================] - 1s 300us/step - loss: 0.2907 - acc: 0.8580\n",
      "Epoch 142/160\n",
      "4263/4263 [==============================] - 1s 321us/step - loss: 0.2864 - acc: 0.8619\n",
      "Epoch 143/160\n",
      "4263/4263 [==============================] - 1s 287us/step - loss: 0.2797 - acc: 0.8662\n",
      "Epoch 144/160\n",
      "4263/4263 [==============================] - 1s 282us/step - loss: 0.2767 - acc: 0.8652\n",
      "Epoch 145/160\n",
      "4263/4263 [==============================] - 1s 322us/step - loss: 0.2948 - acc: 0.8621\n",
      "Epoch 146/160\n",
      "4263/4263 [==============================] - 2s 400us/step - loss: 0.2817 - acc: 0.8621\n",
      "Epoch 147/160\n",
      "4263/4263 [==============================] - 2s 382us/step - loss: 0.2869 - acc: 0.8629\n",
      "Epoch 148/160\n",
      "4263/4263 [==============================] - 1s 300us/step - loss: 0.2966 - acc: 0.8570\n",
      "Epoch 149/160\n",
      "4263/4263 [==============================] - 1s 293us/step - loss: 0.2801 - acc: 0.8652\n",
      "Epoch 150/160\n",
      "4263/4263 [==============================] - 1s 300us/step - loss: 0.2824 - acc: 0.8631\n",
      "Epoch 151/160\n",
      "4263/4263 [==============================] - 1s 303us/step - loss: 0.2755 - acc: 0.8665\n",
      "Epoch 152/160\n",
      "4263/4263 [==============================] - 1s 310us/step - loss: 0.2813 - acc: 0.8649\n",
      "Epoch 153/160\n",
      "4263/4263 [==============================] - 1s 316us/step - loss: 0.2805 - acc: 0.8655\n",
      "Epoch 154/160\n",
      "4263/4263 [==============================] - 1s 290us/step - loss: 0.2798 - acc: 0.8631\n",
      "Epoch 155/160\n",
      "4263/4263 [==============================] - 1s 296us/step - loss: 0.2758 - acc: 0.8677\n",
      "Epoch 156/160\n",
      "4263/4263 [==============================] - 1s 296us/step - loss: 0.2674 - acc: 0.8697\n",
      "Epoch 157/160\n",
      "4263/4263 [==============================] - 1s 293us/step - loss: 0.2720 - acc: 0.8676\n",
      "Epoch 158/160\n",
      "4263/4263 [==============================] - 1s 308us/step - loss: 0.2752 - acc: 0.8706\n",
      "Epoch 159/160\n",
      "4263/4263 [==============================] - 1s 310us/step - loss: 0.2811 - acc: 0.8659\n",
      "Epoch 160/160\n",
      "4263/4263 [==============================] - 1s 306us/step - loss: 0.2738 - acc: 0.8682\n",
      "1066/1066 [==============================] - 0s 250us/step\n",
      "4263/4263 [==============================] - 0s 66us/step\n",
      "\n",
      "acc: 82.86%\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "[[182  77   1  19]\n",
      " [ 30 549  21  10]\n",
      " [  5  23  68   0]\n",
      " [ 11  10   0  60]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.80      0.65      0.72       279\n",
      "      Normal       0.83      0.90      0.87       610\n",
      "        Slow       0.76      0.71      0.73        96\n",
      "   Very Fast       0.67      0.74      0.71        81\n",
      "\n",
      "    accuracy                           0.81      1066\n",
      "   macro avg       0.77      0.75      0.76      1066\n",
      "weighted avg       0.80      0.81      0.80      1066\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8058161350844277"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df=pd.read_csv('6mar.csv')\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
