{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "5275/5275 [==============================] - 4s 744us/step - loss: 0.4381 - acc: 0.7964\n",
      "Epoch 2/160\n",
      "5275/5275 [==============================] - 2s 287us/step - loss: 0.3955 - acc: 0.8112\n",
      "Epoch 3/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.3869 - acc: 0.8118\n",
      "Epoch 4/160\n",
      "5275/5275 [==============================] - 2s 301us/step - loss: 0.3783 - acc: 0.8180\n",
      "Epoch 5/160\n",
      "5275/5275 [==============================] - 2s 325us/step - loss: 0.3766 - acc: 0.8189\n",
      "Epoch 6/160\n",
      "5275/5275 [==============================] - 2s 288us/step - loss: 0.3739 - acc: 0.8200\n",
      "Epoch 7/160\n",
      "5275/5275 [==============================] - 1s 282us/step - loss: 0.3781 - acc: 0.8184\n",
      "Epoch 8/160\n",
      "5275/5275 [==============================] - 1s 276us/step - loss: 0.3698 - acc: 0.8239\n",
      "Epoch 9/160\n",
      "5275/5275 [==============================] - 2s 287us/step - loss: 0.3668 - acc: 0.8255\n",
      "Epoch 10/160\n",
      "5275/5275 [==============================] - 2s 286us/step - loss: 0.3683 - acc: 0.8244\n",
      "Epoch 11/160\n",
      "5275/5275 [==============================] - 1s 264us/step - loss: 0.3647 - acc: 0.8276\n",
      "Epoch 12/160\n",
      "5275/5275 [==============================] - 1s 275us/step - loss: 0.3686 - acc: 0.8249\n",
      "Epoch 13/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.3661 - acc: 0.8266\n",
      "Epoch 14/160\n",
      "5275/5275 [==============================] - 1s 252us/step - loss: 0.3616 - acc: 0.8261\n",
      "Epoch 15/160\n",
      "5275/5275 [==============================] - 1s 260us/step - loss: 0.3600 - acc: 0.8287\n",
      "Epoch 16/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.3603 - acc: 0.8305\n",
      "Epoch 17/160\n",
      "5275/5275 [==============================] - 1s 260us/step - loss: 0.3585 - acc: 0.8318\n",
      "Epoch 18/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.3567 - acc: 0.8320\n",
      "Epoch 19/160\n",
      "5275/5275 [==============================] - 1s 258us/step - loss: 0.3566 - acc: 0.8323\n",
      "Epoch 20/160\n",
      "5275/5275 [==============================] - 1s 252us/step - loss: 0.3553 - acc: 0.8319\n",
      "Epoch 21/160\n",
      "5275/5275 [==============================] - 1s 256us/step - loss: 0.3502 - acc: 0.8345\n",
      "Epoch 22/160\n",
      "5275/5275 [==============================] - 1s 254us/step - loss: 0.3492 - acc: 0.8363\n",
      "Epoch 23/160\n",
      "5275/5275 [==============================] - 1s 252us/step - loss: 0.3503 - acc: 0.8341\n",
      "Epoch 24/160\n",
      "5275/5275 [==============================] - 1s 251us/step - loss: 0.3474 - acc: 0.8369\n",
      "Epoch 25/160\n",
      "5275/5275 [==============================] - 1s 254us/step - loss: 0.3501 - acc: 0.8335\n",
      "Epoch 26/160\n",
      "5275/5275 [==============================] - 1s 255us/step - loss: 0.3459 - acc: 0.8369\n",
      "Epoch 27/160\n",
      "5275/5275 [==============================] - 1s 258us/step - loss: 0.3478 - acc: 0.8373\n",
      "Epoch 28/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.3468 - acc: 0.8343\n",
      "Epoch 29/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.3431 - acc: 0.8393\n",
      "Epoch 30/160\n",
      "5275/5275 [==============================] - 1s 254us/step - loss: 0.3451 - acc: 0.8368\n",
      "Epoch 31/160\n",
      "5275/5275 [==============================] - 1s 250us/step - loss: 0.3428 - acc: 0.8363\n",
      "Epoch 32/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.3424 - acc: 0.8373\n",
      "Epoch 33/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.3474 - acc: 0.8343\n",
      "Epoch 34/160\n",
      "5275/5275 [==============================] - 1s 254us/step - loss: 0.3423 - acc: 0.8395\n",
      "Epoch 35/160\n",
      "5275/5275 [==============================] - 1s 258us/step - loss: 0.3464 - acc: 0.8365\n",
      "Epoch 36/160\n",
      "5275/5275 [==============================] - 1s 259us/step - loss: 0.3453 - acc: 0.8357\n",
      "Epoch 37/160\n",
      "5275/5275 [==============================] - 1s 263us/step - loss: 0.3418 - acc: 0.8377\n",
      "Epoch 38/160\n",
      "5275/5275 [==============================] - 1s 258us/step - loss: 0.3425 - acc: 0.8388\n",
      "Epoch 39/160\n",
      "5275/5275 [==============================] - 1s 256us/step - loss: 0.3416 - acc: 0.8378\n",
      "Epoch 40/160\n",
      "5275/5275 [==============================] - 1s 257us/step - loss: 0.3382 - acc: 0.8398\n",
      "Epoch 41/160\n",
      "5275/5275 [==============================] - 1s 255us/step - loss: 0.3396 - acc: 0.8395\n",
      "Epoch 42/160\n",
      "5275/5275 [==============================] - 1s 258us/step - loss: 0.3365 - acc: 0.8416\n",
      "Epoch 43/160\n",
      "5275/5275 [==============================] - 1s 255us/step - loss: 0.3368 - acc: 0.8391\n",
      "Epoch 44/160\n",
      "5275/5275 [==============================] - 1s 257us/step - loss: 0.3404 - acc: 0.8391\n",
      "Epoch 45/160\n",
      "5275/5275 [==============================] - 2s 300us/step - loss: 0.3360 - acc: 0.8421\n",
      "Epoch 46/160\n",
      "5275/5275 [==============================] - 2s 310us/step - loss: 0.3331 - acc: 0.8415\n",
      "Epoch 47/160\n",
      "5275/5275 [==============================] - 1s 280us/step - loss: 0.3345 - acc: 0.8414\n",
      "Epoch 48/160\n",
      "5275/5275 [==============================] - 1s 257us/step - loss: 0.3341 - acc: 0.8446\n",
      "Epoch 49/160\n",
      "5275/5275 [==============================] - 1s 258us/step - loss: 0.3350 - acc: 0.8405\n",
      "Epoch 50/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3351 - acc: 0.8398\n",
      "Epoch 51/160\n",
      "5275/5275 [==============================] - 1s 251us/step - loss: 0.3389 - acc: 0.8400\n",
      "Epoch 52/160\n",
      "5275/5275 [==============================] - 1s 247us/step - loss: 0.3315 - acc: 0.8450\n",
      "Epoch 53/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3295 - acc: 0.8473\n",
      "Epoch 54/160\n",
      "5275/5275 [==============================] - 1s 246us/step - loss: 0.3316 - acc: 0.8453\n",
      "Epoch 55/160\n",
      "5275/5275 [==============================] - 1s 246us/step - loss: 0.3300 - acc: 0.8441\n",
      "Epoch 56/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3332 - acc: 0.8440\n",
      "Epoch 57/160\n",
      "5275/5275 [==============================] - 1s 247us/step - loss: 0.3288 - acc: 0.8465\n",
      "Epoch 58/160\n",
      "5275/5275 [==============================] - 1s 250us/step - loss: 0.3279 - acc: 0.8497\n",
      "Epoch 59/160\n",
      "5275/5275 [==============================] - 1s 252us/step - loss: 0.3294 - acc: 0.8456\n",
      "Epoch 60/160\n",
      "5275/5275 [==============================] - 1s 250us/step - loss: 0.3288 - acc: 0.8456\n",
      "Epoch 61/160\n",
      "5275/5275 [==============================] - 1s 244us/step - loss: 0.3304 - acc: 0.8463\n",
      "Epoch 62/160\n",
      "5275/5275 [==============================] - 1s 243us/step - loss: 0.3296 - acc: 0.8468\n",
      "Epoch 63/160\n",
      "5275/5275 [==============================] - 1s 249us/step - loss: 0.3275 - acc: 0.8461\n",
      "Epoch 64/160\n",
      "5275/5275 [==============================] - 1s 247us/step - loss: 0.3254 - acc: 0.8473\n",
      "Epoch 65/160\n",
      "5275/5275 [==============================] - 1s 247us/step - loss: 0.3284 - acc: 0.8455\n",
      "Epoch 66/160\n",
      "5275/5275 [==============================] - 1s 247us/step - loss: 0.3261 - acc: 0.8476\n",
      "Epoch 67/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3279 - acc: 0.8478\n",
      "Epoch 68/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3277 - acc: 0.8441\n",
      "Epoch 69/160\n",
      "5275/5275 [==============================] - 1s 243us/step - loss: 0.3232 - acc: 0.8496\n",
      "Epoch 70/160\n",
      "5275/5275 [==============================] - 1s 251us/step - loss: 0.3246 - acc: 0.8480\n",
      "Epoch 71/160\n",
      "5275/5275 [==============================] - 1s 252us/step - loss: 0.3271 - acc: 0.8460\n",
      "Epoch 72/160\n",
      "5275/5275 [==============================] - 1s 270us/step - loss: 0.3221 - acc: 0.8491\n",
      "Epoch 73/160\n",
      "5275/5275 [==============================] - 1s 250us/step - loss: 0.3239 - acc: 0.8480\n",
      "Epoch 74/160\n",
      "5275/5275 [==============================] - 1s 264us/step - loss: 0.3256 - acc: 0.8464\n",
      "Epoch 75/160\n",
      "5275/5275 [==============================] - 1s 270us/step - loss: 0.3236 - acc: 0.8480\n",
      "Epoch 76/160\n",
      "5275/5275 [==============================] - 1s 250us/step - loss: 0.3229 - acc: 0.8480\n",
      "Epoch 77/160\n",
      "5275/5275 [==============================] - 1s 262us/step - loss: 0.3200 - acc: 0.8495\n",
      "Epoch 78/160\n",
      "5275/5275 [==============================] - 2s 350us/step - loss: 0.3235 - acc: 0.8477\n",
      "Epoch 79/160\n",
      "5275/5275 [==============================] - 2s 310us/step - loss: 0.3231 - acc: 0.8482\n",
      "Epoch 80/160\n",
      "5275/5275 [==============================] - 1s 264us/step - loss: 0.3184 - acc: 0.8514\n",
      "Epoch 81/160\n",
      "5275/5275 [==============================] - 2s 303us/step - loss: 0.3237 - acc: 0.8494\n",
      "Epoch 82/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5275/5275 [==============================] - 2s 295us/step - loss: 0.3208 - acc: 0.8491\n",
      "Epoch 83/160\n",
      "5275/5275 [==============================] - 1s 279us/step - loss: 0.3193 - acc: 0.8508\n",
      "Epoch 84/160\n",
      "5275/5275 [==============================] - 2s 287us/step - loss: 0.3204 - acc: 0.8492\n",
      "Epoch 85/160\n",
      "5275/5275 [==============================] - 2s 293us/step - loss: 0.3167 - acc: 0.8524\n",
      "Epoch 86/160\n",
      "5275/5275 [==============================] - 1s 245us/step - loss: 0.3172 - acc: 0.8509\n",
      "Epoch 87/160\n",
      "5275/5275 [==============================] - 1s 246us/step - loss: 0.3174 - acc: 0.8489\n",
      "Epoch 88/160\n",
      "5275/5275 [==============================] - 1s 242us/step - loss: 0.3175 - acc: 0.8500\n",
      "Epoch 89/160\n",
      "5275/5275 [==============================] - 1s 242us/step - loss: 0.3187 - acc: 0.8509\n",
      "Epoch 90/160\n",
      "5275/5275 [==============================] - 1s 243us/step - loss: 0.3186 - acc: 0.8522\n",
      "Epoch 91/160\n",
      "5275/5275 [==============================] - 1s 246us/step - loss: 0.3232 - acc: 0.8476\n",
      "Epoch 92/160\n",
      "5275/5275 [==============================] - 2s 310us/step - loss: 0.3173 - acc: 0.8496\n",
      "Epoch 93/160\n",
      "5275/5275 [==============================] - 1s 245us/step - loss: 0.3125 - acc: 0.8512\n",
      "Epoch 94/160\n",
      "5275/5275 [==============================] - 1s 244us/step - loss: 0.3177 - acc: 0.8494\n",
      "Epoch 95/160\n",
      "5275/5275 [==============================] - 1s 256us/step - loss: 0.3147 - acc: 0.8537\n",
      "Epoch 96/160\n",
      "5275/5275 [==============================] - 1s 264us/step - loss: 0.3172 - acc: 0.8517\n",
      "Epoch 97/160\n",
      "5275/5275 [==============================] - 1s 260us/step - loss: 0.3118 - acc: 0.8552\n",
      "Epoch 98/160\n",
      "5275/5275 [==============================] - 1s 262us/step - loss: 0.3116 - acc: 0.8535\n",
      "Epoch 99/160\n",
      "5275/5275 [==============================] - 2s 291us/step - loss: 0.3121 - acc: 0.8516\n",
      "Epoch 100/160\n",
      "5275/5275 [==============================] - 1s 284us/step - loss: 0.3174 - acc: 0.8512\n",
      "Epoch 101/160\n",
      "5275/5275 [==============================] - 2s 304us/step - loss: 0.3147 - acc: 0.8534\n",
      "Epoch 102/160\n",
      "5275/5275 [==============================] - 1s 275us/step - loss: 0.3124 - acc: 0.8541\n",
      "Epoch 103/160\n",
      "5275/5275 [==============================] - 1s 263us/step - loss: 0.3084 - acc: 0.8547\n",
      "Epoch 104/160\n",
      "5275/5275 [==============================] - 1s 271us/step - loss: 0.3099 - acc: 0.8528\n",
      "Epoch 105/160\n",
      "5275/5275 [==============================] - 1s 275us/step - loss: 0.3103 - acc: 0.8536\n",
      "Epoch 106/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.3095 - acc: 0.8540\n",
      "Epoch 107/160\n",
      "5275/5275 [==============================] - 1s 252us/step - loss: 0.3151 - acc: 0.8530\n",
      "Epoch 108/160\n",
      "5275/5275 [==============================] - 1s 254us/step - loss: 0.3207 - acc: 0.8499\n",
      "Epoch 109/160\n",
      "5275/5275 [==============================] - 1s 257us/step - loss: 0.3134 - acc: 0.8534\n",
      "Epoch 110/160\n",
      "5275/5275 [==============================] - 1s 252us/step - loss: 0.3077 - acc: 0.8548\n",
      "Epoch 111/160\n",
      "5275/5275 [==============================] - 1s 247us/step - loss: 0.3063 - acc: 0.8576\n",
      "Epoch 112/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3143 - acc: 0.8555\n",
      "Epoch 113/160\n",
      "5275/5275 [==============================] - 1s 243us/step - loss: 0.3114 - acc: 0.8541\n",
      "Epoch 114/160\n",
      "5275/5275 [==============================] - 1s 250us/step - loss: 0.3034 - acc: 0.8574\n",
      "Epoch 115/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.3064 - acc: 0.8551\n",
      "Epoch 116/160\n",
      "5275/5275 [==============================] - 1s 269us/step - loss: 0.3069 - acc: 0.8570\n",
      "Epoch 117/160\n",
      "5275/5275 [==============================] - 2s 291us/step - loss: 0.3056 - acc: 0.8582\n",
      "Epoch 118/160\n",
      "5275/5275 [==============================] - 1s 257us/step - loss: 0.3048 - acc: 0.8584\n",
      "Epoch 119/160\n",
      "5275/5275 [==============================] - 1s 251us/step - loss: 0.3042 - acc: 0.8565\n",
      "Epoch 120/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3151 - acc: 0.8544\n",
      "Epoch 121/160\n",
      "5275/5275 [==============================] - 1s 246us/step - loss: 0.3081 - acc: 0.8545\n",
      "Epoch 122/160\n",
      "5275/5275 [==============================] - 1s 250us/step - loss: 0.3057 - acc: 0.8555\n",
      "Epoch 123/160\n",
      "5275/5275 [==============================] - 1s 247us/step - loss: 0.3035 - acc: 0.8577\n",
      "Epoch 124/160\n",
      "5275/5275 [==============================] - 1s 251us/step - loss: 0.2986 - acc: 0.8595\n",
      "Epoch 125/160\n",
      "5275/5275 [==============================] - 1s 249us/step - loss: 0.3046 - acc: 0.8557\n",
      "Epoch 126/160\n",
      "5275/5275 [==============================] - 1s 244us/step - loss: 0.3016 - acc: 0.8571\n",
      "Epoch 127/160\n",
      "5275/5275 [==============================] - 1s 248us/step - loss: 0.3011 - acc: 0.8578\n",
      "Epoch 128/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.3088 - acc: 0.8551\n",
      "Epoch 129/160\n",
      "5275/5275 [==============================] - 2s 294us/step - loss: 0.3008 - acc: 0.8561\n",
      "Epoch 130/160\n",
      "5275/5275 [==============================] - 1s 274us/step - loss: 0.3015 - acc: 0.8581\n",
      "Epoch 131/160\n",
      "5275/5275 [==============================] - 1s 265us/step - loss: 0.3000 - acc: 0.8589\n",
      "Epoch 132/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.3047 - acc: 0.8578\n",
      "Epoch 133/160\n",
      "5275/5275 [==============================] - 2s 293us/step - loss: 0.2989 - acc: 0.8592\n",
      "Epoch 134/160\n",
      "5275/5275 [==============================] - 1s 258us/step - loss: 0.2973 - acc: 0.8606\n",
      "Epoch 135/160\n",
      "5275/5275 [==============================] - 1s 284us/step - loss: 0.2969 - acc: 0.8592\n",
      "Epoch 136/160\n",
      "5275/5275 [==============================] - 1s 282us/step - loss: 0.3052 - acc: 0.8563\n",
      "Epoch 137/160\n",
      "5275/5275 [==============================] - 1s 259us/step - loss: 0.2986 - acc: 0.8590\n",
      "Epoch 138/160\n",
      "5275/5275 [==============================] - 1s 273us/step - loss: 0.2977 - acc: 0.8598\n",
      "Epoch 139/160\n",
      "5275/5275 [==============================] - 1s 263us/step - loss: 0.3019 - acc: 0.8562\n",
      "Epoch 140/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.3002 - acc: 0.8589\n",
      "Epoch 141/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.2929 - acc: 0.8589\n",
      "Epoch 142/160\n",
      "5275/5275 [==============================] - 1s 263us/step - loss: 0.2945 - acc: 0.8601\n",
      "Epoch 143/160\n",
      "5275/5275 [==============================] - 1s 262us/step - loss: 0.3101 - acc: 0.8553\n",
      "Epoch 144/160\n",
      "5275/5275 [==============================] - 1s 265us/step - loss: 0.2944 - acc: 0.8609\n",
      "Epoch 145/160\n",
      "5275/5275 [==============================] - 1s 282us/step - loss: 0.2897 - acc: 0.8618\n",
      "Epoch 146/160\n",
      "5275/5275 [==============================] - 1s 284us/step - loss: 0.2913 - acc: 0.8613\n",
      "Epoch 147/160\n",
      "5275/5275 [==============================] - 2s 292us/step - loss: 0.2974 - acc: 0.8585\n",
      "Epoch 148/160\n",
      "5275/5275 [==============================] - 2s 287us/step - loss: 0.2935 - acc: 0.8598\n",
      "Epoch 149/160\n",
      "5275/5275 [==============================] - 1s 278us/step - loss: 0.2946 - acc: 0.8594\n",
      "Epoch 150/160\n",
      "5275/5275 [==============================] - 1s 267us/step - loss: 0.2953 - acc: 0.8609\n",
      "Epoch 151/160\n",
      "5275/5275 [==============================] - 1s 262us/step - loss: 0.2903 - acc: 0.8623\n",
      "Epoch 152/160\n",
      "5275/5275 [==============================] - 1s 265us/step - loss: 0.2876 - acc: 0.8634\n",
      "Epoch 153/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.2994 - acc: 0.8583\n",
      "Epoch 154/160\n",
      "5275/5275 [==============================] - 1s 262us/step - loss: 0.2879 - acc: 0.8636\n",
      "Epoch 155/160\n",
      "5275/5275 [==============================] - 1s 259us/step - loss: 0.2916 - acc: 0.8609\n",
      "Epoch 156/160\n",
      "5275/5275 [==============================] - 1s 253us/step - loss: 0.2909 - acc: 0.8622\n",
      "Epoch 157/160\n",
      "5275/5275 [==============================] - 1s 255us/step - loss: 0.2886 - acc: 0.8624\n",
      "Epoch 158/160\n",
      "5275/5275 [==============================] - 1s 261us/step - loss: 0.3006 - acc: 0.8577\n",
      "Epoch 159/160\n",
      "5275/5275 [==============================] - 1s 263us/step - loss: 0.2869 - acc: 0.8642\n",
      "Epoch 160/160\n",
      "5275/5275 [==============================] - 1s 262us/step - loss: 0.2827 - acc: 0.8682\n",
      "54/54 [==============================] - 1s 12ms/step\n",
      "5275/5275 [==============================] - 1s 103us/step\n",
      "\n",
      "acc: 91.67%\n",
      "[0.01424464 0.878948   0.10507032 0.00173701]\n",
      "0 1 0 0\n",
      "[5.6257197e-03 9.4619262e-01 4.8132747e-02 4.8808019e-05]\n",
      "0 1 0 0\n",
      "[1.1476751e-02 9.8229355e-01 6.0416376e-03 1.8815327e-04]\n",
      "0 1 0 0\n",
      "[1.0455442e-01 8.9349490e-01 1.9220572e-03 2.8649056e-05]\n",
      "0 1 0 0\n",
      "[0.31764507 0.5900035  0.00238092 0.08997048]\n",
      "0 1 0 0\n",
      "[0.398445   0.5968111  0.00208069 0.00266317]\n",
      "0 1 0 0\n",
      "[1.7480473e-01 1.1413444e-02 1.7627639e-06 8.1378007e-01]\n",
      "0 0 0 1\n",
      "[3.0124328e-01 6.9240373e-01 5.8127465e-03 5.4025807e-04]\n",
      "0 1 0 0\n",
      "[1.00169982e-05 1.12958394e-01 8.87031019e-01 5.62528669e-07]\n",
      "0 0 1 0\n",
      "[1.4450845e-01 7.6537454e-01 8.9712627e-02 4.0450445e-04]\n",
      "0 1 0 0\n",
      "[5.3773654e-01 3.8673708e-01 7.5453013e-02 7.3356234e-05]\n",
      "1 0 0 0\n",
      "[1.9904061e-01 7.9147094e-01 9.2942296e-03 1.9431236e-04]\n",
      "0 1 0 0\n",
      "[1.5542288e-01 1.7025009e-02 2.0827927e-06 8.2754999e-01]\n",
      "0 0 0 1\n",
      "[1.5458441e-01 8.3674133e-01 8.6088264e-03 6.5441927e-05]\n",
      "0 1 0 0\n",
      "[1.8036899e-01 8.1963015e-01 5.7917021e-07 2.6353058e-07]\n",
      "0 1 0 0\n",
      "[0.00973773 0.9573878  0.01456676 0.01830761]\n",
      "0 1 0 0\n",
      "[1.1768423e-05 9.9554622e-01 4.4419584e-03 1.0710924e-08]\n",
      "0 1 0 0\n",
      "[4.6120938e-03 9.9518102e-01 1.6082611e-04 4.6079997e-05]\n",
      "0 1 0 0\n",
      "[3.3482815e-05 9.9408990e-01 5.8765323e-03 1.4441638e-09]\n",
      "0 1 0 0\n",
      "[4.4340673e-03 4.6983594e-01 5.2568603e-01 4.3971824e-05]\n",
      "0 0 1 0\n",
      "[0.08198822 0.87800235 0.01910981 0.02089958]\n",
      "0 1 0 0\n",
      "[0.31212324 0.64415586 0.0323039  0.01141696]\n",
      "0 1 0 0\n",
      "[0.21462163 0.7600905  0.00390446 0.0213834 ]\n",
      "0 1 0 0\n",
      "[0.69304496 0.27981466 0.00133435 0.02580602]\n",
      "1 0 0 0\n",
      "[1.0485950e-01 8.6816859e-01 2.6506042e-02 4.6594589e-04]\n",
      "0 1 0 0\n",
      "[7.73988903e-01 2.14844346e-01 1.05100473e-04 1.10616265e-02]\n",
      "1 0 0 0\n",
      "[1.6453950e-02 6.6617662e-01 3.1726697e-01 1.0244612e-04]\n",
      "0 1 0 0\n",
      "[5.7344556e-02 8.8426501e-01 5.8223177e-02 1.6726875e-04]\n",
      "0 1 0 0\n",
      "[9.1165632e-02 8.9827293e-01 1.0497249e-02 6.4152839e-05]\n",
      "0 1 0 0\n",
      "[0.3808134  0.6141612  0.00321441 0.00181098]\n",
      "0 1 0 0\n",
      "[6.0168600e-01 3.9254326e-01 9.2286045e-06 5.7615037e-03]\n",
      "1 0 0 0\n",
      "[2.1391751e-01 7.6742250e-01 1.8540045e-02 1.1997141e-04]\n",
      "0 1 0 0\n",
      "[6.6743763e-03 1.0651549e-03 4.0375095e-13 9.9226052e-01]\n",
      "0 0 0 1\n",
      "[1.4421725e-01 8.5236597e-01 3.3837941e-03 3.3043965e-05]\n",
      "0 1 0 0\n",
      "[2.9929103e-02 9.2065585e-01 4.9359184e-02 5.5898348e-05]\n",
      "0 1 0 0\n",
      "[1.4816591e-01 8.4725869e-01 4.4851019e-03 9.0423346e-05]\n",
      "0 1 0 0\n",
      "[0.659682   0.12879954 0.00098047 0.210538  ]\n",
      "1 0 0 0\n",
      "[1.7271627e-01 8.2214993e-01 5.0370540e-03 9.6740252e-05]\n",
      "0 1 0 0\n",
      "[3.7853396e-01 5.8301568e-01 3.8338561e-02 1.1185816e-04]\n",
      "0 1 0 0\n",
      "[0.02054006 0.9543576  0.02323084 0.00187144]\n",
      "0 1 0 0\n",
      "[1.5261278e-02 9.8437762e-01 3.1289359e-04 4.8227947e-05]\n",
      "0 1 0 0\n",
      "[1.34411216e-01 8.55647922e-01 9.83197708e-03 1.08860884e-04]\n",
      "0 1 0 0\n",
      "[0.562015   0.34502715 0.00303005 0.08992784]\n",
      "1 0 0 0\n",
      "[5.49876178e-03 8.76092434e-01 1.18349575e-01 5.92138276e-05]\n",
      "0 1 0 0\n",
      "[0.10710374 0.63581955 0.2564206  0.0006561 ]\n",
      "0 1 0 0\n",
      "[1.1582952e-01 8.8415730e-01 6.7553992e-06 6.3958955e-06]\n",
      "0 1 0 0\n",
      "[6.54535880e-03 9.79570985e-01 1.38722658e-02 1.13158485e-05]\n",
      "0 1 0 0\n",
      "[0.79565626 0.16000907 0.00100827 0.04332644]\n",
      "1 0 0 0\n",
      "[2.3214076e-02 9.7089493e-01 5.8528474e-03 3.8242906e-05]\n",
      "0 1 0 0\n",
      "[0.58853817 0.40766066 0.00122441 0.00257673]\n",
      "1 0 0 0\n",
      "[4.5200437e-03 8.1911534e-01 1.7633168e-01 3.2948181e-05]\n",
      "0 1 0 0\n",
      "[0.003821   0.9314439  0.06200879 0.00272631]\n",
      "0 1 0 0\n",
      "[5.1758146e-01 4.2456128e-02 9.7785560e-05 4.3986467e-01]\n",
      "1 0 0 0\n",
      "[1.12290755e-01 8.86682987e-01 9.94683593e-04 3.16468140e-05]\n",
      "0 1 0 0\n",
      "[[ 5  3  0  0]\n",
      " [ 1 36  1  0]\n",
      " [ 1  0  2  0]\n",
      " [ 2  0  0  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.56      0.62      0.59         8\n",
      "      Normal       0.92      0.95      0.94        38\n",
      "        Slow       0.67      0.67      0.67         3\n",
      "   Very Fast       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.79      0.71      0.73        54\n",
      "weighted avg       0.86      0.85      0.85        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df=pd.read_csv('6mar.csv')\n",
    "\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.01,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    print(x)\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n",
    "model.save('model/speed_detect.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3    4\n",
      "1323   1.0  3.085571  0.005212  0.130302  4.0\n",
      "1839   0.0  5.172046  0.022128  0.243410  4.0\n",
      "798    0.0  2.545230  0.013541  0.379138  4.0\n",
      "3855   1.0  4.259374  0.032495  0.019497  2.0\n",
      "4552   3.0  2.509777  0.006388  0.076659  4.0\n",
      "856    0.0  2.076659  0.005213  0.109464  4.0\n",
      "2333   0.0  1.106034  0.000000  0.005952  2.0\n",
      "2499   0.0  4.495125  0.011891  0.089184  2.0\n",
      "5010  13.0  3.579910  0.000000  0.546133  4.0\n",
      "4379   0.0  8.011461  0.031487  0.018892  4.0\n",
      "4733   0.0  3.654303  0.000000  0.000000  1.0\n",
      "655    0.0  3.588144  0.011785  0.129637  3.0\n",
      "2101   0.0  0.726065  0.000000  0.013668  2.0\n",
      "893    1.0  4.956470  0.011841  0.082884  1.0\n",
      "373    0.0  3.289301  0.016111  0.281948  1.0\n",
      "297    0.0  3.499739  0.012103  0.102880  4.0\n",
      "3817   4.0  0.929351  0.022881  0.011440  2.0\n",
      "1808   0.0  2.795294  0.012137  0.121367  4.0\n",
      "4392   4.0  5.524710  0.019157  0.287361  4.0\n",
      "3585   7.0  6.477202  0.019052  0.152418  4.0\n",
      "240    0.0  4.181343  0.006051  0.127079  4.0\n",
      "4650   0.0  4.177690  0.000000  0.068097  4.0\n",
      "2951   0.0  3.072988  0.007079  0.028314  4.0\n",
      "2860   0.0  2.580487  0.000000  0.040184  3.0\n",
      "465    2.0  3.657031  0.016694  0.100161  2.0\n",
      "3685   0.0  0.355616  0.000000  0.061995  4.0\n",
      "4316   0.0  8.378208  0.013982  0.027965  2.0\n",
      "84     1.0  2.985339  0.018774  0.093868  3.0\n",
      "1498   1.0  4.544012  0.018051  0.090256  2.0\n",
      "803    0.0  2.144665  0.005977  0.089654  4.0\n",
      "2476   0.0  2.005344  0.010818  0.010818  1.0\n",
      "8      0.0  3.443288  0.017508  0.064197  3.0\n",
      "5057   2.0  0.948848  0.000000  0.006341  1.0\n",
      "1738   0.0  3.464186  0.024499  0.165370  3.0\n",
      "721    0.0  5.410257  0.012493  0.318566  3.0\n",
      "1782   0.0  4.015828  0.012094  0.187452  3.0\n",
      "5035   0.0  2.149982  0.000000  0.006749  1.0\n",
      "2892   0.0  4.079779  0.018644  0.136719  3.0\n",
      "4470   0.0  4.600205  0.006543  0.019629  1.0\n",
      "5040   2.0  5.213526  0.000000  0.000000  1.0\n",
      "810    0.0  2.597716  0.011873  0.142473  4.0\n",
      "2847   2.0  1.979790  0.011483  0.200960  3.0\n",
      "3094   0.0  3.259883  0.000000  0.045425  3.0\n",
      "2572   2.0  6.226260  0.024604  0.043057  2.0\n",
      "5182   7.0  5.270924  0.000000  0.101373  4.0\n",
      "4856   5.0  2.116246  0.000000  0.024726  2.0\n",
      "33     3.0  4.290753  0.018629  0.043467  3.0\n",
      "4301   0.0  1.882212  0.006472  0.038833  2.0\n",
      "711    1.0  3.758847  0.024635  0.172443  3.0\n",
      "3662   2.0  2.135021  0.021156  0.042312  4.0\n",
      "1129   0.0  3.935685  0.015849  0.388311  3.0\n",
      "848    1.0  3.654100  0.018396  0.085850  4.0\n",
      "2284   0.0  1.205762  0.000000  0.036062  3.0\n",
      "1630   1.0  5.376115  0.011191  0.167868  2.0\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading Keras model and Flask starting server...please wait until server has fully started\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "def init():\n",
    "    global model,graph\n",
    "    # load the pre-trained Keras model\n",
    "    model = load_model('model/speed_detect.h5')\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "def getParameters():\n",
    "    parameters = []\n",
    "    parameters.append(flask.request.args.get('Wifi_density'))\n",
    "    parameters.append(flask.request.args.get('Intersection_density'))\n",
    "    parameters.append(flask.request.args.get('Honk_duration'))\n",
    "    parameters.append(flask.request.args.get('Timelevel'))\n",
    "    parameters.append(flask.request.args.get('Road_surface'))\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def sendResponse(responseObj):\n",
    "    response = flask.jsonify(responseObj)\n",
    "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
    "    response.headers.add('Access-Control-Allow-Methods', 'GET')\n",
    "    response.headers.add('Access-Control-Allow-Headers', 'accept,content-type,Origin,X-Requested-With,Content-Type,access_token,Accept,Authorization,source')\n",
    "    response.headers.add('Access-Control-Allow-Credentials', True)\n",
    "    return response\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"GET\"])\n",
    "def predict():\n",
    "    \n",
    "    parameters = getParameters()\n",
    "    inputFeature = np.asarray(parameters).reshape(1,5)\n",
    "    with graph.as_default():\n",
    "        print(inputFeature)\n",
    "        raw_prediction = model.predict(inputFeature)\n",
    "    print(raw_prediction)\n",
    "   \n",
    "   # k_1=round(raw_prediction[0])\n",
    "    k_1_i=int(raw_prediction[0][0])\n",
    "        #k_1_s=str(k_1_i)\n",
    "    #k_2=round(raw_prediction[1])\n",
    "    k_2_i=int(raw_prediction[0][1])\n",
    "        #k_2_s=str(k_2_i)\n",
    "    #k_3=round(raw_prediction[2])\n",
    "    k_3_i=int(raw_prediction[0][2])\n",
    "        #k_3_s=str(k_3_i)\n",
    "   # k_4=round(raw_prediction[3])\n",
    "    k_4_i=int(raw_prediction[0][3])\n",
    "        #k_4_s=str(k_4_i)\n",
    "        \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        prediction='Bad Data'\n",
    "        \n",
    "    else:\n",
    "        if k_1_i==1:\n",
    "            prediction='Fast'\n",
    "        if k_2_i==1:\n",
    "            prediction='Normal'\n",
    "        if k_3_i==1:\n",
    "            prediction='Slow'\n",
    "        if k_4_i==1:\n",
    "            prediction='Very Fast'\n",
    "    print(prediction)\n",
    "        \n",
    "    return sendResponse({prediction})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print((\"* Loading Keras model and Flask starting server...\"\n",
    "\"please wait until server has fully started\"))\n",
    "    init()\n",
    "    app.run(threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading Keras model and Flask starting server...please wait until server has fully started\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28641    0.0216159  1.         3.         4.77619068]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/May/2019 15:56:01] \"\u001b[37mGET /predict?Wifi_density=0.28641&Intersection_density=0.0216159&Honk_duration=1&Timelevel=3&Road_surface=4.776190676 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.9584955  0.04150444 0.        ]]\n",
      "Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [28/May/2019 15:56:41] \"\u001b[37mGET /predict?Wifi_density=0.28641&Intersection_density=0.0216159&Honk_duration=1&Timelevel=3&Road_surface=4.776190676 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28641    0.0216159  1.         3.         4.77619068]]\n",
      "[[0.         0.9584955  0.04150444 0.        ]]\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from json import dumps, loads, JSONEncoder, JSONDecoder\n",
    "import pickle\n",
    "\n",
    "app = flask.Flask(__name__)\n",
    "def init():\n",
    "    global model,graph\n",
    "    # load the pre-trained Keras model\n",
    "    model = load_model('model/speed_detect.h5')\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "def getParameters():\n",
    "    parameters = []\n",
    "    parameters.append(flask.request.args.get('Wifi_density'))\n",
    "    parameters.append(flask.request.args.get('Intersection_density'))\n",
    "    parameters.append(flask.request.args.get('Honk_duration'))\n",
    "    parameters.append(flask.request.args.get('Timelevel'))\n",
    "    parameters.append(flask.request.args.get('Road_surface'))\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def sendResponse(responseObj):\n",
    "    response = flask.jsonify(responseObj)\n",
    "    response.headers.add('Access-Control-Allow-Origin', '*')\n",
    "    response.headers.add('Access-Control-Allow-Methods', 'GET')\n",
    "    response.headers.add('Access-Control-Allow-Headers', 'accept,content-type,Origin,X-Requested-With,Content-Type,access_token,Accept,Authorization,source')\n",
    "    response.headers.add('Access-Control-Allow-Credentials', True)\n",
    "    return response\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"GET\"])\n",
    "def predict():\n",
    "    count=0\n",
    "    parameters = getParameters()\n",
    "    for x in parameters:\n",
    "        if count==0 or count==1 or count==4:\n",
    "            parameters[count]=float(x)\n",
    "        else:\n",
    "            parameters[count]=int(x)\n",
    "        count=count+1\n",
    "    inputFeature = np.asarray(parameters).reshape(1,5)\n",
    "    with graph.as_default():\n",
    "        print(inputFeature)\n",
    "        raw_prediction = model.predict(inputFeature)\n",
    "    print(raw_prediction)\n",
    "   \n",
    "    k_1=round(raw_prediction[0][0])\n",
    "    k_1_i=int(k_1)\n",
    "        #k_1_s=str(k_1_i)\n",
    "    k_2=round(raw_prediction[0][1])\n",
    "    k_2_i=int(k_2)\n",
    "        #k_2_s=str(k_2_i)\n",
    "    k_3=round(raw_prediction[0][2])\n",
    "    k_3_i=int(k_3)\n",
    "        #k_3_s=str(k_3_i)\n",
    "    k_4=round(raw_prediction[0][3])\n",
    "    k_4_i=int(k_4)\n",
    "        #k_4_s=str(k_4_i)\n",
    "        \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        prediction='Bad Data'\n",
    "        \n",
    "    else:\n",
    "        if k_1_i==1:\n",
    "            prediction='Fast'\n",
    "        if k_2_i==1:\n",
    "            prediction='Normal'\n",
    "        if k_3_i==1:\n",
    "            prediction='Slow'\n",
    "        if k_4_i==1:\n",
    "            prediction='Very Fast'\n",
    "    print(prediction)\n",
    "        \n",
    "    return sendResponse(prediction)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print((\"* Loading Keras model and Flask starting server...\"\n",
    "\"please wait until server has fully started\"))\n",
    "    init()\n",
    "    app.run(threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
