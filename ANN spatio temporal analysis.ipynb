{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "WARNING:tensorflow:From /home/abhijit/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/abhijit/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/160\n",
      "582/582 [==============================] - 1s 1ms/step - loss: 0.4966 - acc: 0.7736\n",
      "Epoch 2/160\n",
      "582/582 [==============================] - 0s 299us/step - loss: 0.4754 - acc: 0.7788\n",
      "Epoch 3/160\n",
      " 50/582 [=>............................] - ETA: 0s - loss: 0.4440 - acc: 0.7950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/582 [==============================] - 0s 319us/step - loss: 0.4541 - acc: 0.7904\n",
      "Epoch 4/160\n",
      "582/582 [==============================] - 0s 338us/step - loss: 0.4344 - acc: 0.7865\n",
      "Epoch 5/160\n",
      "582/582 [==============================] - 0s 292us/step - loss: 0.4379 - acc: 0.7818\n",
      "Epoch 6/160\n",
      "582/582 [==============================] - 0s 310us/step - loss: 0.4282 - acc: 0.7895\n",
      "Epoch 7/160\n",
      "582/582 [==============================] - 0s 298us/step - loss: 0.4297 - acc: 0.7771\n",
      "Epoch 8/160\n",
      "582/582 [==============================] - 0s 299us/step - loss: 0.4178 - acc: 0.7796\n",
      "Epoch 9/160\n",
      "582/582 [==============================] - 0s 281us/step - loss: 0.4093 - acc: 0.7942\n",
      "Epoch 10/160\n",
      "582/582 [==============================] - 0s 284us/step - loss: 0.4142 - acc: 0.7908\n",
      "Epoch 11/160\n",
      "582/582 [==============================] - 0s 314us/step - loss: 0.4246 - acc: 0.7822\n",
      "Epoch 12/160\n",
      "582/582 [==============================] - 0s 303us/step - loss: 0.4144 - acc: 0.7934\n",
      "Epoch 13/160\n",
      "582/582 [==============================] - 0s 277us/step - loss: 0.4092 - acc: 0.8007\n",
      "Epoch 14/160\n",
      "582/582 [==============================] - 0s 289us/step - loss: 0.4134 - acc: 0.7942\n",
      "Epoch 15/160\n",
      "582/582 [==============================] - 0s 293us/step - loss: 0.4108 - acc: 0.7908\n",
      "Epoch 16/160\n",
      "582/582 [==============================] - 0s 284us/step - loss: 0.4159 - acc: 0.7844\n",
      "Epoch 17/160\n",
      "582/582 [==============================] - 0s 306us/step - loss: 0.4140 - acc: 0.7912\n",
      "Epoch 18/160\n",
      "582/582 [==============================] - 0s 334us/step - loss: 0.4077 - acc: 0.7951\n",
      "Epoch 19/160\n",
      "582/582 [==============================] - 0s 290us/step - loss: 0.4035 - acc: 0.7998\n",
      "Epoch 20/160\n",
      "582/582 [==============================] - 0s 301us/step - loss: 0.4053 - acc: 0.7942\n",
      "Epoch 21/160\n",
      "582/582 [==============================] - 0s 305us/step - loss: 0.4069 - acc: 0.7964\n",
      "Epoch 22/160\n",
      "582/582 [==============================] - 0s 314us/step - loss: 0.4049 - acc: 0.7977\n",
      "Epoch 23/160\n",
      "582/582 [==============================] - 0s 333us/step - loss: 0.3996 - acc: 0.8011\n",
      "Epoch 24/160\n",
      "582/582 [==============================] - 0s 298us/step - loss: 0.4068 - acc: 0.7964\n",
      "Epoch 25/160\n",
      "582/582 [==============================] - 0s 333us/step - loss: 0.3998 - acc: 0.8041\n",
      "Epoch 26/160\n",
      "582/582 [==============================] - 0s 315us/step - loss: 0.3956 - acc: 0.7934\n",
      "Epoch 27/160\n",
      "582/582 [==============================] - 0s 286us/step - loss: 0.4141 - acc: 0.7882\n",
      "Epoch 28/160\n",
      "582/582 [==============================] - 0s 329us/step - loss: 0.4024 - acc: 0.8028\n",
      "Epoch 29/160\n",
      "582/582 [==============================] - 0s 278us/step - loss: 0.4014 - acc: 0.7968\n",
      "Epoch 30/160\n",
      "582/582 [==============================] - 0s 287us/step - loss: 0.4123 - acc: 0.7955\n",
      "Epoch 31/160\n",
      "582/582 [==============================] - 0s 296us/step - loss: 0.3992 - acc: 0.7981\n",
      "Epoch 32/160\n",
      "582/582 [==============================] - 0s 310us/step - loss: 0.3970 - acc: 0.7960\n",
      "Epoch 33/160\n",
      "582/582 [==============================] - 0s 286us/step - loss: 0.4020 - acc: 0.8003\n",
      "Epoch 34/160\n",
      "582/582 [==============================] - 0s 315us/step - loss: 0.3990 - acc: 0.7930\n",
      "Epoch 35/160\n",
      "582/582 [==============================] - 0s 340us/step - loss: 0.3952 - acc: 0.8041\n",
      "Epoch 36/160\n",
      "582/582 [==============================] - 0s 365us/step - loss: 0.3985 - acc: 0.8028\n",
      "Epoch 37/160\n",
      "582/582 [==============================] - 0s 356us/step - loss: 0.3930 - acc: 0.8028\n",
      "Epoch 38/160\n",
      "582/582 [==============================] - 0s 297us/step - loss: 0.3920 - acc: 0.8067\n",
      "Epoch 39/160\n",
      "582/582 [==============================] - 0s 303us/step - loss: 0.3920 - acc: 0.8037\n",
      "Epoch 40/160\n",
      "582/582 [==============================] - 0s 299us/step - loss: 0.4000 - acc: 0.7947\n",
      "Epoch 41/160\n",
      "582/582 [==============================] - 0s 264us/step - loss: 0.4070 - acc: 0.8033\n",
      "Epoch 42/160\n",
      "582/582 [==============================] - 0s 305us/step - loss: 0.3953 - acc: 0.8028\n",
      "Epoch 43/160\n",
      "582/582 [==============================] - 0s 311us/step - loss: 0.4008 - acc: 0.8003\n",
      "Epoch 44/160\n",
      "582/582 [==============================] - 0s 274us/step - loss: 0.3939 - acc: 0.8041\n",
      "Epoch 45/160\n",
      "582/582 [==============================] - 0s 295us/step - loss: 0.3955 - acc: 0.8106\n",
      "Epoch 46/160\n",
      "582/582 [==============================] - 0s 308us/step - loss: 0.3967 - acc: 0.8084\n",
      "Epoch 47/160\n",
      "582/582 [==============================] - 0s 291us/step - loss: 0.3909 - acc: 0.8063\n",
      "Epoch 48/160\n",
      "582/582 [==============================] - 0s 287us/step - loss: 0.3901 - acc: 0.8110\n",
      "Epoch 49/160\n",
      "582/582 [==============================] - 0s 297us/step - loss: 0.4045 - acc: 0.7908\n",
      "Epoch 50/160\n",
      "582/582 [==============================] - 0s 271us/step - loss: 0.3910 - acc: 0.8093\n",
      "Epoch 51/160\n",
      "582/582 [==============================] - 0s 277us/step - loss: 0.3926 - acc: 0.8114\n",
      "Epoch 52/160\n",
      "582/582 [==============================] - 0s 315us/step - loss: 0.4000 - acc: 0.7917\n",
      "Epoch 53/160\n",
      "582/582 [==============================] - 0s 286us/step - loss: 0.3999 - acc: 0.7973\n",
      "Epoch 54/160\n",
      "582/582 [==============================] - 0s 280us/step - loss: 0.3948 - acc: 0.8050\n",
      "Epoch 55/160\n",
      "582/582 [==============================] - 0s 303us/step - loss: 0.3872 - acc: 0.8063\n",
      "Epoch 56/160\n",
      "582/582 [==============================] - 0s 294us/step - loss: 0.3889 - acc: 0.8080\n",
      "Epoch 57/160\n",
      "582/582 [==============================] - 0s 269us/step - loss: 0.3942 - acc: 0.8015\n",
      "Epoch 58/160\n",
      "582/582 [==============================] - 0s 297us/step - loss: 0.3875 - acc: 0.8127\n",
      "Epoch 59/160\n",
      "582/582 [==============================] - 0s 292us/step - loss: 0.3923 - acc: 0.8088\n",
      "Epoch 60/160\n",
      "582/582 [==============================] - 0s 272us/step - loss: 0.3849 - acc: 0.8136\n",
      "Epoch 61/160\n",
      "582/582 [==============================] - 0s 327us/step - loss: 0.3823 - acc: 0.8097\n",
      "Epoch 62/160\n",
      "582/582 [==============================] - 0s 300us/step - loss: 0.3825 - acc: 0.8119\n",
      "Epoch 63/160\n",
      "582/582 [==============================] - 0s 270us/step - loss: 0.3776 - acc: 0.8149\n",
      "Epoch 64/160\n",
      "582/582 [==============================] - 0s 269us/step - loss: 0.3856 - acc: 0.8097\n",
      "Epoch 65/160\n",
      "582/582 [==============================] - 0s 244us/step - loss: 0.3813 - acc: 0.8149\n",
      "Epoch 66/160\n",
      "582/582 [==============================] - 0s 270us/step - loss: 0.3790 - acc: 0.8192\n",
      "Epoch 67/160\n",
      "582/582 [==============================] - 0s 257us/step - loss: 0.3940 - acc: 0.8071\n",
      "Epoch 68/160\n",
      "582/582 [==============================] - 0s 239us/step - loss: 0.3849 - acc: 0.8174\n",
      "Epoch 69/160\n",
      "582/582 [==============================] - 0s 254us/step - loss: 0.3837 - acc: 0.8144\n",
      "Epoch 70/160\n",
      "582/582 [==============================] - 0s 230us/step - loss: 0.3825 - acc: 0.8166\n",
      "Epoch 71/160\n",
      "582/582 [==============================] - 0s 243us/step - loss: 0.3860 - acc: 0.8140\n",
      "Epoch 72/160\n",
      "582/582 [==============================] - 0s 250us/step - loss: 0.3730 - acc: 0.8252\n",
      "Epoch 73/160\n",
      "582/582 [==============================] - 0s 267us/step - loss: 0.3753 - acc: 0.8222\n",
      "Epoch 74/160\n",
      "582/582 [==============================] - 0s 279us/step - loss: 0.3749 - acc: 0.8192\n",
      "Epoch 75/160\n",
      "582/582 [==============================] - 0s 361us/step - loss: 0.3761 - acc: 0.8213\n",
      "Epoch 76/160\n",
      "582/582 [==============================] - 0s 363us/step - loss: 0.3790 - acc: 0.8123\n",
      "Epoch 77/160\n",
      "582/582 [==============================] - 0s 369us/step - loss: 0.3766 - acc: 0.8131\n",
      "Epoch 78/160\n",
      "582/582 [==============================] - 0s 355us/step - loss: 0.3711 - acc: 0.8222\n",
      "Epoch 79/160\n",
      "582/582 [==============================] - 0s 343us/step - loss: 0.3711 - acc: 0.8209\n",
      "Epoch 80/160\n",
      "582/582 [==============================] - 0s 346us/step - loss: 0.3693 - acc: 0.8192\n",
      "Epoch 81/160\n",
      "582/582 [==============================] - 0s 366us/step - loss: 0.3674 - acc: 0.8247\n",
      "Epoch 82/160\n",
      "582/582 [==============================] - 0s 376us/step - loss: 0.3677 - acc: 0.8265\n",
      "Epoch 83/160\n",
      "582/582 [==============================] - 0s 347us/step - loss: 0.3680 - acc: 0.8295\n",
      "Epoch 84/160\n",
      "582/582 [==============================] - 0s 305us/step - loss: 0.3745 - acc: 0.8170\n",
      "Epoch 85/160\n",
      "582/582 [==============================] - 0s 350us/step - loss: 0.3843 - acc: 0.8174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/160\n",
      "582/582 [==============================] - 0s 344us/step - loss: 0.3744 - acc: 0.8170\n",
      "Epoch 87/160\n",
      "582/582 [==============================] - 0s 315us/step - loss: 0.3714 - acc: 0.8179\n",
      "Epoch 88/160\n",
      "582/582 [==============================] - 0s 347us/step - loss: 0.3660 - acc: 0.8256\n",
      "Epoch 89/160\n",
      "582/582 [==============================] - 0s 334us/step - loss: 0.3609 - acc: 0.8303\n",
      "Epoch 90/160\n",
      "582/582 [==============================] - 0s 376us/step - loss: 0.3651 - acc: 0.8166\n",
      "Epoch 91/160\n",
      "582/582 [==============================] - 0s 394us/step - loss: 0.3636 - acc: 0.8256\n",
      "Epoch 92/160\n",
      "582/582 [==============================] - 0s 339us/step - loss: 0.3615 - acc: 0.8308\n",
      "Epoch 93/160\n",
      "582/582 [==============================] - 0s 368us/step - loss: 0.3686 - acc: 0.8235\n",
      "Epoch 94/160\n",
      "582/582 [==============================] - 0s 408us/step - loss: 0.3602 - acc: 0.8286\n",
      "Epoch 95/160\n",
      "582/582 [==============================] - 0s 299us/step - loss: 0.3783 - acc: 0.8149\n",
      "Epoch 96/160\n",
      "582/582 [==============================] - 0s 257us/step - loss: 0.3736 - acc: 0.8183\n",
      "Epoch 97/160\n",
      "582/582 [==============================] - 0s 261us/step - loss: 0.3649 - acc: 0.8230\n",
      "Epoch 98/160\n",
      "582/582 [==============================] - 0s 270us/step - loss: 0.3651 - acc: 0.8239\n",
      "Epoch 99/160\n",
      "582/582 [==============================] - 0s 266us/step - loss: 0.3564 - acc: 0.8295\n",
      "Epoch 100/160\n",
      "582/582 [==============================] - 0s 255us/step - loss: 0.3704 - acc: 0.8247\n",
      "Epoch 101/160\n",
      "582/582 [==============================] - 0s 244us/step - loss: 0.3605 - acc: 0.8277\n",
      "Epoch 102/160\n",
      "582/582 [==============================] - 0s 239us/step - loss: 0.3554 - acc: 0.8376\n",
      "Epoch 103/160\n",
      "582/582 [==============================] - 0s 249us/step - loss: 0.3650 - acc: 0.8247\n",
      "Epoch 104/160\n",
      "582/582 [==============================] - 0s 350us/step - loss: 0.3682 - acc: 0.8200\n",
      "Epoch 105/160\n",
      "582/582 [==============================] - 0s 323us/step - loss: 0.3588 - acc: 0.8282\n",
      "Epoch 106/160\n",
      "582/582 [==============================] - 0s 246us/step - loss: 0.3566 - acc: 0.8256\n",
      "Epoch 107/160\n",
      "582/582 [==============================] - 0s 278us/step - loss: 0.3608 - acc: 0.8256\n",
      "Epoch 108/160\n",
      "582/582 [==============================] - 0s 242us/step - loss: 0.3532 - acc: 0.8333\n",
      "Epoch 109/160\n",
      "582/582 [==============================] - 0s 252us/step - loss: 0.3502 - acc: 0.8338\n",
      "Epoch 110/160\n",
      "582/582 [==============================] - 0s 246us/step - loss: 0.3530 - acc: 0.8273\n",
      "Epoch 111/160\n",
      "582/582 [==============================] - 0s 239us/step - loss: 0.3488 - acc: 0.8295\n",
      "Epoch 112/160\n",
      "582/582 [==============================] - 0s 232us/step - loss: 0.3532 - acc: 0.8308\n",
      "Epoch 113/160\n",
      "582/582 [==============================] - 0s 262us/step - loss: 0.3541 - acc: 0.8320\n",
      "Epoch 114/160\n",
      "582/582 [==============================] - 0s 232us/step - loss: 0.3703 - acc: 0.8213\n",
      "Epoch 115/160\n",
      "582/582 [==============================] - 0s 234us/step - loss: 0.3614 - acc: 0.8269\n",
      "Epoch 116/160\n",
      "582/582 [==============================] - 0s 289us/step - loss: 0.3617 - acc: 0.8247\n",
      "Epoch 117/160\n",
      "582/582 [==============================] - 0s 420us/step - loss: 0.3527 - acc: 0.8290\n",
      "Epoch 118/160\n",
      "582/582 [==============================] - 0s 338us/step - loss: 0.3457 - acc: 0.8346\n",
      "Epoch 119/160\n",
      "582/582 [==============================] - 0s 362us/step - loss: 0.3461 - acc: 0.8282\n",
      "Epoch 120/160\n",
      "582/582 [==============================] - 0s 351us/step - loss: 0.3419 - acc: 0.8368\n",
      "Epoch 121/160\n",
      "582/582 [==============================] - 0s 351us/step - loss: 0.3452 - acc: 0.8351\n",
      "Epoch 122/160\n",
      "582/582 [==============================] - 0s 376us/step - loss: 0.3510 - acc: 0.8299\n",
      "Epoch 123/160\n",
      "582/582 [==============================] - 0s 383us/step - loss: 0.3603 - acc: 0.8247\n",
      "Epoch 124/160\n",
      "582/582 [==============================] - 0s 363us/step - loss: 0.3548 - acc: 0.8312\n",
      "Epoch 125/160\n",
      "582/582 [==============================] - 0s 421us/step - loss: 0.3518 - acc: 0.8333\n",
      "Epoch 126/160\n",
      "582/582 [==============================] - 0s 354us/step - loss: 0.3425 - acc: 0.8363\n",
      "Epoch 127/160\n",
      "582/582 [==============================] - 0s 402us/step - loss: 0.3468 - acc: 0.8329\n",
      "Epoch 128/160\n",
      "582/582 [==============================] - 0s 361us/step - loss: 0.3658 - acc: 0.8299\n",
      "Epoch 129/160\n",
      "582/582 [==============================] - 0s 403us/step - loss: 0.3621 - acc: 0.8243\n",
      "Epoch 130/160\n",
      "582/582 [==============================] - 0s 303us/step - loss: 0.3482 - acc: 0.8316\n",
      "Epoch 131/160\n",
      "582/582 [==============================] - 0s 286us/step - loss: 0.3575 - acc: 0.8277\n",
      "Epoch 132/160\n",
      "582/582 [==============================] - 0s 297us/step - loss: 0.3634 - acc: 0.8286\n",
      "Epoch 133/160\n",
      "582/582 [==============================] - 0s 303us/step - loss: 0.3482 - acc: 0.8320\n",
      "Epoch 134/160\n",
      "582/582 [==============================] - 0s 276us/step - loss: 0.3462 - acc: 0.8333\n",
      "Epoch 135/160\n",
      "582/582 [==============================] - 0s 275us/step - loss: 0.3454 - acc: 0.8351\n",
      "Epoch 136/160\n",
      "582/582 [==============================] - 0s 263us/step - loss: 0.3433 - acc: 0.8346\n",
      "Epoch 137/160\n",
      "582/582 [==============================] - 0s 288us/step - loss: 0.3443 - acc: 0.8316\n",
      "Epoch 138/160\n",
      "582/582 [==============================] - 0s 299us/step - loss: 0.3483 - acc: 0.8282\n",
      "Epoch 139/160\n",
      "582/582 [==============================] - 0s 290us/step - loss: 0.3453 - acc: 0.8368\n",
      "Epoch 140/160\n",
      "582/582 [==============================] - 0s 259us/step - loss: 0.3433 - acc: 0.8363\n",
      "Epoch 141/160\n",
      "582/582 [==============================] - 0s 297us/step - loss: 0.3351 - acc: 0.8415\n",
      "Epoch 142/160\n",
      "582/582 [==============================] - 0s 272us/step - loss: 0.3350 - acc: 0.8359\n",
      "Epoch 143/160\n",
      "582/582 [==============================] - 0s 353us/step - loss: 0.3306 - acc: 0.8411\n",
      "Epoch 144/160\n",
      "582/582 [==============================] - 0s 389us/step - loss: 0.3420 - acc: 0.8351\n",
      "Epoch 145/160\n",
      "582/582 [==============================] - 0s 362us/step - loss: 0.3480 - acc: 0.8385\n",
      "Epoch 146/160\n",
      "582/582 [==============================] - 0s 276us/step - loss: 0.3476 - acc: 0.8342\n",
      "Epoch 147/160\n",
      "582/582 [==============================] - 0s 301us/step - loss: 0.3520 - acc: 0.8316\n",
      "Epoch 148/160\n",
      "582/582 [==============================] - 0s 280us/step - loss: 0.3466 - acc: 0.8316\n",
      "Epoch 149/160\n",
      "582/582 [==============================] - 0s 260us/step - loss: 0.3407 - acc: 0.8368\n",
      "Epoch 150/160\n",
      "582/582 [==============================] - 0s 268us/step - loss: 0.3318 - acc: 0.8393\n",
      "Epoch 151/160\n",
      "582/582 [==============================] - 0s 277us/step - loss: 0.3307 - acc: 0.8381\n",
      "Epoch 152/160\n",
      "582/582 [==============================] - 0s 299us/step - loss: 0.3315 - acc: 0.8381\n",
      "Epoch 153/160\n",
      "582/582 [==============================] - 0s 275us/step - loss: 0.3588 - acc: 0.8235\n",
      "Epoch 154/160\n",
      "582/582 [==============================] - 0s 297us/step - loss: 0.3642 - acc: 0.8230\n",
      "Epoch 155/160\n",
      "582/582 [==============================] - 0s 276us/step - loss: 0.3447 - acc: 0.8355\n",
      "Epoch 156/160\n",
      "582/582 [==============================] - 0s 264us/step - loss: 0.3487 - acc: 0.8351\n",
      "Epoch 157/160\n",
      "582/582 [==============================] - 0s 269us/step - loss: 0.3401 - acc: 0.8346\n",
      "Epoch 158/160\n",
      "582/582 [==============================] - 0s 270us/step - loss: 0.3428 - acc: 0.8342\n",
      "Epoch 159/160\n",
      "582/582 [==============================] - 0s 305us/step - loss: 0.3413 - acc: 0.8351\n",
      "Epoch 160/160\n",
      "582/582 [==============================] - 0s 297us/step - loss: 0.3569 - acc: 0.8290\n",
      "146/146 [==============================] - 0s 604us/step\n",
      "582/582 [==============================] - 0s 74us/step\n",
      "\n",
      "acc: 79.28%\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "[[25  9  1  1]\n",
      " [ 3 70  4  5]\n",
      " [ 0  0  5  0]\n",
      " [ 5  0  0 18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.76      0.69      0.72        36\n",
      "      Normal       0.89      0.85      0.87        82\n",
      "        Slow       0.50      1.00      0.67         5\n",
      "   Very Fast       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.81       146\n",
      "   macro avg       0.72      0.83      0.76       146\n",
      "weighted avg       0.82      0.81      0.81       146\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8082191780821918"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[df_k.Timelevel==1]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Timelevel 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "1324/1324 [==============================] - 1s 731us/step - loss: 0.4730 - acc: 0.7744\n",
      "Epoch 2/160\n",
      "1324/1324 [==============================] - 0s 336us/step - loss: 0.4233 - acc: 0.7863\n",
      "Epoch 3/160\n",
      "1324/1324 [==============================] - 0s 350us/step - loss: 0.4207 - acc: 0.7895\n",
      "Epoch 4/160\n",
      "1324/1324 [==============================] - 0s 302us/step - loss: 0.4076 - acc: 0.7957\n",
      "Epoch 5/160\n",
      "1324/1324 [==============================] - 0s 330us/step - loss: 0.4019 - acc: 0.8048\n",
      "Epoch 6/160\n",
      "1324/1324 [==============================] - 0s 294us/step - loss: 0.3996 - acc: 0.7993\n",
      "Epoch 7/160\n",
      "1324/1324 [==============================] - 0s 332us/step - loss: 0.4040 - acc: 0.8021\n",
      "Epoch 8/160\n",
      "1324/1324 [==============================] - 1s 396us/step - loss: 0.3958 - acc: 0.8074\n",
      "Epoch 9/160\n",
      "1324/1324 [==============================] - 0s 257us/step - loss: 0.3988 - acc: 0.8012\n",
      "Epoch 10/160\n",
      "1324/1324 [==============================] - 1s 417us/step - loss: 0.3860 - acc: 0.8136\n",
      "Epoch 11/160\n",
      "1324/1324 [==============================] - 1s 532us/step - loss: 0.3916 - acc: 0.8108\n",
      "Epoch 12/160\n",
      "1324/1324 [==============================] - 1s 380us/step - loss: 0.3883 - acc: 0.8117\n",
      "Epoch 13/160\n",
      "1324/1324 [==============================] - 1s 465us/step - loss: 0.3903 - acc: 0.8114\n",
      "Epoch 14/160\n",
      "1324/1324 [==============================] - 1s 393us/step - loss: 0.3842 - acc: 0.8150\n",
      "Epoch 15/160\n",
      "1324/1324 [==============================] - 1s 399us/step - loss: 0.3822 - acc: 0.8172\n",
      "Epoch 16/160\n",
      "1324/1324 [==============================] - 1s 424us/step - loss: 0.3786 - acc: 0.8204\n",
      "Epoch 17/160\n",
      "1324/1324 [==============================] - 0s 316us/step - loss: 0.3864 - acc: 0.8104\n",
      "Epoch 18/160\n",
      "1324/1324 [==============================] - 0s 322us/step - loss: 0.3772 - acc: 0.8216\n",
      "Epoch 19/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3775 - acc: 0.8148\n",
      "Epoch 20/160\n",
      "1324/1324 [==============================] - 0s 307us/step - loss: 0.3762 - acc: 0.8201\n",
      "Epoch 21/160\n",
      "1324/1324 [==============================] - 0s 310us/step - loss: 0.3805 - acc: 0.8185\n",
      "Epoch 22/160\n",
      "1324/1324 [==============================] - 0s 312us/step - loss: 0.3817 - acc: 0.8150\n",
      "Epoch 23/160\n",
      "1324/1324 [==============================] - 0s 310us/step - loss: 0.3759 - acc: 0.8165\n",
      "Epoch 24/160\n",
      "1324/1324 [==============================] - 0s 330us/step - loss: 0.3766 - acc: 0.8206\n",
      "Epoch 25/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3761 - acc: 0.8231\n",
      "Epoch 26/160\n",
      "1324/1324 [==============================] - 0s 312us/step - loss: 0.3781 - acc: 0.8174\n",
      "Epoch 27/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3727 - acc: 0.8204\n",
      "Epoch 28/160\n",
      "1324/1324 [==============================] - 0s 305us/step - loss: 0.3721 - acc: 0.8185\n",
      "Epoch 29/160\n",
      "1324/1324 [==============================] - 0s 316us/step - loss: 0.3678 - acc: 0.8270\n",
      "Epoch 30/160\n",
      "1324/1324 [==============================] - 0s 298us/step - loss: 0.3726 - acc: 0.8184\n",
      "Epoch 31/160\n",
      "1324/1324 [==============================] - 0s 304us/step - loss: 0.3677 - acc: 0.8223\n",
      "Epoch 32/160\n",
      "1324/1324 [==============================] - 0s 307us/step - loss: 0.3729 - acc: 0.8204\n",
      "Epoch 33/160\n",
      "1324/1324 [==============================] - 0s 299us/step - loss: 0.3690 - acc: 0.8219\n",
      "Epoch 34/160\n",
      "1324/1324 [==============================] - 0s 306us/step - loss: 0.3621 - acc: 0.8272\n",
      "Epoch 35/160\n",
      "1324/1324 [==============================] - 0s 314us/step - loss: 0.3682 - acc: 0.8270\n",
      "Epoch 36/160\n",
      "1324/1324 [==============================] - 0s 306us/step - loss: 0.3663 - acc: 0.8255\n",
      "Epoch 37/160\n",
      "1324/1324 [==============================] - 0s 317us/step - loss: 0.3613 - acc: 0.8289\n",
      "Epoch 38/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3656 - acc: 0.8246\n",
      "Epoch 39/160\n",
      "1324/1324 [==============================] - 0s 319us/step - loss: 0.3642 - acc: 0.8287\n",
      "Epoch 40/160\n",
      "1324/1324 [==============================] - 0s 319us/step - loss: 0.3610 - acc: 0.8284\n",
      "Epoch 41/160\n",
      "1324/1324 [==============================] - 0s 308us/step - loss: 0.3593 - acc: 0.8269\n",
      "Epoch 42/160\n",
      "1324/1324 [==============================] - 0s 319us/step - loss: 0.3567 - acc: 0.8297\n",
      "Epoch 43/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3582 - acc: 0.8297\n",
      "Epoch 44/160\n",
      "1324/1324 [==============================] - 0s 306us/step - loss: 0.3606 - acc: 0.8304\n",
      "Epoch 45/160\n",
      "1324/1324 [==============================] - 0s 293us/step - loss: 0.3615 - acc: 0.8240\n",
      "Epoch 46/160\n",
      "1324/1324 [==============================] - 0s 303us/step - loss: 0.3601 - acc: 0.8314\n",
      "Epoch 47/160\n",
      "1324/1324 [==============================] - 0s 315us/step - loss: 0.3586 - acc: 0.8295\n",
      "Epoch 48/160\n",
      "1324/1324 [==============================] - 0s 306us/step - loss: 0.3580 - acc: 0.8308\n",
      "Epoch 49/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3561 - acc: 0.8321\n",
      "Epoch 50/160\n",
      "1324/1324 [==============================] - 0s 316us/step - loss: 0.3536 - acc: 0.8310\n",
      "Epoch 51/160\n",
      "1324/1324 [==============================] - 0s 301us/step - loss: 0.3546 - acc: 0.8278\n",
      "Epoch 52/160\n",
      "1324/1324 [==============================] - 0s 303us/step - loss: 0.3526 - acc: 0.8369\n",
      "Epoch 53/160\n",
      "1324/1324 [==============================] - 0s 309us/step - loss: 0.3537 - acc: 0.8308\n",
      "Epoch 54/160\n",
      "1324/1324 [==============================] - 0s 338us/step - loss: 0.3516 - acc: 0.8325\n",
      "Epoch 55/160\n",
      "1324/1324 [==============================] - 0s 318us/step - loss: 0.3513 - acc: 0.8346\n",
      "Epoch 56/160\n",
      "1324/1324 [==============================] - 0s 306us/step - loss: 0.3514 - acc: 0.8378\n",
      "Epoch 57/160\n",
      "1324/1324 [==============================] - 0s 305us/step - loss: 0.3623 - acc: 0.8278\n",
      "Epoch 58/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3521 - acc: 0.8297\n",
      "Epoch 59/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3587 - acc: 0.8312\n",
      "Epoch 60/160\n",
      "1324/1324 [==============================] - 0s 296us/step - loss: 0.3515 - acc: 0.8312\n",
      "Epoch 61/160\n",
      "1324/1324 [==============================] - 0s 302us/step - loss: 0.3530 - acc: 0.8265\n",
      "Epoch 62/160\n",
      "1324/1324 [==============================] - 0s 301us/step - loss: 0.3483 - acc: 0.8327\n",
      "Epoch 63/160\n",
      "1324/1324 [==============================] - 0s 317us/step - loss: 0.3422 - acc: 0.8329\n",
      "Epoch 64/160\n",
      "1324/1324 [==============================] - 0s 295us/step - loss: 0.3482 - acc: 0.8372\n",
      "Epoch 65/160\n",
      "1324/1324 [==============================] - 0s 315us/step - loss: 0.3419 - acc: 0.8357\n",
      "Epoch 66/160\n",
      "1324/1324 [==============================] - 0s 305us/step - loss: 0.3529 - acc: 0.8299\n",
      "Epoch 67/160\n",
      "1324/1324 [==============================] - 0s 306us/step - loss: 0.3512 - acc: 0.8299\n",
      "Epoch 68/160\n",
      "1324/1324 [==============================] - 0s 304us/step - loss: 0.3519 - acc: 0.8340\n",
      "Epoch 69/160\n",
      "1324/1324 [==============================] - 0s 310us/step - loss: 0.3501 - acc: 0.8340\n",
      "Epoch 70/160\n",
      "1324/1324 [==============================] - 0s 312us/step - loss: 0.3510 - acc: 0.8301\n",
      "Epoch 71/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3476 - acc: 0.8346\n",
      "Epoch 72/160\n",
      "1324/1324 [==============================] - 0s 301us/step - loss: 0.3366 - acc: 0.8391\n",
      "Epoch 73/160\n",
      "1324/1324 [==============================] - 0s 313us/step - loss: 0.3421 - acc: 0.8412\n",
      "Epoch 74/160\n",
      "1324/1324 [==============================] - 0s 305us/step - loss: 0.3412 - acc: 0.8391\n",
      "Epoch 75/160\n",
      "1324/1324 [==============================] - 0s 294us/step - loss: 0.3375 - acc: 0.8401\n",
      "Epoch 76/160\n",
      "1324/1324 [==============================] - 0s 295us/step - loss: 0.3457 - acc: 0.8335\n",
      "Epoch 77/160\n",
      "1324/1324 [==============================] - 0s 313us/step - loss: 0.3513 - acc: 0.8308\n",
      "Epoch 78/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3399 - acc: 0.8370\n",
      "Epoch 79/160\n",
      "1324/1324 [==============================] - 0s 307us/step - loss: 0.3377 - acc: 0.8389\n",
      "Epoch 80/160\n",
      "1324/1324 [==============================] - 0s 308us/step - loss: 0.3369 - acc: 0.8404\n",
      "Epoch 81/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3410 - acc: 0.8361\n",
      "Epoch 82/160\n",
      "1324/1324 [==============================] - 0s 293us/step - loss: 0.3450 - acc: 0.8372\n",
      "Epoch 83/160\n",
      "1324/1324 [==============================] - 0s 301us/step - loss: 0.3471 - acc: 0.8335\n",
      "Epoch 84/160\n",
      "1324/1324 [==============================] - 0s 301us/step - loss: 0.3358 - acc: 0.8440\n",
      "Epoch 85/160\n",
      "1324/1324 [==============================] - 0s 304us/step - loss: 0.3366 - acc: 0.8416\n",
      "Epoch 86/160\n",
      "1324/1324 [==============================] - 0s 291us/step - loss: 0.3312 - acc: 0.8408\n",
      "Epoch 87/160\n",
      "1324/1324 [==============================] - 0s 296us/step - loss: 0.3364 - acc: 0.8406\n",
      "Epoch 88/160\n",
      "1324/1324 [==============================] - 0s 302us/step - loss: 0.3337 - acc: 0.8399\n",
      "Epoch 89/160\n",
      "1324/1324 [==============================] - 0s 308us/step - loss: 0.3312 - acc: 0.8414\n",
      "Epoch 90/160\n",
      "1324/1324 [==============================] - 0s 291us/step - loss: 0.3388 - acc: 0.8395\n",
      "Epoch 91/160\n",
      "1324/1324 [==============================] - 0s 299us/step - loss: 0.3342 - acc: 0.8401\n",
      "Epoch 92/160\n",
      "1324/1324 [==============================] - 0s 308us/step - loss: 0.3330 - acc: 0.8433\n",
      "Epoch 93/160\n",
      "1324/1324 [==============================] - 0s 312us/step - loss: 0.3441 - acc: 0.8380\n",
      "Epoch 94/160\n",
      "1324/1324 [==============================] - 0s 298us/step - loss: 0.3456 - acc: 0.8374\n",
      "Epoch 95/160\n",
      "1324/1324 [==============================] - 0s 297us/step - loss: 0.3470 - acc: 0.8350\n",
      "Epoch 96/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3408 - acc: 0.8416\n",
      "Epoch 97/160\n",
      "1324/1324 [==============================] - 0s 319us/step - loss: 0.3421 - acc: 0.8389\n",
      "Epoch 98/160\n",
      "1324/1324 [==============================] - 0s 318us/step - loss: 0.3320 - acc: 0.8467\n",
      "Epoch 99/160\n",
      "1324/1324 [==============================] - 0s 304us/step - loss: 0.3334 - acc: 0.8457\n",
      "Epoch 100/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3365 - acc: 0.8437\n",
      "Epoch 101/160\n",
      "1324/1324 [==============================] - 0s 292us/step - loss: 0.3394 - acc: 0.8401\n",
      "Epoch 102/160\n",
      "1324/1324 [==============================] - 0s 317us/step - loss: 0.3366 - acc: 0.8412\n",
      "Epoch 103/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3325 - acc: 0.8363\n",
      "Epoch 104/160\n",
      "1324/1324 [==============================] - 0s 287us/step - loss: 0.3303 - acc: 0.8431\n",
      "Epoch 105/160\n",
      "1324/1324 [==============================] - 0s 310us/step - loss: 0.3320 - acc: 0.8412\n",
      "Epoch 106/160\n",
      "1324/1324 [==============================] - 0s 303us/step - loss: 0.3274 - acc: 0.8438\n",
      "Epoch 107/160\n",
      "1324/1324 [==============================] - 0s 289us/step - loss: 0.3252 - acc: 0.8471\n",
      "Epoch 108/160\n",
      "1324/1324 [==============================] - 0s 303us/step - loss: 0.3364 - acc: 0.8420\n",
      "Epoch 109/160\n",
      "1324/1324 [==============================] - 0s 299us/step - loss: 0.3311 - acc: 0.8420\n",
      "Epoch 110/160\n",
      "1324/1324 [==============================] - 0s 306us/step - loss: 0.3232 - acc: 0.8486\n",
      "Epoch 111/160\n",
      "1324/1324 [==============================] - 0s 300us/step - loss: 0.3255 - acc: 0.8463\n",
      "Epoch 112/160\n",
      "1324/1324 [==============================] - 0s 299us/step - loss: 0.3296 - acc: 0.8420\n",
      "Epoch 113/160\n",
      "1324/1324 [==============================] - 0s 327us/step - loss: 0.3509 - acc: 0.8363\n",
      "Epoch 114/160\n",
      "1324/1324 [==============================] - 0s 312us/step - loss: 0.3303 - acc: 0.8448\n",
      "Epoch 115/160\n",
      "1324/1324 [==============================] - 0s 311us/step - loss: 0.3289 - acc: 0.8401\n",
      "Epoch 116/160\n",
      "1324/1324 [==============================] - 0s 292us/step - loss: 0.3289 - acc: 0.8423\n",
      "Epoch 117/160\n",
      "1324/1324 [==============================] - 0s 296us/step - loss: 0.3213 - acc: 0.8465\n",
      "Epoch 118/160\n",
      "1324/1324 [==============================] - 0s 301us/step - loss: 0.3260 - acc: 0.8437\n",
      "Epoch 119/160\n",
      "1324/1324 [==============================] - 0s 316us/step - loss: 0.3369 - acc: 0.8353\n",
      "Epoch 120/160\n",
      "1324/1324 [==============================] - 0s 325us/step - loss: 0.3202 - acc: 0.8480\n",
      "Epoch 121/160\n",
      "1324/1324 [==============================] - 0s 318us/step - loss: 0.3172 - acc: 0.8506\n",
      "Epoch 122/160\n",
      "1324/1324 [==============================] - 0s 302us/step - loss: 0.3243 - acc: 0.8446\n",
      "Epoch 123/160\n",
      "1324/1324 [==============================] - 0s 294us/step - loss: 0.3264 - acc: 0.8461\n",
      "Epoch 124/160\n",
      "1324/1324 [==============================] - 0s 297us/step - loss: 0.3254 - acc: 0.8489\n",
      "Epoch 125/160\n",
      "1324/1324 [==============================] - 0s 313us/step - loss: 0.3302 - acc: 0.8471\n",
      "Epoch 126/160\n",
      "1324/1324 [==============================] - 0s 291us/step - loss: 0.3221 - acc: 0.8516\n",
      "Epoch 127/160\n",
      "1324/1324 [==============================] - 0s 307us/step - loss: 0.3147 - acc: 0.8489\n",
      "Epoch 128/160\n",
      "1324/1324 [==============================] - 1s 431us/step - loss: 0.3229 - acc: 0.8448\n",
      "Epoch 129/160\n",
      "1324/1324 [==============================] - 1s 530us/step - loss: 0.3242 - acc: 0.8448\n",
      "Epoch 130/160\n",
      "1324/1324 [==============================] - 0s 340us/step - loss: 0.3296 - acc: 0.8412\n",
      "Epoch 131/160\n",
      "1324/1324 [==============================] - 1s 419us/step - loss: 0.3187 - acc: 0.8510\n",
      "Epoch 132/160\n",
      "1324/1324 [==============================] - 0s 335us/step - loss: 0.3211 - acc: 0.8459\n",
      "Epoch 133/160\n",
      "1324/1324 [==============================] - 0s 325us/step - loss: 0.3269 - acc: 0.8427\n",
      "Epoch 134/160\n",
      "1324/1324 [==============================] - 0s 344us/step - loss: 0.3286 - acc: 0.8406\n",
      "Epoch 135/160\n",
      "1324/1324 [==============================] - 0s 362us/step - loss: 0.3266 - acc: 0.8459\n",
      "Epoch 136/160\n",
      "1324/1324 [==============================] - 1s 466us/step - loss: 0.3217 - acc: 0.8440\n",
      "Epoch 137/160\n",
      "1324/1324 [==============================] - 0s 371us/step - loss: 0.3118 - acc: 0.8542\n",
      "Epoch 138/160\n",
      "1324/1324 [==============================] - 0s 315us/step - loss: 0.3192 - acc: 0.8478\n",
      "Epoch 139/160\n",
      "1324/1324 [==============================] - 0s 318us/step - loss: 0.3151 - acc: 0.8525\n",
      "Epoch 140/160\n",
      "1324/1324 [==============================] - 1s 510us/step - loss: 0.3130 - acc: 0.8512\n",
      "Epoch 141/160\n",
      "1324/1324 [==============================] - 1s 462us/step - loss: 0.3715 - acc: 0.8263\n",
      "Epoch 142/160\n",
      "1324/1324 [==============================] - 1s 474us/step - loss: 0.3414 - acc: 0.8410\n",
      "Epoch 143/160\n",
      "1324/1324 [==============================] - 0s 350us/step - loss: 0.3287 - acc: 0.8391\n",
      "Epoch 144/160\n",
      "1324/1324 [==============================] - 0s 310us/step - loss: 0.3205 - acc: 0.8455\n",
      "Epoch 145/160\n",
      "1324/1324 [==============================] - 0s 328us/step - loss: 0.3211 - acc: 0.8463\n",
      "Epoch 146/160\n",
      "1324/1324 [==============================] - 0s 359us/step - loss: 0.3188 - acc: 0.8488\n",
      "Epoch 147/160\n",
      "1324/1324 [==============================] - 0s 322us/step - loss: 0.3129 - acc: 0.8531\n",
      "Epoch 148/160\n",
      "1324/1324 [==============================] - 0s 332us/step - loss: 0.3148 - acc: 0.8514\n",
      "Epoch 149/160\n",
      "1324/1324 [==============================] - 0s 320us/step - loss: 0.3246 - acc: 0.8450\n",
      "Epoch 150/160\n",
      "1324/1324 [==============================] - 0s 350us/step - loss: 0.3148 - acc: 0.8486\n",
      "Epoch 151/160\n",
      "1324/1324 [==============================] - 0s 289us/step - loss: 0.3092 - acc: 0.8489\n",
      "Epoch 152/160\n",
      "1324/1324 [==============================] - 0s 326us/step - loss: 0.3076 - acc: 0.8533\n",
      "Epoch 153/160\n",
      "1324/1324 [==============================] - 0s 291us/step - loss: 0.3114 - acc: 0.8535\n",
      "Epoch 154/160\n",
      "1324/1324 [==============================] - 0s 282us/step - loss: 0.3112 - acc: 0.8518\n",
      "Epoch 155/160\n",
      "1324/1324 [==============================] - 0s 334us/step - loss: 0.3123 - acc: 0.8557\n",
      "Epoch 156/160\n",
      "1324/1324 [==============================] - 0s 327us/step - loss: 0.3119 - acc: 0.8548\n",
      "Epoch 157/160\n",
      "1324/1324 [==============================] - 0s 273us/step - loss: 0.3051 - acc: 0.8544\n",
      "Epoch 158/160\n",
      "1324/1324 [==============================] - 0s 369us/step - loss: 0.3217 - acc: 0.8478\n",
      "Epoch 159/160\n",
      "1324/1324 [==============================] - 0s 305us/step - loss: 0.3225 - acc: 0.8459\n",
      "Epoch 160/160\n",
      "1324/1324 [==============================] - 1s 406us/step - loss: 0.3075 - acc: 0.8569\n",
      "332/332 [==============================] - 0s 627us/step\n",
      "1324/1324 [==============================] - 0s 102us/step\n",
      "\n",
      "acc: 80.87%\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[ 71  30   2  12]\n",
      " [ 10 127   6   3]\n",
      " [  2   2  14   0]\n",
      " [  7   1   0  45]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.79      0.62      0.69       115\n",
      "      Normal       0.79      0.87      0.83       146\n",
      "        Slow       0.64      0.78      0.70        18\n",
      "   Very Fast       0.75      0.85      0.80        53\n",
      "\n",
      "    accuracy                           0.77       332\n",
      "   macro avg       0.74      0.78      0.75       332\n",
      "weighted avg       0.78      0.77      0.77       332\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7740963855421686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[df_k.Timelevel==2]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy Timelevel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "1140/1140 [==============================] - 1s 948us/step - loss: 0.4481 - acc: 0.7908\n",
      "Epoch 2/160\n",
      "1140/1140 [==============================] - 0s 336us/step - loss: 0.3709 - acc: 0.8322\n",
      "Epoch 3/160\n",
      "1140/1140 [==============================] - 0s 329us/step - loss: 0.3652 - acc: 0.8294\n",
      "Epoch 4/160\n",
      "1140/1140 [==============================] - 0s 424us/step - loss: 0.3568 - acc: 0.8360\n",
      "Epoch 5/160\n",
      "1140/1140 [==============================] - 0s 256us/step - loss: 0.3599 - acc: 0.8305\n",
      "Epoch 6/160\n",
      "1140/1140 [==============================] - 0s 432us/step - loss: 0.3539 - acc: 0.8366\n",
      "Epoch 7/160\n",
      "1140/1140 [==============================] - ETA: 0s - loss: 0.3480 - acc: 0.842 - 1s 559us/step - loss: 0.3471 - acc: 0.8439\n",
      "Epoch 8/160\n",
      "1140/1140 [==============================] - 0s 375us/step - loss: 0.3400 - acc: 0.8390\n",
      "Epoch 9/160\n",
      "1140/1140 [==============================] - 0s 372us/step - loss: 0.3472 - acc: 0.8342\n",
      "Epoch 10/160\n",
      "1140/1140 [==============================] - 0s 409us/step - loss: 0.3429 - acc: 0.8432\n",
      "Epoch 11/160\n",
      "1140/1140 [==============================] - 0s 408us/step - loss: 0.3484 - acc: 0.8351\n",
      "Epoch 12/160\n",
      "1140/1140 [==============================] - 1s 543us/step - loss: 0.3436 - acc: 0.8399\n",
      "Epoch 13/160\n",
      "1140/1140 [==============================] - 1s 503us/step - loss: 0.3356 - acc: 0.8465\n",
      "Epoch 14/160\n",
      "1140/1140 [==============================] - 1s 579us/step - loss: 0.3366 - acc: 0.8364\n",
      "Epoch 15/160\n",
      "1140/1140 [==============================] - 1s 474us/step - loss: 0.3338 - acc: 0.8445\n",
      "Epoch 16/160\n",
      "1140/1140 [==============================] - 0s 359us/step - loss: 0.3327 - acc: 0.8410\n",
      "Epoch 17/160\n",
      "1140/1140 [==============================] - 0s 348us/step - loss: 0.3324 - acc: 0.8430\n",
      "Epoch 18/160\n",
      "1140/1140 [==============================] - 0s 346us/step - loss: 0.3276 - acc: 0.8463\n",
      "Epoch 19/160\n",
      "1140/1140 [==============================] - 0s 389us/step - loss: 0.3324 - acc: 0.8478\n",
      "Epoch 20/160\n",
      "1140/1140 [==============================] - 0s 366us/step - loss: 0.3287 - acc: 0.8450\n",
      "Epoch 21/160\n",
      "1140/1140 [==============================] - 0s 403us/step - loss: 0.3241 - acc: 0.8454\n",
      "Epoch 22/160\n",
      "1140/1140 [==============================] - 0s 371us/step - loss: 0.3338 - acc: 0.8397\n",
      "Epoch 23/160\n",
      "1140/1140 [==============================] - 0s 418us/step - loss: 0.3416 - acc: 0.8327\n",
      "Epoch 24/160\n",
      "1140/1140 [==============================] - 0s 378us/step - loss: 0.3349 - acc: 0.8450\n",
      "Epoch 25/160\n",
      "1140/1140 [==============================] - 0s 353us/step - loss: 0.3276 - acc: 0.8441\n",
      "Epoch 26/160\n",
      "1140/1140 [==============================] - 0s 364us/step - loss: 0.3267 - acc: 0.8496\n",
      "Epoch 27/160\n",
      "1140/1140 [==============================] - 0s 383us/step - loss: 0.3180 - acc: 0.8493\n",
      "Epoch 28/160\n",
      "1140/1140 [==============================] - 0s 392us/step - loss: 0.3227 - acc: 0.8443\n",
      "Epoch 29/160\n",
      "1140/1140 [==============================] - 0s 351us/step - loss: 0.3229 - acc: 0.8544\n",
      "Epoch 30/160\n",
      "1140/1140 [==============================] - 0s 361us/step - loss: 0.3221 - acc: 0.8500\n",
      "Epoch 31/160\n",
      "1140/1140 [==============================] - 0s 359us/step - loss: 0.3242 - acc: 0.8496\n",
      "Epoch 32/160\n",
      "1140/1140 [==============================] - 0s 401us/step - loss: 0.3203 - acc: 0.8524\n",
      "Epoch 33/160\n",
      "1140/1140 [==============================] - 1s 482us/step - loss: 0.3245 - acc: 0.8434\n",
      "Epoch 34/160\n",
      "1140/1140 [==============================] - 0s 391us/step - loss: 0.3165 - acc: 0.8564\n",
      "Epoch 35/160\n",
      "1140/1140 [==============================] - 0s 321us/step - loss: 0.3203 - acc: 0.8461\n",
      "Epoch 36/160\n",
      "1140/1140 [==============================] - 0s 311us/step - loss: 0.3287 - acc: 0.8489\n",
      "Epoch 37/160\n",
      "1140/1140 [==============================] - 0s 324us/step - loss: 0.3233 - acc: 0.8456\n",
      "Epoch 38/160\n",
      "1140/1140 [==============================] - 0s 344us/step - loss: 0.3229 - acc: 0.8509\n",
      "Epoch 39/160\n",
      "1140/1140 [==============================] - 0s 324us/step - loss: 0.3174 - acc: 0.8535\n",
      "Epoch 40/160\n",
      "1140/1140 [==============================] - 0s 312us/step - loss: 0.3138 - acc: 0.8550\n",
      "Epoch 41/160\n",
      "1140/1140 [==============================] - 0s 324us/step - loss: 0.3218 - acc: 0.8529\n",
      "Epoch 42/160\n",
      "1140/1140 [==============================] - 0s 350us/step - loss: 0.3173 - acc: 0.8550\n",
      "Epoch 43/160\n",
      "1140/1140 [==============================] - 0s 304us/step - loss: 0.3175 - acc: 0.8535\n",
      "Epoch 44/160\n",
      "1140/1140 [==============================] - 0s 314us/step - loss: 0.3167 - acc: 0.8507\n",
      "Epoch 45/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.3117 - acc: 0.8522\n",
      "Epoch 46/160\n",
      "1140/1140 [==============================] - 0s 315us/step - loss: 0.3111 - acc: 0.8568\n",
      "Epoch 47/160\n",
      "1140/1140 [==============================] - 0s 318us/step - loss: 0.3095 - acc: 0.8590\n",
      "Epoch 48/160\n",
      "1140/1140 [==============================] - 0s 308us/step - loss: 0.3077 - acc: 0.8557\n",
      "Epoch 49/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.3134 - acc: 0.8566\n",
      "Epoch 50/160\n",
      "1140/1140 [==============================] - 0s 311us/step - loss: 0.3135 - acc: 0.8537\n",
      "Epoch 51/160\n",
      "1140/1140 [==============================] - 0s 303us/step - loss: 0.3109 - acc: 0.8559\n",
      "Epoch 52/160\n",
      "1140/1140 [==============================] - 0s 307us/step - loss: 0.3061 - acc: 0.8550\n",
      "Epoch 53/160\n",
      "1140/1140 [==============================] - 0s 314us/step - loss: 0.3156 - acc: 0.8518\n",
      "Epoch 54/160\n",
      "1140/1140 [==============================] - 0s 296us/step - loss: 0.3058 - acc: 0.8526\n",
      "Epoch 55/160\n",
      "1140/1140 [==============================] - 0s 318us/step - loss: 0.3134 - acc: 0.8504\n",
      "Epoch 56/160\n",
      "1140/1140 [==============================] - 0s 330us/step - loss: 0.3098 - acc: 0.8555\n",
      "Epoch 57/160\n",
      "1140/1140 [==============================] - 0s 313us/step - loss: 0.3207 - acc: 0.8493\n",
      "Epoch 58/160\n",
      "1140/1140 [==============================] - 0s 311us/step - loss: 0.3102 - acc: 0.8522\n",
      "Epoch 59/160\n",
      "1140/1140 [==============================] - 0s 298us/step - loss: 0.3041 - acc: 0.8629\n",
      "Epoch 60/160\n",
      "1140/1140 [==============================] - 0s 296us/step - loss: 0.3116 - acc: 0.8577\n",
      "Epoch 61/160\n",
      "1140/1140 [==============================] - 0s 303us/step - loss: 0.3145 - acc: 0.8561\n",
      "Epoch 62/160\n",
      "1140/1140 [==============================] - 0s 313us/step - loss: 0.3138 - acc: 0.8550\n",
      "Epoch 63/160\n",
      "1140/1140 [==============================] - 0s 303us/step - loss: 0.3052 - acc: 0.8548\n",
      "Epoch 64/160\n",
      "1140/1140 [==============================] - 0s 297us/step - loss: 0.3011 - acc: 0.8603\n",
      "Epoch 65/160\n",
      "1140/1140 [==============================] - 0s 313us/step - loss: 0.3015 - acc: 0.8561\n",
      "Epoch 66/160\n",
      "1140/1140 [==============================] - 0s 319us/step - loss: 0.3050 - acc: 0.8586\n",
      "Epoch 67/160\n",
      "1140/1140 [==============================] - 0s 304us/step - loss: 0.3042 - acc: 0.8592\n",
      "Epoch 68/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.3039 - acc: 0.8544\n",
      "Epoch 69/160\n",
      "1140/1140 [==============================] - 0s 317us/step - loss: 0.3039 - acc: 0.8566\n",
      "Epoch 70/160\n",
      "1140/1140 [==============================] - 0s 304us/step - loss: 0.2988 - acc: 0.8610\n",
      "Epoch 71/160\n",
      "1140/1140 [==============================] - 0s 313us/step - loss: 0.3068 - acc: 0.8568\n",
      "Epoch 72/160\n",
      "1140/1140 [==============================] - 0s 329us/step - loss: 0.3041 - acc: 0.8634\n",
      "Epoch 73/160\n",
      "1140/1140 [==============================] - 0s 313us/step - loss: 0.3112 - acc: 0.8566\n",
      "Epoch 74/160\n",
      "1140/1140 [==============================] - 0s 312us/step - loss: 0.3024 - acc: 0.8575\n",
      "Epoch 75/160\n",
      "1140/1140 [==============================] - 0s 305us/step - loss: 0.3054 - acc: 0.8586\n",
      "Epoch 76/160\n",
      "1140/1140 [==============================] - 0s 319us/step - loss: 0.3024 - acc: 0.8627\n",
      "Epoch 77/160\n",
      "1140/1140 [==============================] - 0s 303us/step - loss: 0.2974 - acc: 0.8616\n",
      "Epoch 78/160\n",
      "1140/1140 [==============================] - 0s 307us/step - loss: 0.3073 - acc: 0.8588\n",
      "Epoch 79/160\n",
      "1140/1140 [==============================] - 0s 305us/step - loss: 0.3023 - acc: 0.8612\n",
      "Epoch 80/160\n",
      "1140/1140 [==============================] - 0s 301us/step - loss: 0.3008 - acc: 0.8673\n",
      "Epoch 81/160\n",
      "1140/1140 [==============================] - 0s 305us/step - loss: 0.2959 - acc: 0.8632\n",
      "Epoch 82/160\n",
      "1140/1140 [==============================] - 0s 298us/step - loss: 0.3010 - acc: 0.8570\n",
      "Epoch 83/160\n",
      "1140/1140 [==============================] - 0s 286us/step - loss: 0.2958 - acc: 0.8682\n",
      "Epoch 84/160\n",
      "1140/1140 [==============================] - 0s 301us/step - loss: 0.2981 - acc: 0.8612\n",
      "Epoch 85/160\n",
      "1140/1140 [==============================] - 0s 318us/step - loss: 0.3065 - acc: 0.8596\n",
      "Epoch 86/160\n",
      "1140/1140 [==============================] - 0s 288us/step - loss: 0.3054 - acc: 0.8557\n",
      "Epoch 87/160\n",
      "1140/1140 [==============================] - 0s 313us/step - loss: 0.3051 - acc: 0.8645\n",
      "Epoch 88/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.3012 - acc: 0.8625\n",
      "Epoch 89/160\n",
      "1140/1140 [==============================] - 0s 321us/step - loss: 0.2982 - acc: 0.8636\n",
      "Epoch 90/160\n",
      "1140/1140 [==============================] - 0s 316us/step - loss: 0.2935 - acc: 0.8702\n",
      "Epoch 91/160\n",
      "1140/1140 [==============================] - 0s 315us/step - loss: 0.2917 - acc: 0.8686\n",
      "Epoch 92/160\n",
      "1140/1140 [==============================] - 0s 302us/step - loss: 0.2987 - acc: 0.8673\n",
      "Epoch 93/160\n",
      "1140/1140 [==============================] - 0s 300us/step - loss: 0.3136 - acc: 0.8524\n",
      "Epoch 94/160\n",
      "1140/1140 [==============================] - 0s 295us/step - loss: 0.2979 - acc: 0.8669\n",
      "Epoch 95/160\n",
      "1140/1140 [==============================] - 0s 306us/step - loss: 0.2948 - acc: 0.8618\n",
      "Epoch 96/160\n",
      "1140/1140 [==============================] - 0s 300us/step - loss: 0.2973 - acc: 0.8625\n",
      "Epoch 97/160\n",
      "1140/1140 [==============================] - 0s 314us/step - loss: 0.2916 - acc: 0.8671\n",
      "Epoch 98/160\n",
      "1140/1140 [==============================] - 0s 287us/step - loss: 0.2965 - acc: 0.8684\n",
      "Epoch 99/160\n",
      "1140/1140 [==============================] - 0s 304us/step - loss: 0.3035 - acc: 0.8559\n",
      "Epoch 100/160\n",
      "1140/1140 [==============================] - 0s 315us/step - loss: 0.2956 - acc: 0.8638\n",
      "Epoch 101/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.2932 - acc: 0.8667\n",
      "Epoch 102/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.2924 - acc: 0.8654\n",
      "Epoch 103/160\n",
      "1140/1140 [==============================] - 0s 313us/step - loss: 0.2862 - acc: 0.8669\n",
      "Epoch 104/160\n",
      "1140/1140 [==============================] - 0s 298us/step - loss: 0.2906 - acc: 0.8651\n",
      "Epoch 105/160\n",
      "1140/1140 [==============================] - 0s 316us/step - loss: 0.2928 - acc: 0.8629\n",
      "Epoch 106/160\n",
      "1140/1140 [==============================] - 0s 324us/step - loss: 0.2911 - acc: 0.8658\n",
      "Epoch 107/160\n",
      "1140/1140 [==============================] - 0s 306us/step - loss: 0.2922 - acc: 0.8664\n",
      "Epoch 108/160\n",
      "1140/1140 [==============================] - 0s 308us/step - loss: 0.2956 - acc: 0.8693\n",
      "Epoch 109/160\n",
      "1140/1140 [==============================] - 0s 311us/step - loss: 0.2940 - acc: 0.8678\n",
      "Epoch 110/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.2862 - acc: 0.8684\n",
      "Epoch 111/160\n",
      "1140/1140 [==============================] - 0s 315us/step - loss: 0.2919 - acc: 0.8697\n",
      "Epoch 112/160\n",
      "1140/1140 [==============================] - 0s 302us/step - loss: 0.3033 - acc: 0.8564\n",
      "Epoch 113/160\n",
      "1140/1140 [==============================] - 0s 298us/step - loss: 0.2874 - acc: 0.8711\n",
      "Epoch 114/160\n",
      "1140/1140 [==============================] - 0s 309us/step - loss: 0.2969 - acc: 0.8649\n",
      "Epoch 115/160\n",
      "1140/1140 [==============================] - 0s 314us/step - loss: 0.2950 - acc: 0.8616\n",
      "Epoch 116/160\n",
      "1140/1140 [==============================] - 0s 306us/step - loss: 0.2931 - acc: 0.8618\n",
      "Epoch 117/160\n",
      "1140/1140 [==============================] - 0s 299us/step - loss: 0.2984 - acc: 0.8590\n",
      "Epoch 118/160\n",
      "1140/1140 [==============================] - 0s 295us/step - loss: 0.2915 - acc: 0.8654\n",
      "Epoch 119/160\n",
      "1140/1140 [==============================] - 0s 316us/step - loss: 0.2856 - acc: 0.8711\n",
      "Epoch 120/160\n",
      "1140/1140 [==============================] - 0s 285us/step - loss: 0.2811 - acc: 0.8737\n",
      "Epoch 121/160\n",
      "1140/1140 [==============================] - 0s 319us/step - loss: 0.2838 - acc: 0.8673\n",
      "Epoch 122/160\n",
      "1140/1140 [==============================] - 0s 304us/step - loss: 0.2892 - acc: 0.8660\n",
      "Epoch 123/160\n",
      "1140/1140 [==============================] - 0s 306us/step - loss: 0.2889 - acc: 0.8662\n",
      "Epoch 124/160\n",
      "1140/1140 [==============================] - 0s 323us/step - loss: 0.2892 - acc: 0.8675\n",
      "Epoch 125/160\n",
      "1140/1140 [==============================] - 0s 307us/step - loss: 0.2913 - acc: 0.8704\n",
      "Epoch 126/160\n",
      "1140/1140 [==============================] - 0s 316us/step - loss: 0.2888 - acc: 0.8702\n",
      "Epoch 127/160\n",
      "1140/1140 [==============================] - 0s 311us/step - loss: 0.2878 - acc: 0.8693\n",
      "Epoch 128/160\n",
      "1140/1140 [==============================] - 0s 294us/step - loss: 0.2873 - acc: 0.8715\n",
      "Epoch 129/160\n",
      "1140/1140 [==============================] - 0s 321us/step - loss: 0.2884 - acc: 0.8623\n",
      "Epoch 130/160\n",
      "1140/1140 [==============================] - 0s 271us/step - loss: 0.2914 - acc: 0.8660\n",
      "Epoch 131/160\n",
      "1140/1140 [==============================] - 0s 272us/step - loss: 0.2839 - acc: 0.8706\n",
      "Epoch 132/160\n",
      "1140/1140 [==============================] - 0s 325us/step - loss: 0.2873 - acc: 0.8671\n",
      "Epoch 133/160\n",
      "1140/1140 [==============================] - 0s 277us/step - loss: 0.2835 - acc: 0.8669\n",
      "Epoch 134/160\n",
      "1140/1140 [==============================] - 0s 273us/step - loss: 0.2868 - acc: 0.8662\n",
      "Epoch 135/160\n",
      "1140/1140 [==============================] - 0s 294us/step - loss: 0.2910 - acc: 0.8682\n",
      "Epoch 136/160\n",
      "1140/1140 [==============================] - 0s 288us/step - loss: 0.2846 - acc: 0.8706\n",
      "Epoch 137/160\n",
      "1140/1140 [==============================] - 0s 267us/step - loss: 0.2916 - acc: 0.8713\n",
      "Epoch 138/160\n",
      "1140/1140 [==============================] - 0s 288us/step - loss: 0.2956 - acc: 0.8680\n",
      "Epoch 139/160\n",
      "1140/1140 [==============================] - 0s 321us/step - loss: 0.2904 - acc: 0.8645\n",
      "Epoch 140/160\n",
      "1140/1140 [==============================] - 0s 291us/step - loss: 0.2777 - acc: 0.8704\n",
      "Epoch 141/160\n",
      "1140/1140 [==============================] - 0s 310us/step - loss: 0.2791 - acc: 0.8719\n",
      "Epoch 142/160\n",
      "1140/1140 [==============================] - 0s 334us/step - loss: 0.2727 - acc: 0.8726\n",
      "Epoch 143/160\n",
      "1140/1140 [==============================] - 0s 312us/step - loss: 0.2814 - acc: 0.8717\n",
      "Epoch 144/160\n",
      "1140/1140 [==============================] - 0s 295us/step - loss: 0.2855 - acc: 0.8704\n",
      "Epoch 145/160\n",
      "1140/1140 [==============================] - 0s 358us/step - loss: 0.2835 - acc: 0.8691\n",
      "Epoch 146/160\n",
      "1140/1140 [==============================] - 0s 342us/step - loss: 0.2769 - acc: 0.8724\n",
      "Epoch 147/160\n",
      "1140/1140 [==============================] - 0s 299us/step - loss: 0.2774 - acc: 0.8735\n",
      "Epoch 148/160\n",
      "1140/1140 [==============================] - 0s 301us/step - loss: 0.2967 - acc: 0.8651\n",
      "Epoch 149/160\n",
      "1140/1140 [==============================] - 0s 312us/step - loss: 0.3063 - acc: 0.8544\n",
      "Epoch 150/160\n",
      "1140/1140 [==============================] - 0s 298us/step - loss: 0.2872 - acc: 0.8680\n",
      "Epoch 151/160\n",
      "1140/1140 [==============================] - 0s 349us/step - loss: 0.2749 - acc: 0.8743\n",
      "Epoch 152/160\n",
      "1140/1140 [==============================] - 0s 389us/step - loss: 0.2767 - acc: 0.8726\n",
      "Epoch 153/160\n",
      "1140/1140 [==============================] - 0s 434us/step - loss: 0.2713 - acc: 0.8750\n",
      "Epoch 154/160\n",
      "1140/1140 [==============================] - 0s 382us/step - loss: 0.2708 - acc: 0.8706\n",
      "Epoch 155/160\n",
      "1140/1140 [==============================] - 0s 359us/step - loss: 0.2750 - acc: 0.8748\n",
      "Epoch 156/160\n",
      "1140/1140 [==============================] - 0s 288us/step - loss: 0.2750 - acc: 0.8708\n",
      "Epoch 157/160\n",
      "1140/1140 [==============================] - 0s 314us/step - loss: 0.2799 - acc: 0.8708\n",
      "Epoch 158/160\n",
      "1140/1140 [==============================] - 0s 411us/step - loss: 0.2794 - acc: 0.8715\n",
      "Epoch 159/160\n",
      "1140/1140 [==============================] - 0s 343us/step - loss: 0.2751 - acc: 0.8746\n",
      "Epoch 160/160\n",
      "1140/1140 [==============================] - 0s 393us/step - loss: 0.2777 - acc: 0.8711\n",
      "286/286 [==============================] - 0s 817us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140/1140 [==============================] - 0s 61us/step\n",
      "\n",
      "acc: 84.97%\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "[[ 63  20   0   1]\n",
      " [ 20 156   2   0]\n",
      " [  1   5  10   0]\n",
      " [  2   0   0   6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.73      0.75      0.74        84\n",
      "      Normal       0.86      0.88      0.87       178\n",
      "        Slow       0.83      0.62      0.71        16\n",
      "   Very Fast       0.86      0.75      0.80         8\n",
      "\n",
      "    accuracy                           0.82       286\n",
      "   macro avg       0.82      0.75      0.78       286\n",
      "weighted avg       0.82      0.82      0.82       286\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8216783216783217"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[df_k.Timelevel==3]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy Timelevel 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "1215/1215 [==============================] - 1s 936us/step - loss: 0.4339 - acc: 0.8152\n",
      "Epoch 2/160\n",
      "1215/1215 [==============================] - 0s 321us/step - loss: 0.3888 - acc: 0.8319\n",
      "Epoch 3/160\n",
      "1215/1215 [==============================] - 0s 291us/step - loss: 0.3788 - acc: 0.8360\n",
      "Epoch 4/160\n",
      "1215/1215 [==============================] - 0s 295us/step - loss: 0.3728 - acc: 0.8342\n",
      "Epoch 5/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.3715 - acc: 0.8399\n",
      "Epoch 6/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.3733 - acc: 0.8434\n",
      "Epoch 7/160\n",
      "1215/1215 [==============================] - 0s 303us/step - loss: 0.3650 - acc: 0.8414\n",
      "Epoch 8/160\n",
      "1215/1215 [==============================] - 0s 370us/step - loss: 0.3659 - acc: 0.8430\n",
      "Epoch 9/160\n",
      "1215/1215 [==============================] - 0s 310us/step - loss: 0.3596 - acc: 0.8434\n",
      "Epoch 10/160\n",
      "1215/1215 [==============================] - 0s 308us/step - loss: 0.3639 - acc: 0.8447\n",
      "Epoch 11/160\n",
      "1215/1215 [==============================] - 0s 381us/step - loss: 0.3610 - acc: 0.8428\n",
      "Epoch 12/160\n",
      "1215/1215 [==============================] - 0s 403us/step - loss: 0.3643 - acc: 0.8447\n",
      "Epoch 13/160\n",
      "1215/1215 [==============================] - 0s 365us/step - loss: 0.3584 - acc: 0.8436\n",
      "Epoch 14/160\n",
      "1215/1215 [==============================] - 0s 348us/step - loss: 0.3557 - acc: 0.8426\n",
      "Epoch 15/160\n",
      "1215/1215 [==============================] - 0s 309us/step - loss: 0.3595 - acc: 0.8385\n",
      "Epoch 16/160\n",
      "1215/1215 [==============================] - 0s 305us/step - loss: 0.3581 - acc: 0.8428\n",
      "Epoch 17/160\n",
      "1215/1215 [==============================] - 0s 308us/step - loss: 0.3562 - acc: 0.8447\n",
      "Epoch 18/160\n",
      "1215/1215 [==============================] - 0s 315us/step - loss: 0.3527 - acc: 0.8434\n",
      "Epoch 19/160\n",
      "1215/1215 [==============================] - 0s 308us/step - loss: 0.3510 - acc: 0.8430\n",
      "Epoch 20/160\n",
      "1215/1215 [==============================] - 0s 316us/step - loss: 0.3558 - acc: 0.8459\n",
      "Epoch 21/160\n",
      "1215/1215 [==============================] - 0s 320us/step - loss: 0.3506 - acc: 0.8409\n",
      "Epoch 22/160\n",
      "1215/1215 [==============================] - 0s 299us/step - loss: 0.3537 - acc: 0.8440\n",
      "Epoch 23/160\n",
      "1215/1215 [==============================] - 0s 307us/step - loss: 0.3488 - acc: 0.8428\n",
      "Epoch 24/160\n",
      "1215/1215 [==============================] - 0s 305us/step - loss: 0.3444 - acc: 0.8459\n",
      "Epoch 25/160\n",
      "1215/1215 [==============================] - 0s 313us/step - loss: 0.3514 - acc: 0.8449\n",
      "Epoch 26/160\n",
      "1215/1215 [==============================] - 0s 307us/step - loss: 0.3495 - acc: 0.8477\n",
      "Epoch 27/160\n",
      "1215/1215 [==============================] - 0s 314us/step - loss: 0.3470 - acc: 0.8455\n",
      "Epoch 28/160\n",
      "1215/1215 [==============================] - 0s 323us/step - loss: 0.3448 - acc: 0.8461\n",
      "Epoch 29/160\n",
      "1215/1215 [==============================] - 0s 353us/step - loss: 0.3473 - acc: 0.8434\n",
      "Epoch 30/160\n",
      "1215/1215 [==============================] - 0s 340us/step - loss: 0.3483 - acc: 0.8440\n",
      "Epoch 31/160\n",
      "1215/1215 [==============================] - 0s 312us/step - loss: 0.3460 - acc: 0.8430\n",
      "Epoch 32/160\n",
      "1215/1215 [==============================] - 0s 311us/step - loss: 0.3435 - acc: 0.8426\n",
      "Epoch 33/160\n",
      "1215/1215 [==============================] - 0s 306us/step - loss: 0.3497 - acc: 0.8449\n",
      "Epoch 34/160\n",
      "1215/1215 [==============================] - 0s 301us/step - loss: 0.3435 - acc: 0.8438\n",
      "Epoch 35/160\n",
      "1215/1215 [==============================] - 0s 302us/step - loss: 0.3376 - acc: 0.8455\n",
      "Epoch 36/160\n",
      "1215/1215 [==============================] - 0s 325us/step - loss: 0.3426 - acc: 0.8442\n",
      "Epoch 37/160\n",
      "1215/1215 [==============================] - 0s 323us/step - loss: 0.3419 - acc: 0.8498\n",
      "Epoch 38/160\n",
      "1215/1215 [==============================] - 0s 318us/step - loss: 0.3381 - acc: 0.8461\n",
      "Epoch 39/160\n",
      "1215/1215 [==============================] - 0s 295us/step - loss: 0.3337 - acc: 0.8498\n",
      "Epoch 40/160\n",
      "1215/1215 [==============================] - 0s 313us/step - loss: 0.3433 - acc: 0.8438\n",
      "Epoch 41/160\n",
      "1215/1215 [==============================] - 0s 304us/step - loss: 0.3442 - acc: 0.8418\n",
      "Epoch 42/160\n",
      "1215/1215 [==============================] - 0s 309us/step - loss: 0.3315 - acc: 0.8492\n",
      "Epoch 43/160\n",
      "1215/1215 [==============================] - 0s 301us/step - loss: 0.3439 - acc: 0.8473\n",
      "Epoch 44/160\n",
      "1215/1215 [==============================] - 0s 324us/step - loss: 0.3419 - acc: 0.8426\n",
      "Epoch 45/160\n",
      "1215/1215 [==============================] - 0s 330us/step - loss: 0.3368 - acc: 0.8527\n",
      "Epoch 46/160\n",
      "1215/1215 [==============================] - 0s 328us/step - loss: 0.3320 - acc: 0.8506\n",
      "Epoch 47/160\n",
      "1215/1215 [==============================] - 0s 322us/step - loss: 0.3334 - acc: 0.8471\n",
      "Epoch 48/160\n",
      "1215/1215 [==============================] - 0s 322us/step - loss: 0.3355 - acc: 0.8444\n",
      "Epoch 49/160\n",
      "1215/1215 [==============================] - 0s 289us/step - loss: 0.3317 - acc: 0.8529\n",
      "Epoch 50/160\n",
      "1215/1215 [==============================] - 0s 319us/step - loss: 0.3377 - acc: 0.8477\n",
      "Epoch 51/160\n",
      "1215/1215 [==============================] - 0s 320us/step - loss: 0.3301 - acc: 0.8498\n",
      "Epoch 52/160\n",
      "1215/1215 [==============================] - 0s 326us/step - loss: 0.3302 - acc: 0.8465\n",
      "Epoch 53/160\n",
      "1215/1215 [==============================] - 0s 327us/step - loss: 0.3332 - acc: 0.8467\n",
      "Epoch 54/160\n",
      "1215/1215 [==============================] - 0s 308us/step - loss: 0.3309 - acc: 0.8473\n",
      "Epoch 55/160\n",
      "1215/1215 [==============================] - 0s 310us/step - loss: 0.3335 - acc: 0.8467\n",
      "Epoch 56/160\n",
      "1215/1215 [==============================] - 0s 293us/step - loss: 0.3286 - acc: 0.8506\n",
      "Epoch 57/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.3331 - acc: 0.8475\n",
      "Epoch 58/160\n",
      "1215/1215 [==============================] - 0s 299us/step - loss: 0.3323 - acc: 0.8492\n",
      "Epoch 59/160\n",
      "1215/1215 [==============================] - 0s 343us/step - loss: 0.3387 - acc: 0.8405\n",
      "Epoch 60/160\n",
      "1215/1215 [==============================] - 0s 309us/step - loss: 0.3302 - acc: 0.8523\n",
      "Epoch 61/160\n",
      "1215/1215 [==============================] - 0s 309us/step - loss: 0.3336 - acc: 0.8486\n",
      "Epoch 62/160\n",
      "1215/1215 [==============================] - 0s 302us/step - loss: 0.3418 - acc: 0.8467\n",
      "Epoch 63/160\n",
      "1215/1215 [==============================] - 0s 303us/step - loss: 0.3297 - acc: 0.8494\n",
      "Epoch 64/160\n",
      "1215/1215 [==============================] - 0s 334us/step - loss: 0.3298 - acc: 0.8506\n",
      "Epoch 65/160\n",
      "1215/1215 [==============================] - 0s 318us/step - loss: 0.3317 - acc: 0.8514\n",
      "Epoch 66/160\n",
      "1215/1215 [==============================] - 0s 329us/step - loss: 0.3262 - acc: 0.8516\n",
      "Epoch 67/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.3223 - acc: 0.8551\n",
      "Epoch 68/160\n",
      "1215/1215 [==============================] - 0s 323us/step - loss: 0.3266 - acc: 0.8506\n",
      "Epoch 69/160\n",
      "1215/1215 [==============================] - 0s 307us/step - loss: 0.3252 - acc: 0.8525\n",
      "Epoch 70/160\n",
      "1215/1215 [==============================] - 0s 309us/step - loss: 0.3206 - acc: 0.8566\n",
      "Epoch 71/160\n",
      "1215/1215 [==============================] - 0s 308us/step - loss: 0.3232 - acc: 0.8521\n",
      "Epoch 72/160\n",
      "1215/1215 [==============================] - 0s 393us/step - loss: 0.3262 - acc: 0.8506\n",
      "Epoch 73/160\n",
      "1215/1215 [==============================] - 0s 323us/step - loss: 0.3224 - acc: 0.8533\n",
      "Epoch 74/160\n",
      "1215/1215 [==============================] - 0s 333us/step - loss: 0.3258 - acc: 0.8541\n",
      "Epoch 75/160\n",
      "1215/1215 [==============================] - 0s 334us/step - loss: 0.3211 - acc: 0.8523\n",
      "Epoch 76/160\n",
      "1215/1215 [==============================] - 0s 303us/step - loss: 0.3263 - acc: 0.8537\n",
      "Epoch 77/160\n",
      "1215/1215 [==============================] - 0s 319us/step - loss: 0.3250 - acc: 0.8488\n",
      "Epoch 78/160\n",
      "1215/1215 [==============================] - 0s 354us/step - loss: 0.3239 - acc: 0.8514\n",
      "Epoch 79/160\n",
      "1215/1215 [==============================] - 0s 309us/step - loss: 0.3187 - acc: 0.8541\n",
      "Epoch 80/160\n",
      "1215/1215 [==============================] - 0s 321us/step - loss: 0.3164 - acc: 0.8588\n",
      "Epoch 81/160\n",
      "1215/1215 [==============================] - 0s 348us/step - loss: 0.3246 - acc: 0.8535\n",
      "Epoch 82/160\n",
      "1215/1215 [==============================] - 0s 298us/step - loss: 0.3166 - acc: 0.8586\n",
      "Epoch 83/160\n",
      "1215/1215 [==============================] - 0s 303us/step - loss: 0.3185 - acc: 0.8525\n",
      "Epoch 84/160\n",
      "1215/1215 [==============================] - 0s 280us/step - loss: 0.3162 - acc: 0.8570\n",
      "Epoch 85/160\n",
      "1215/1215 [==============================] - 0s 301us/step - loss: 0.3148 - acc: 0.8551\n",
      "Epoch 86/160\n",
      "1215/1215 [==============================] - 0s 357us/step - loss: 0.3191 - acc: 0.8556\n",
      "Epoch 87/160\n",
      "1215/1215 [==============================] - 0s 337us/step - loss: 0.3087 - acc: 0.8634\n",
      "Epoch 88/160\n",
      "1215/1215 [==============================] - 0s 307us/step - loss: 0.3185 - acc: 0.8595\n",
      "Epoch 89/160\n",
      "1215/1215 [==============================] - 0s 296us/step - loss: 0.3146 - acc: 0.8570\n",
      "Epoch 90/160\n",
      "1215/1215 [==============================] - 0s 318us/step - loss: 0.3207 - acc: 0.8566\n",
      "Epoch 91/160\n",
      "1215/1215 [==============================] - 0s 331us/step - loss: 0.3091 - acc: 0.8603\n",
      "Epoch 92/160\n",
      "1215/1215 [==============================] - 0s 344us/step - loss: 0.3194 - acc: 0.8586\n",
      "Epoch 93/160\n",
      "1215/1215 [==============================] - 0s 318us/step - loss: 0.3151 - acc: 0.8593\n",
      "Epoch 94/160\n",
      "1215/1215 [==============================] - 0s 290us/step - loss: 0.3147 - acc: 0.8593\n",
      "Epoch 95/160\n",
      "1215/1215 [==============================] - 0s 282us/step - loss: 0.3285 - acc: 0.8525\n",
      "Epoch 96/160\n",
      "1215/1215 [==============================] - 0s 310us/step - loss: 0.3233 - acc: 0.8553\n",
      "Epoch 97/160\n",
      "1215/1215 [==============================] - 0s 302us/step - loss: 0.3134 - acc: 0.8580\n",
      "Epoch 98/160\n",
      "1215/1215 [==============================] - 0s 289us/step - loss: 0.3186 - acc: 0.8543\n",
      "Epoch 99/160\n",
      "1215/1215 [==============================] - 0s 285us/step - loss: 0.3067 - acc: 0.8619\n",
      "Epoch 100/160\n",
      "1215/1215 [==============================] - 0s 286us/step - loss: 0.3063 - acc: 0.8607\n",
      "Epoch 101/160\n",
      "1215/1215 [==============================] - 0s 284us/step - loss: 0.3212 - acc: 0.8506\n",
      "Epoch 102/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.3199 - acc: 0.8541\n",
      "Epoch 103/160\n",
      "1215/1215 [==============================] - 0s 289us/step - loss: 0.3022 - acc: 0.8638\n",
      "Epoch 104/160\n",
      "1215/1215 [==============================] - 0s 301us/step - loss: 0.3076 - acc: 0.8626\n",
      "Epoch 105/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.3114 - acc: 0.8593\n",
      "Epoch 106/160\n",
      "1215/1215 [==============================] - 0s 303us/step - loss: 0.3113 - acc: 0.8521\n",
      "Epoch 107/160\n",
      "1215/1215 [==============================] - 0s 295us/step - loss: 0.3156 - acc: 0.8599\n",
      "Epoch 108/160\n",
      "1215/1215 [==============================] - 0s 305us/step - loss: 0.3084 - acc: 0.8601\n",
      "Epoch 109/160\n",
      "1215/1215 [==============================] - 0s 297us/step - loss: 0.3254 - acc: 0.8481\n",
      "Epoch 110/160\n",
      "1215/1215 [==============================] - 0s 274us/step - loss: 0.3106 - acc: 0.8568\n",
      "Epoch 111/160\n",
      "1215/1215 [==============================] - 0s 293us/step - loss: 0.3125 - acc: 0.8591\n",
      "Epoch 112/160\n",
      "1215/1215 [==============================] - 0s 283us/step - loss: 0.3048 - acc: 0.8621\n",
      "Epoch 113/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.3012 - acc: 0.8601\n",
      "Epoch 114/160\n",
      "1215/1215 [==============================] - 0s 286us/step - loss: 0.3072 - acc: 0.8564\n",
      "Epoch 115/160\n",
      "1215/1215 [==============================] - 0s 296us/step - loss: 0.3073 - acc: 0.8588\n",
      "Epoch 116/160\n",
      "1215/1215 [==============================] - 0s 297us/step - loss: 0.3121 - acc: 0.8580\n",
      "Epoch 117/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.3147 - acc: 0.8619\n",
      "Epoch 118/160\n",
      "1215/1215 [==============================] - 0s 291us/step - loss: 0.3182 - acc: 0.8543\n",
      "Epoch 119/160\n",
      "1215/1215 [==============================] - 0s 280us/step - loss: 0.3068 - acc: 0.8613\n",
      "Epoch 120/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.3107 - acc: 0.8572\n",
      "Epoch 121/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.3008 - acc: 0.8617\n",
      "Epoch 122/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.3033 - acc: 0.8597\n",
      "Epoch 123/160\n",
      "1215/1215 [==============================] - 0s 308us/step - loss: 0.2986 - acc: 0.8611\n",
      "Epoch 124/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.3057 - acc: 0.8599\n",
      "Epoch 125/160\n",
      "1215/1215 [==============================] - 0s 307us/step - loss: 0.3000 - acc: 0.8599\n",
      "Epoch 126/160\n",
      "1215/1215 [==============================] - 0s 317us/step - loss: 0.3004 - acc: 0.8621\n",
      "Epoch 127/160\n",
      "1215/1215 [==============================] - 0s 312us/step - loss: 0.2931 - acc: 0.8673\n",
      "Epoch 128/160\n",
      "1215/1215 [==============================] - 0s 317us/step - loss: 0.3016 - acc: 0.8605\n",
      "Epoch 129/160\n",
      "1215/1215 [==============================] - 0s 284us/step - loss: 0.3041 - acc: 0.8644\n",
      "Epoch 130/160\n",
      "1215/1215 [==============================] - 0s 295us/step - loss: 0.3080 - acc: 0.8578\n",
      "Epoch 131/160\n",
      "1215/1215 [==============================] - 0s 280us/step - loss: 0.2949 - acc: 0.8613\n",
      "Epoch 132/160\n",
      "1215/1215 [==============================] - 0s 278us/step - loss: 0.2968 - acc: 0.8595\n",
      "Epoch 133/160\n",
      "1215/1215 [==============================] - 0s 286us/step - loss: 0.2936 - acc: 0.8630\n",
      "Epoch 134/160\n",
      "1215/1215 [==============================] - 0s 302us/step - loss: 0.2929 - acc: 0.8642\n",
      "Epoch 135/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.2960 - acc: 0.8626\n",
      "Epoch 136/160\n",
      "1215/1215 [==============================] - 0s 288us/step - loss: 0.3099 - acc: 0.8584\n",
      "Epoch 137/160\n",
      "1215/1215 [==============================] - 0s 285us/step - loss: 0.2979 - acc: 0.8628\n",
      "Epoch 138/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.3027 - acc: 0.8609\n",
      "Epoch 139/160\n",
      "1215/1215 [==============================] - 0s 305us/step - loss: 0.2872 - acc: 0.8708\n",
      "Epoch 140/160\n",
      "1215/1215 [==============================] - 0s 311us/step - loss: 0.2914 - acc: 0.8733\n",
      "Epoch 141/160\n",
      "1215/1215 [==============================] - 0s 317us/step - loss: 0.3018 - acc: 0.8656\n",
      "Epoch 142/160\n",
      "1215/1215 [==============================] - 0s 302us/step - loss: 0.2892 - acc: 0.8652\n",
      "Epoch 143/160\n",
      "1215/1215 [==============================] - 0s 283us/step - loss: 0.2833 - acc: 0.8743\n",
      "Epoch 144/160\n",
      "1215/1215 [==============================] - 0s 294us/step - loss: 0.2975 - acc: 0.8640\n",
      "Epoch 145/160\n",
      "1215/1215 [==============================] - 0s 300us/step - loss: 0.2968 - acc: 0.8636\n",
      "Epoch 146/160\n",
      "1215/1215 [==============================] - 0s 286us/step - loss: 0.2953 - acc: 0.8677\n",
      "Epoch 147/160\n",
      "1215/1215 [==============================] - 0s 296us/step - loss: 0.3063 - acc: 0.8658\n",
      "Epoch 148/160\n",
      "1215/1215 [==============================] - 0s 279us/step - loss: 0.2935 - acc: 0.8665\n",
      "Epoch 149/160\n",
      "1215/1215 [==============================] - 0s 298us/step - loss: 0.2921 - acc: 0.8630\n",
      "Epoch 150/160\n",
      "1215/1215 [==============================] - 0s 292us/step - loss: 0.2883 - acc: 0.8660\n",
      "Epoch 151/160\n",
      "1215/1215 [==============================] - 0s 305us/step - loss: 0.2830 - acc: 0.8669\n",
      "Epoch 152/160\n",
      "1215/1215 [==============================] - 0s 285us/step - loss: 0.2761 - acc: 0.8679\n",
      "Epoch 153/160\n",
      "1215/1215 [==============================] - 0s 299us/step - loss: 0.2797 - acc: 0.8704\n",
      "Epoch 154/160\n",
      "1215/1215 [==============================] - 0s 293us/step - loss: 0.2811 - acc: 0.8660\n",
      "Epoch 155/160\n",
      "1215/1215 [==============================] - 0s 288us/step - loss: 0.2813 - acc: 0.8695\n",
      "Epoch 156/160\n",
      "1215/1215 [==============================] - 0s 323us/step - loss: 0.2783 - acc: 0.8700\n",
      "Epoch 157/160\n",
      "1215/1215 [==============================] - 0s 304us/step - loss: 0.2764 - acc: 0.8728\n",
      "Epoch 158/160\n",
      "1215/1215 [==============================] - 0s 308us/step - loss: 0.2768 - acc: 0.8728\n",
      "Epoch 159/160\n",
      "1215/1215 [==============================] - 0s 284us/step - loss: 0.2810 - acc: 0.8698\n",
      "Epoch 160/160\n",
      "1215/1215 [==============================] - 0s 291us/step - loss: 0.2835 - acc: 0.8640\n",
      "304/304 [==============================] - 0s 745us/step\n",
      "1215/1215 [==============================] - 0s 68us/step\n",
      "\n",
      "acc: 82.07%\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[ 35  25   3   0]\n",
      " [ 10 175  10   0]\n",
      " [  0  10  23   0]\n",
      " [  2   2   2   7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.74      0.56      0.64        63\n",
      "      Normal       0.83      0.90      0.86       195\n",
      "        Slow       0.61      0.70      0.65        33\n",
      "   Very Fast       1.00      0.54      0.70        13\n",
      "\n",
      "    accuracy                           0.79       304\n",
      "   macro avg       0.79      0.67      0.71       304\n",
      "weighted avg       0.79      0.79      0.78       304\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7894736842105263"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[df_k.Timelevel==4]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy timelevel 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "717/717 [==============================] - 1s 2ms/step - loss: 0.5040 - acc: 0.7503\n",
      "Epoch 2/160\n",
      "717/717 [==============================] - 0s 324us/step - loss: 0.4567 - acc: 0.7629\n",
      "Epoch 3/160\n",
      "717/717 [==============================] - 0s 336us/step - loss: 0.4448 - acc: 0.7810\n",
      "Epoch 4/160\n",
      "717/717 [==============================] - 0s 316us/step - loss: 0.4319 - acc: 0.7877\n",
      "Epoch 5/160\n",
      "717/717 [==============================] - 0s 323us/step - loss: 0.4399 - acc: 0.7779\n",
      "Epoch 6/160\n",
      "717/717 [==============================] - 0s 314us/step - loss: 0.4156 - acc: 0.8006\n",
      "Epoch 7/160\n",
      "717/717 [==============================] - 0s 365us/step - loss: 0.4119 - acc: 0.7964\n",
      "Epoch 8/160\n",
      "717/717 [==============================] - 0s 326us/step - loss: 0.4091 - acc: 0.7918\n",
      "Epoch 9/160\n",
      "717/717 [==============================] - 0s 324us/step - loss: 0.4057 - acc: 0.8006\n",
      "Epoch 10/160\n",
      "717/717 [==============================] - 0s 299us/step - loss: 0.4072 - acc: 0.8026\n",
      "Epoch 11/160\n",
      "717/717 [==============================] - 0s 291us/step - loss: 0.4143 - acc: 0.7936\n",
      "Epoch 12/160\n",
      "717/717 [==============================] - 0s 367us/step - loss: 0.4078 - acc: 0.8033\n",
      "Epoch 13/160\n",
      "717/717 [==============================] - 0s 397us/step - loss: 0.4040 - acc: 0.8089\n",
      "Epoch 14/160\n",
      "717/717 [==============================] - 0s 353us/step - loss: 0.4025 - acc: 0.8075\n",
      "Epoch 15/160\n",
      "717/717 [==============================] - 0s 305us/step - loss: 0.3973 - acc: 0.8072\n",
      "Epoch 16/160\n",
      "717/717 [==============================] - 0s 328us/step - loss: 0.4020 - acc: 0.8026\n",
      "Epoch 17/160\n",
      "717/717 [==============================] - 0s 316us/step - loss: 0.3977 - acc: 0.8086\n",
      "Epoch 18/160\n",
      "717/717 [==============================] - 0s 332us/step - loss: 0.3917 - acc: 0.8187\n",
      "Epoch 19/160\n",
      "717/717 [==============================] - 0s 336us/step - loss: 0.3891 - acc: 0.8229\n",
      "Epoch 20/160\n",
      "717/717 [==============================] - 0s 317us/step - loss: 0.3863 - acc: 0.8197\n",
      "Epoch 21/160\n",
      "717/717 [==============================] - 0s 321us/step - loss: 0.3898 - acc: 0.8180\n",
      "Epoch 22/160\n",
      "717/717 [==============================] - 0s 315us/step - loss: 0.3878 - acc: 0.8201\n",
      "Epoch 23/160\n",
      "717/717 [==============================] - 0s 311us/step - loss: 0.3887 - acc: 0.8162\n",
      "Epoch 24/160\n",
      "717/717 [==============================] - 0s 322us/step - loss: 0.3945 - acc: 0.8107\n",
      "Epoch 25/160\n",
      "717/717 [==============================] - 0s 307us/step - loss: 0.3841 - acc: 0.8197\n",
      "Epoch 26/160\n",
      "717/717 [==============================] - 0s 330us/step - loss: 0.3877 - acc: 0.8159\n",
      "Epoch 27/160\n",
      "717/717 [==============================] - 0s 309us/step - loss: 0.3847 - acc: 0.8243\n",
      "Epoch 28/160\n",
      "717/717 [==============================] - 0s 294us/step - loss: 0.3839 - acc: 0.8183\n",
      "Epoch 29/160\n",
      "717/717 [==============================] - 0s 310us/step - loss: 0.3799 - acc: 0.8239\n",
      "Epoch 30/160\n",
      "717/717 [==============================] - 0s 318us/step - loss: 0.3798 - acc: 0.8257\n",
      "Epoch 31/160\n",
      "717/717 [==============================] - 0s 307us/step - loss: 0.3787 - acc: 0.8232\n",
      "Epoch 32/160\n",
      "717/717 [==============================] - 0s 326us/step - loss: 0.3864 - acc: 0.8204\n",
      "Epoch 33/160\n",
      "717/717 [==============================] - 0s 320us/step - loss: 0.3827 - acc: 0.8243\n",
      "Epoch 34/160\n",
      "717/717 [==============================] - 0s 321us/step - loss: 0.3791 - acc: 0.8298\n",
      "Epoch 35/160\n",
      "717/717 [==============================] - 0s 303us/step - loss: 0.3804 - acc: 0.8250\n",
      "Epoch 36/160\n",
      "717/717 [==============================] - 0s 315us/step - loss: 0.3767 - acc: 0.8253\n",
      "Epoch 37/160\n",
      "717/717 [==============================] - 0s 329us/step - loss: 0.3791 - acc: 0.8232\n",
      "Epoch 38/160\n",
      "717/717 [==============================] - 0s 303us/step - loss: 0.3796 - acc: 0.8225\n",
      "Epoch 39/160\n",
      "717/717 [==============================] - 0s 315us/step - loss: 0.3752 - acc: 0.8229\n",
      "Epoch 40/160\n",
      "717/717 [==============================] - 0s 300us/step - loss: 0.3758 - acc: 0.8246\n",
      "Epoch 41/160\n",
      "717/717 [==============================] - 0s 331us/step - loss: 0.3728 - acc: 0.8354\n",
      "Epoch 42/160\n",
      "717/717 [==============================] - 0s 316us/step - loss: 0.3768 - acc: 0.8218\n",
      "Epoch 43/160\n",
      "717/717 [==============================] - 0s 307us/step - loss: 0.3753 - acc: 0.8250\n",
      "Epoch 44/160\n",
      "717/717 [==============================] - 0s 305us/step - loss: 0.3758 - acc: 0.8285\n",
      "Epoch 45/160\n",
      "717/717 [==============================] - 0s 341us/step - loss: 0.3778 - acc: 0.8208\n",
      "Epoch 46/160\n",
      "717/717 [==============================] - 0s 337us/step - loss: 0.3722 - acc: 0.8285\n",
      "Epoch 47/160\n",
      "717/717 [==============================] - 0s 329us/step - loss: 0.3746 - acc: 0.8298\n",
      "Epoch 48/160\n",
      "717/717 [==============================] - 0s 304us/step - loss: 0.3812 - acc: 0.8222\n",
      "Epoch 49/160\n",
      "717/717 [==============================] - 0s 319us/step - loss: 0.3717 - acc: 0.8271\n",
      "Epoch 50/160\n",
      "717/717 [==============================] - 0s 312us/step - loss: 0.3713 - acc: 0.8305\n",
      "Epoch 51/160\n",
      "717/717 [==============================] - 0s 316us/step - loss: 0.3678 - acc: 0.8316\n",
      "Epoch 52/160\n",
      "717/717 [==============================] - 0s 326us/step - loss: 0.3662 - acc: 0.8319\n",
      "Epoch 53/160\n",
      "717/717 [==============================] - 0s 321us/step - loss: 0.3701 - acc: 0.8285\n",
      "Epoch 54/160\n",
      "717/717 [==============================] - 0s 302us/step - loss: 0.3642 - acc: 0.8291\n",
      "Epoch 55/160\n",
      "717/717 [==============================] - 0s 334us/step - loss: 0.3835 - acc: 0.8218\n",
      "Epoch 56/160\n",
      "717/717 [==============================] - 0s 314us/step - loss: 0.3721 - acc: 0.8243\n",
      "Epoch 57/160\n",
      "717/717 [==============================] - 0s 308us/step - loss: 0.3730 - acc: 0.8302\n",
      "Epoch 58/160\n",
      "717/717 [==============================] - 0s 305us/step - loss: 0.3857 - acc: 0.8128\n",
      "Epoch 59/160\n",
      "717/717 [==============================] - 0s 315us/step - loss: 0.3744 - acc: 0.8288\n",
      "Epoch 60/160\n",
      "717/717 [==============================] - 0s 318us/step - loss: 0.3679 - acc: 0.8323\n",
      "Epoch 61/160\n",
      "717/717 [==============================] - 0s 294us/step - loss: 0.3777 - acc: 0.8236\n",
      "Epoch 62/160\n",
      "717/717 [==============================] - 0s 309us/step - loss: 0.3740 - acc: 0.8260\n",
      "Epoch 63/160\n",
      "717/717 [==============================] - 0s 304us/step - loss: 0.3695 - acc: 0.8267\n",
      "Epoch 64/160\n",
      "717/717 [==============================] - 0s 313us/step - loss: 0.3696 - acc: 0.8312\n",
      "Epoch 65/160\n",
      "717/717 [==============================] - 0s 312us/step - loss: 0.3636 - acc: 0.8260\n",
      "Epoch 66/160\n",
      "717/717 [==============================] - 0s 308us/step - loss: 0.3662 - acc: 0.8330\n",
      "Epoch 67/160\n",
      "717/717 [==============================] - 0s 306us/step - loss: 0.3612 - acc: 0.8305\n",
      "Epoch 68/160\n",
      "717/717 [==============================] - 0s 329us/step - loss: 0.3689 - acc: 0.8264\n",
      "Epoch 69/160\n",
      "717/717 [==============================] - 0s 316us/step - loss: 0.3639 - acc: 0.8344\n",
      "Epoch 70/160\n",
      "717/717 [==============================] - 0s 301us/step - loss: 0.3596 - acc: 0.8382\n",
      "Epoch 71/160\n",
      "717/717 [==============================] - 0s 327us/step - loss: 0.3654 - acc: 0.8305\n",
      "Epoch 72/160\n",
      "717/717 [==============================] - 0s 330us/step - loss: 0.3779 - acc: 0.8309\n",
      "Epoch 73/160\n",
      "717/717 [==============================] - 0s 356us/step - loss: 0.3647 - acc: 0.8344\n",
      "Epoch 74/160\n",
      "717/717 [==============================] - 0s 331us/step - loss: 0.3647 - acc: 0.8333\n",
      "Epoch 75/160\n",
      "717/717 [==============================] - 0s 311us/step - loss: 0.3722 - acc: 0.8267\n",
      "Epoch 76/160\n",
      "717/717 [==============================] - 0s 334us/step - loss: 0.3612 - acc: 0.8319\n",
      "Epoch 77/160\n",
      "717/717 [==============================] - 0s 342us/step - loss: 0.3610 - acc: 0.8375\n",
      "Epoch 78/160\n",
      "717/717 [==============================] - 0s 324us/step - loss: 0.3615 - acc: 0.8288\n",
      "Epoch 79/160\n",
      "717/717 [==============================] - 0s 326us/step - loss: 0.3559 - acc: 0.8396\n",
      "Epoch 80/160\n",
      "717/717 [==============================] - 0s 322us/step - loss: 0.3546 - acc: 0.8354\n",
      "Epoch 81/160\n",
      "717/717 [==============================] - 0s 361us/step - loss: 0.3553 - acc: 0.8365\n",
      "Epoch 82/160\n",
      "717/717 [==============================] - 0s 332us/step - loss: 0.3563 - acc: 0.8375\n",
      "Epoch 83/160\n",
      "717/717 [==============================] - 0s 321us/step - loss: 0.3549 - acc: 0.8403\n",
      "Epoch 84/160\n",
      "717/717 [==============================] - 0s 378us/step - loss: 0.3602 - acc: 0.8267\n",
      "Epoch 85/160\n",
      "717/717 [==============================] - 0s 339us/step - loss: 0.3615 - acc: 0.8351\n",
      "Epoch 86/160\n",
      "717/717 [==============================] - 0s 321us/step - loss: 0.3607 - acc: 0.8243\n",
      "Epoch 87/160\n",
      "717/717 [==============================] - 0s 318us/step - loss: 0.3546 - acc: 0.8316\n",
      "Epoch 88/160\n",
      "717/717 [==============================] - 0s 333us/step - loss: 0.3641 - acc: 0.8316\n",
      "Epoch 89/160\n",
      "717/717 [==============================] - 0s 300us/step - loss: 0.3662 - acc: 0.8298\n",
      "Epoch 90/160\n",
      "717/717 [==============================] - 0s 300us/step - loss: 0.3621 - acc: 0.8295\n",
      "Epoch 91/160\n",
      "717/717 [==============================] - 0s 326us/step - loss: 0.3547 - acc: 0.8330\n",
      "Epoch 92/160\n",
      "717/717 [==============================] - 0s 298us/step - loss: 0.3479 - acc: 0.8414\n",
      "Epoch 93/160\n",
      "717/717 [==============================] - 0s 309us/step - loss: 0.3489 - acc: 0.8414\n",
      "Epoch 94/160\n",
      "717/717 [==============================] - 0s 299us/step - loss: 0.3487 - acc: 0.8375\n",
      "Epoch 95/160\n",
      "717/717 [==============================] - 0s 341us/step - loss: 0.3524 - acc: 0.8407\n",
      "Epoch 96/160\n",
      "717/717 [==============================] - 0s 325us/step - loss: 0.3667 - acc: 0.8323\n",
      "Epoch 97/160\n",
      "717/717 [==============================] - 0s 380us/step - loss: 0.3548 - acc: 0.8414\n",
      "Epoch 98/160\n",
      "717/717 [==============================] - 0s 382us/step - loss: 0.3613 - acc: 0.8323\n",
      "Epoch 99/160\n",
      "717/717 [==============================] - 0s 305us/step - loss: 0.3487 - acc: 0.8361\n",
      "Epoch 100/160\n",
      "717/717 [==============================] - 0s 314us/step - loss: 0.3578 - acc: 0.8344\n",
      "Epoch 101/160\n",
      "717/717 [==============================] - 0s 314us/step - loss: 0.3562 - acc: 0.8354\n",
      "Epoch 102/160\n",
      "717/717 [==============================] - 0s 305us/step - loss: 0.3513 - acc: 0.8434\n",
      "Epoch 103/160\n",
      "717/717 [==============================] - 0s 302us/step - loss: 0.3517 - acc: 0.8379\n",
      "Epoch 104/160\n",
      "717/717 [==============================] - 0s 319us/step - loss: 0.3534 - acc: 0.8319\n",
      "Epoch 105/160\n",
      "717/717 [==============================] - 0s 321us/step - loss: 0.3457 - acc: 0.8438\n",
      "Epoch 106/160\n",
      "717/717 [==============================] - 0s 302us/step - loss: 0.3459 - acc: 0.8431\n",
      "Epoch 107/160\n",
      "717/717 [==============================] - 0s 312us/step - loss: 0.3543 - acc: 0.8379\n",
      "Epoch 108/160\n",
      "717/717 [==============================] - 0s 309us/step - loss: 0.3541 - acc: 0.8368\n",
      "Epoch 109/160\n",
      "717/717 [==============================] - 0s 309us/step - loss: 0.3519 - acc: 0.8351\n",
      "Epoch 110/160\n",
      "717/717 [==============================] - 0s 299us/step - loss: 0.3537 - acc: 0.8368\n",
      "Epoch 111/160\n",
      "717/717 [==============================] - 0s 316us/step - loss: 0.3400 - acc: 0.8441\n",
      "Epoch 112/160\n",
      "717/717 [==============================] - 0s 298us/step - loss: 0.3368 - acc: 0.8438\n",
      "Epoch 113/160\n",
      "717/717 [==============================] - 0s 303us/step - loss: 0.3575 - acc: 0.8361\n",
      "Epoch 114/160\n",
      "717/717 [==============================] - 0s 309us/step - loss: 0.3409 - acc: 0.8448\n",
      "Epoch 115/160\n",
      "717/717 [==============================] - 0s 316us/step - loss: 0.3444 - acc: 0.8389\n",
      "Epoch 116/160\n",
      "717/717 [==============================] - 0s 313us/step - loss: 0.3441 - acc: 0.8427\n",
      "Epoch 117/160\n",
      "717/717 [==============================] - 0s 307us/step - loss: 0.3519 - acc: 0.8389\n",
      "Epoch 118/160\n",
      "717/717 [==============================] - 0s 306us/step - loss: 0.3509 - acc: 0.8431\n",
      "Epoch 119/160\n",
      "717/717 [==============================] - 0s 301us/step - loss: 0.3474 - acc: 0.8452\n",
      "Epoch 120/160\n",
      "717/717 [==============================] - 0s 327us/step - loss: 0.3454 - acc: 0.8438\n",
      "Epoch 121/160\n",
      "717/717 [==============================] - 0s 317us/step - loss: 0.3558 - acc: 0.8407\n",
      "Epoch 122/160\n",
      "717/717 [==============================] - 0s 298us/step - loss: 0.3590 - acc: 0.8372\n",
      "Epoch 123/160\n",
      "717/717 [==============================] - 0s 296us/step - loss: 0.3442 - acc: 0.8393\n",
      "Epoch 124/160\n",
      "717/717 [==============================] - 0s 281us/step - loss: 0.3402 - acc: 0.8452\n",
      "Epoch 125/160\n",
      "717/717 [==============================] - 0s 317us/step - loss: 0.3427 - acc: 0.8438\n",
      "Epoch 126/160\n",
      "717/717 [==============================] - 0s 294us/step - loss: 0.3462 - acc: 0.8410\n",
      "Epoch 127/160\n",
      "717/717 [==============================] - 0s 318us/step - loss: 0.3585 - acc: 0.8389\n",
      "Epoch 128/160\n",
      "717/717 [==============================] - 0s 317us/step - loss: 0.3674 - acc: 0.8400\n",
      "Epoch 129/160\n",
      "717/717 [==============================] - 0s 320us/step - loss: 0.3608 - acc: 0.8347\n",
      "Epoch 130/160\n",
      "717/717 [==============================] - 0s 319us/step - loss: 0.3516 - acc: 0.8448\n",
      "Epoch 131/160\n",
      "717/717 [==============================] - 0s 304us/step - loss: 0.3383 - acc: 0.8462\n",
      "Epoch 132/160\n",
      "717/717 [==============================] - 0s 293us/step - loss: 0.3359 - acc: 0.8473\n",
      "Epoch 133/160\n",
      "717/717 [==============================] - 0s 313us/step - loss: 0.3492 - acc: 0.8379\n",
      "Epoch 134/160\n",
      "717/717 [==============================] - 0s 321us/step - loss: 0.3439 - acc: 0.8403\n",
      "Epoch 135/160\n",
      "717/717 [==============================] - 0s 290us/step - loss: 0.3362 - acc: 0.8459\n",
      "Epoch 136/160\n",
      "717/717 [==============================] - 0s 314us/step - loss: 0.3429 - acc: 0.8389\n",
      "Epoch 137/160\n",
      "717/717 [==============================] - 0s 300us/step - loss: 0.3372 - acc: 0.8511\n",
      "Epoch 138/160\n",
      "717/717 [==============================] - 0s 300us/step - loss: 0.3373 - acc: 0.8483\n",
      "Epoch 139/160\n",
      "717/717 [==============================] - 0s 332us/step - loss: 0.3518 - acc: 0.8305\n",
      "Epoch 140/160\n",
      "717/717 [==============================] - 0s 303us/step - loss: 0.3474 - acc: 0.8396\n",
      "Epoch 141/160\n",
      "717/717 [==============================] - 0s 298us/step - loss: 0.3391 - acc: 0.8427\n",
      "Epoch 142/160\n",
      "717/717 [==============================] - 0s 288us/step - loss: 0.3299 - acc: 0.8497\n",
      "Epoch 143/160\n",
      "717/717 [==============================] - 0s 308us/step - loss: 0.3282 - acc: 0.8480\n",
      "Epoch 144/160\n",
      "717/717 [==============================] - 0s 322us/step - loss: 0.3293 - acc: 0.8469\n",
      "Epoch 145/160\n",
      "717/717 [==============================] - 0s 311us/step - loss: 0.3328 - acc: 0.8487\n",
      "Epoch 146/160\n",
      "717/717 [==============================] - 0s 304us/step - loss: 0.3337 - acc: 0.8431\n",
      "Epoch 147/160\n",
      "717/717 [==============================] - 0s 317us/step - loss: 0.3362 - acc: 0.8414\n",
      "Epoch 148/160\n",
      "717/717 [==============================] - 0s 312us/step - loss: 0.3323 - acc: 0.8501\n",
      "Epoch 149/160\n",
      "717/717 [==============================] - 0s 304us/step - loss: 0.3239 - acc: 0.8483\n",
      "Epoch 150/160\n",
      "717/717 [==============================] - 0s 318us/step - loss: 0.3255 - acc: 0.8476\n",
      "Epoch 151/160\n",
      "717/717 [==============================] - 0s 296us/step - loss: 0.3291 - acc: 0.8445\n",
      "Epoch 152/160\n",
      "717/717 [==============================] - 0s 298us/step - loss: 0.3254 - acc: 0.8504\n",
      "Epoch 153/160\n",
      "717/717 [==============================] - 0s 297us/step - loss: 0.3245 - acc: 0.8483\n",
      "Epoch 154/160\n",
      "717/717 [==============================] - 0s 311us/step - loss: 0.3282 - acc: 0.8487\n",
      "Epoch 155/160\n",
      "717/717 [==============================] - 0s 300us/step - loss: 0.3293 - acc: 0.8508\n",
      "Epoch 156/160\n",
      "717/717 [==============================] - 0s 297us/step - loss: 0.3247 - acc: 0.8462\n",
      "Epoch 157/160\n",
      "717/717 [==============================] - 0s 292us/step - loss: 0.3230 - acc: 0.8522\n",
      "Epoch 158/160\n",
      "717/717 [==============================] - 0s 287us/step - loss: 0.3637 - acc: 0.8421\n",
      "Epoch 159/160\n",
      "717/717 [==============================] - 0s 326us/step - loss: 0.3456 - acc: 0.8434\n",
      "Epoch 160/160\n",
      "717/717 [==============================] - 0s 342us/step - loss: 0.3336 - acc: 0.8462\n",
      "180/180 [==============================] - 0s 2ms/step\n",
      "717/717 [==============================] - 0s 75us/step\n",
      "\n",
      "acc: 78.89%\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "[[50  5  0  9]\n",
      " [14 10  0  4]\n",
      " [ 2  0  2  0]\n",
      " [19  0  1 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.59      0.78      0.67        64\n",
      "      Normal       0.67      0.36      0.47        28\n",
      "        Slow       0.67      0.50      0.57         4\n",
      "   Very Fast       0.83      0.76      0.80        84\n",
      "\n",
      "    accuracy                           0.70       180\n",
      "   macro avg       0.69      0.60      0.63       180\n",
      "weighted avg       0.72      0.70      0.69       180\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[df_k.Zone=='highway']\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy zone: highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "2272/2272 [==============================] - 2s 771us/step - loss: 0.3941 - acc: 0.8348\n",
      "Epoch 2/160\n",
      "2272/2272 [==============================] - 1s 326us/step - loss: 0.3492 - acc: 0.8543\n",
      "Epoch 3/160\n",
      "2272/2272 [==============================] - 1s 316us/step - loss: 0.3402 - acc: 0.8552\n",
      "Epoch 4/160\n",
      "2272/2272 [==============================] - 1s 327us/step - loss: 0.3351 - acc: 0.8577\n",
      "Epoch 5/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.3352 - acc: 0.8582\n",
      "Epoch 6/160\n",
      "2272/2272 [==============================] - 1s 326us/step - loss: 0.3326 - acc: 0.8561\n",
      "Epoch 7/160\n",
      "2272/2272 [==============================] - 1s 340us/step - loss: 0.3253 - acc: 0.8588\n",
      "Epoch 8/160\n",
      "2272/2272 [==============================] - 1s 316us/step - loss: 0.3220 - acc: 0.8586\n",
      "Epoch 9/160\n",
      "2272/2272 [==============================] - 1s 331us/step - loss: 0.3190 - acc: 0.8622\n",
      "Epoch 10/160\n",
      "2272/2272 [==============================] - 1s 300us/step - loss: 0.3166 - acc: 0.8583\n",
      "Epoch 11/160\n",
      "2272/2272 [==============================] - 1s 299us/step - loss: 0.3142 - acc: 0.8606\n",
      "Epoch 12/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.3190 - acc: 0.8572\n",
      "Epoch 13/160\n",
      "2272/2272 [==============================] - 1s 319us/step - loss: 0.3097 - acc: 0.8622\n",
      "Epoch 14/160\n",
      "2272/2272 [==============================] - 1s 306us/step - loss: 0.3111 - acc: 0.8637\n",
      "Epoch 15/160\n",
      "2272/2272 [==============================] - 1s 319us/step - loss: 0.3051 - acc: 0.8648\n",
      "Epoch 16/160\n",
      "2272/2272 [==============================] - 1s 326us/step - loss: 0.3106 - acc: 0.8608\n",
      "Epoch 17/160\n",
      "2272/2272 [==============================] - 1s 352us/step - loss: 0.3093 - acc: 0.8639\n",
      "Epoch 18/160\n",
      "2272/2272 [==============================] - 1s 306us/step - loss: 0.3079 - acc: 0.8652\n",
      "Epoch 19/160\n",
      "2272/2272 [==============================] - 1s 429us/step - loss: 0.3025 - acc: 0.8654\n",
      "Epoch 20/160\n",
      "2272/2272 [==============================] - 1s 402us/step - loss: 0.3061 - acc: 0.8645\n",
      "Epoch 21/160\n",
      "2272/2272 [==============================] - 1s 343us/step - loss: 0.3083 - acc: 0.8617\n",
      "Epoch 22/160\n",
      "2272/2272 [==============================] - 1s 324us/step - loss: 0.3107 - acc: 0.8662\n",
      "Epoch 23/160\n",
      "2272/2272 [==============================] - 1s 315us/step - loss: 0.3025 - acc: 0.8656\n",
      "Epoch 24/160\n",
      "2272/2272 [==============================] - 1s 310us/step - loss: 0.2992 - acc: 0.8706\n",
      "Epoch 25/160\n",
      "2272/2272 [==============================] - 1s 314us/step - loss: 0.3008 - acc: 0.8685\n",
      "Epoch 26/160\n",
      "2272/2272 [==============================] - 1s 300us/step - loss: 0.2983 - acc: 0.8699\n",
      "Epoch 27/160\n",
      "2272/2272 [==============================] - 1s 312us/step - loss: 0.3027 - acc: 0.8659\n",
      "Epoch 28/160\n",
      "2272/2272 [==============================] - 1s 310us/step - loss: 0.2959 - acc: 0.8697\n",
      "Epoch 29/160\n",
      "2272/2272 [==============================] - 1s 299us/step - loss: 0.2929 - acc: 0.8715\n",
      "Epoch 30/160\n",
      "2272/2272 [==============================] - 1s 313us/step - loss: 0.2958 - acc: 0.8684\n",
      "Epoch 31/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2913 - acc: 0.8718\n",
      "Epoch 32/160\n",
      "2272/2272 [==============================] - 1s 314us/step - loss: 0.3056 - acc: 0.8674\n",
      "Epoch 33/160\n",
      "2272/2272 [==============================] - 1s 315us/step - loss: 0.2948 - acc: 0.8695\n",
      "Epoch 34/160\n",
      "2272/2272 [==============================] - 1s 321us/step - loss: 0.2938 - acc: 0.8717\n",
      "Epoch 35/160\n",
      "2272/2272 [==============================] - 1s 305us/step - loss: 0.2966 - acc: 0.8697\n",
      "Epoch 36/160\n",
      "2272/2272 [==============================] - 1s 313us/step - loss: 0.2915 - acc: 0.8732\n",
      "Epoch 37/160\n",
      "2272/2272 [==============================] - 1s 312us/step - loss: 0.2881 - acc: 0.8720\n",
      "Epoch 38/160\n",
      "2272/2272 [==============================] - 1s 301us/step - loss: 0.2890 - acc: 0.8751\n",
      "Epoch 39/160\n",
      "2272/2272 [==============================] - 1s 298us/step - loss: 0.2923 - acc: 0.8694\n",
      "Epoch 40/160\n",
      "2272/2272 [==============================] - 1s 294us/step - loss: 0.2857 - acc: 0.8704\n",
      "Epoch 41/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2826 - acc: 0.8752\n",
      "Epoch 42/160\n",
      "2272/2272 [==============================] - 1s 308us/step - loss: 0.2827 - acc: 0.8727\n",
      "Epoch 43/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2896 - acc: 0.8736\n",
      "Epoch 44/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2882 - acc: 0.8711\n",
      "Epoch 45/160\n",
      "2272/2272 [==============================] - 1s 310us/step - loss: 0.2894 - acc: 0.8756\n",
      "Epoch 46/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2850 - acc: 0.8749\n",
      "Epoch 47/160\n",
      "2272/2272 [==============================] - 1s 303us/step - loss: 0.2808 - acc: 0.8748\n",
      "Epoch 48/160\n",
      "2272/2272 [==============================] - 1s 311us/step - loss: 0.2840 - acc: 0.8768\n",
      "Epoch 49/160\n",
      "2272/2272 [==============================] - 1s 301us/step - loss: 0.2837 - acc: 0.8746\n",
      "Epoch 50/160\n",
      "2272/2272 [==============================] - 1s 311us/step - loss: 0.2793 - acc: 0.8783\n",
      "Epoch 51/160\n",
      "2272/2272 [==============================] - 1s 304us/step - loss: 0.2834 - acc: 0.8761\n",
      "Epoch 52/160\n",
      "2272/2272 [==============================] - 1s 299us/step - loss: 0.2765 - acc: 0.8776\n",
      "Epoch 53/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2740 - acc: 0.8787\n",
      "Epoch 54/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2773 - acc: 0.8774\n",
      "Epoch 55/160\n",
      "2272/2272 [==============================] - 1s 316us/step - loss: 0.2758 - acc: 0.8785\n",
      "Epoch 56/160\n",
      "2272/2272 [==============================] - 1s 308us/step - loss: 0.2721 - acc: 0.8798\n",
      "Epoch 57/160\n",
      "2272/2272 [==============================] - 1s 306us/step - loss: 0.2803 - acc: 0.8783\n",
      "Epoch 58/160\n",
      "2272/2272 [==============================] - 1s 312us/step - loss: 0.2803 - acc: 0.8768\n",
      "Epoch 59/160\n",
      "2272/2272 [==============================] - 1s 313us/step - loss: 0.2729 - acc: 0.8768\n",
      "Epoch 60/160\n",
      "2272/2272 [==============================] - 1s 308us/step - loss: 0.2688 - acc: 0.8822\n",
      "Epoch 61/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2693 - acc: 0.8805\n",
      "Epoch 62/160\n",
      "2272/2272 [==============================] - 1s 305us/step - loss: 0.2707 - acc: 0.8803\n",
      "Epoch 63/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2738 - acc: 0.8826\n",
      "Epoch 64/160\n",
      "2272/2272 [==============================] - 1s 301us/step - loss: 0.2701 - acc: 0.8806\n",
      "Epoch 65/160\n",
      "2272/2272 [==============================] - 1s 323us/step - loss: 0.2702 - acc: 0.8824\n",
      "Epoch 66/160\n",
      "2272/2272 [==============================] - 1s 346us/step - loss: 0.2676 - acc: 0.8811\n",
      "Epoch 67/160\n",
      "2272/2272 [==============================] - 1s 304us/step - loss: 0.2646 - acc: 0.8828\n",
      "Epoch 68/160\n",
      "2272/2272 [==============================] - 1s 309us/step - loss: 0.2697 - acc: 0.8817\n",
      "Epoch 69/160\n",
      "2272/2272 [==============================] - 1s 326us/step - loss: 0.2714 - acc: 0.8818\n",
      "Epoch 70/160\n",
      "2272/2272 [==============================] - 1s 344us/step - loss: 0.2673 - acc: 0.8845\n",
      "Epoch 71/160\n",
      "2272/2272 [==============================] - 1s 352us/step - loss: 0.2660 - acc: 0.8829\n",
      "Epoch 72/160\n",
      "2272/2272 [==============================] - 1s 423us/step - loss: 0.2717 - acc: 0.8801\n",
      "Epoch 73/160\n",
      "2272/2272 [==============================] - 1s 383us/step - loss: 0.2623 - acc: 0.8848\n",
      "Epoch 74/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2581 - acc: 0.8824\n",
      "Epoch 75/160\n",
      "2272/2272 [==============================] - 1s 358us/step - loss: 0.2632 - acc: 0.8815\n",
      "Epoch 76/160\n",
      "2272/2272 [==============================] - 1s 329us/step - loss: 0.2589 - acc: 0.8888\n",
      "Epoch 77/160\n",
      "2272/2272 [==============================] - 1s 316us/step - loss: 0.2626 - acc: 0.8839\n",
      "Epoch 78/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2579 - acc: 0.8860\n",
      "Epoch 79/160\n",
      "2272/2272 [==============================] - 1s 293us/step - loss: 0.2733 - acc: 0.8791\n",
      "Epoch 80/160\n",
      "2272/2272 [==============================] - 1s 402us/step - loss: 0.2689 - acc: 0.8812\n",
      "Epoch 81/160\n",
      "2272/2272 [==============================] - 1s 329us/step - loss: 0.2585 - acc: 0.8877\n",
      "Epoch 82/160\n",
      "2272/2272 [==============================] - 1s 330us/step - loss: 0.2576 - acc: 0.8850\n",
      "Epoch 83/160\n",
      "2272/2272 [==============================] - 1s 325us/step - loss: 0.2623 - acc: 0.8819\n",
      "Epoch 84/160\n",
      "2272/2272 [==============================] - 1s 310us/step - loss: 0.2534 - acc: 0.8875\n",
      "Epoch 85/160\n",
      "2272/2272 [==============================] - 1s 304us/step - loss: 0.2575 - acc: 0.8860\n",
      "Epoch 86/160\n",
      "2272/2272 [==============================] - 1s 335us/step - loss: 0.2531 - acc: 0.8864\n",
      "Epoch 87/160\n",
      "2272/2272 [==============================] - 1s 296us/step - loss: 0.2613 - acc: 0.8850\n",
      "Epoch 88/160\n",
      "2272/2272 [==============================] - 1s 300us/step - loss: 0.2579 - acc: 0.8853\n",
      "Epoch 89/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2541 - acc: 0.8863\n",
      "Epoch 90/160\n",
      "2272/2272 [==============================] - 1s 312us/step - loss: 0.2490 - acc: 0.8900\n",
      "Epoch 91/160\n",
      "2272/2272 [==============================] - 1s 299us/step - loss: 0.2519 - acc: 0.8868\n",
      "Epoch 92/160\n",
      "2272/2272 [==============================] - 1s 390us/step - loss: 0.2554 - acc: 0.8894\n",
      "Epoch 93/160\n",
      "2272/2272 [==============================] - 1s 320us/step - loss: 0.2482 - acc: 0.8877\n",
      "Epoch 94/160\n",
      "2272/2272 [==============================] - 1s 324us/step - loss: 0.2448 - acc: 0.8902\n",
      "Epoch 95/160\n",
      "2272/2272 [==============================] - 1s 385us/step - loss: 0.2570 - acc: 0.8841\n",
      "Epoch 96/160\n",
      "2272/2272 [==============================] - 1s 323us/step - loss: 0.2507 - acc: 0.8863\n",
      "Epoch 97/160\n",
      "2272/2272 [==============================] - 1s 346us/step - loss: 0.2473 - acc: 0.8891\n",
      "Epoch 98/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2417 - acc: 0.8912\n",
      "Epoch 99/160\n",
      "2272/2272 [==============================] - 1s 310us/step - loss: 0.2516 - acc: 0.8890\n",
      "Epoch 100/160\n",
      "2272/2272 [==============================] - 1s 311us/step - loss: 0.2398 - acc: 0.8935\n",
      "Epoch 101/160\n",
      "2272/2272 [==============================] - 1s 311us/step - loss: 0.2579 - acc: 0.8875\n",
      "Epoch 102/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2513 - acc: 0.8861\n",
      "Epoch 103/160\n",
      "2272/2272 [==============================] - 1s 308us/step - loss: 0.2433 - acc: 0.8884\n",
      "Epoch 104/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2449 - acc: 0.8884\n",
      "Epoch 105/160\n",
      "2272/2272 [==============================] - 1s 321us/step - loss: 0.2373 - acc: 0.8932\n",
      "Epoch 106/160\n",
      "2272/2272 [==============================] - 1s 298us/step - loss: 0.2419 - acc: 0.8908\n",
      "Epoch 107/160\n",
      "2272/2272 [==============================] - 1s 355us/step - loss: 0.2322 - acc: 0.8927\n",
      "Epoch 108/160\n",
      "2272/2272 [==============================] - 1s 326us/step - loss: 0.2401 - acc: 0.8910\n",
      "Epoch 109/160\n",
      "2272/2272 [==============================] - 1s 316us/step - loss: 0.2421 - acc: 0.8899\n",
      "Epoch 110/160\n",
      "2272/2272 [==============================] - 1s 350us/step - loss: 0.2493 - acc: 0.8864\n",
      "Epoch 111/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2393 - acc: 0.8937\n",
      "Epoch 112/160\n",
      "2272/2272 [==============================] - 1s 360us/step - loss: 0.2316 - acc: 0.8951\n",
      "Epoch 113/160\n",
      "2272/2272 [==============================] - 1s 301us/step - loss: 0.2359 - acc: 0.8897\n",
      "Epoch 114/160\n",
      "2272/2272 [==============================] - 1s 297us/step - loss: 0.2408 - acc: 0.8904\n",
      "Epoch 115/160\n",
      "2272/2272 [==============================] - 1s 303us/step - loss: 0.2360 - acc: 0.8944\n",
      "Epoch 116/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2308 - acc: 0.8938\n",
      "Epoch 117/160\n",
      "2272/2272 [==============================] - 1s 313us/step - loss: 0.2347 - acc: 0.8927\n",
      "Epoch 118/160\n",
      "2272/2272 [==============================] - 1s 296us/step - loss: 0.2303 - acc: 0.8934\n",
      "Epoch 119/160\n",
      "2272/2272 [==============================] - 1s 296us/step - loss: 0.2377 - acc: 0.8904\n",
      "Epoch 120/160\n",
      "2272/2272 [==============================] - 1s 309us/step - loss: 0.2275 - acc: 0.8946\n",
      "Epoch 121/160\n",
      "2272/2272 [==============================] - 1s 305us/step - loss: 0.2314 - acc: 0.8970\n",
      "Epoch 122/160\n",
      "2272/2272 [==============================] - 1s 299us/step - loss: 0.2287 - acc: 0.8967\n",
      "Epoch 123/160\n",
      "2272/2272 [==============================] - 1s 326us/step - loss: 0.2316 - acc: 0.8965\n",
      "Epoch 124/160\n",
      "2272/2272 [==============================] - 1s 304us/step - loss: 0.2258 - acc: 0.8982\n",
      "Epoch 125/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2226 - acc: 0.8980\n",
      "Epoch 126/160\n",
      "2272/2272 [==============================] - 1s 313us/step - loss: 0.2201 - acc: 0.9023\n",
      "Epoch 127/160\n",
      "2272/2272 [==============================] - 1s 301us/step - loss: 0.2328 - acc: 0.8908\n",
      "Epoch 128/160\n",
      "2272/2272 [==============================] - 1s 298us/step - loss: 0.2250 - acc: 0.8933\n",
      "Epoch 129/160\n",
      "2272/2272 [==============================] - 1s 308us/step - loss: 0.2233 - acc: 0.8970\n",
      "Epoch 130/160\n",
      "2272/2272 [==============================] - 1s 309us/step - loss: 0.2224 - acc: 0.9012\n",
      "Epoch 131/160\n",
      "2272/2272 [==============================] - 1s 312us/step - loss: 0.2183 - acc: 0.9007\n",
      "Epoch 132/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2185 - acc: 0.9001\n",
      "Epoch 133/160\n",
      "2272/2272 [==============================] - 1s 290us/step - loss: 0.2330 - acc: 0.8945\n",
      "Epoch 134/160\n",
      "2272/2272 [==============================] - 1s 321us/step - loss: 0.2181 - acc: 0.8984\n",
      "Epoch 135/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2280 - acc: 0.8968\n",
      "Epoch 136/160\n",
      "2272/2272 [==============================] - 1s 308us/step - loss: 0.2212 - acc: 0.8973\n",
      "Epoch 137/160\n",
      "2272/2272 [==============================] - 1s 331us/step - loss: 0.2345 - acc: 0.8915\n",
      "Epoch 138/160\n",
      "2272/2272 [==============================] - 1s 304us/step - loss: 0.2357 - acc: 0.8930\n",
      "Epoch 139/160\n",
      "2272/2272 [==============================] - 1s 306us/step - loss: 0.2201 - acc: 0.9031\n",
      "Epoch 140/160\n",
      "2272/2272 [==============================] - 1s 321us/step - loss: 0.2200 - acc: 0.9000\n",
      "Epoch 141/160\n",
      "2272/2272 [==============================] - 1s 325us/step - loss: 0.2200 - acc: 0.9015\n",
      "Epoch 142/160\n",
      "2272/2272 [==============================] - 1s 301us/step - loss: 0.2097 - acc: 0.9018\n",
      "Epoch 143/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2133 - acc: 0.9045\n",
      "Epoch 144/160\n",
      "2272/2272 [==============================] - 1s 303us/step - loss: 0.2188 - acc: 0.8988\n",
      "Epoch 145/160\n",
      "2272/2272 [==============================] - 1s 303us/step - loss: 0.2208 - acc: 0.8993\n",
      "Epoch 146/160\n",
      "2272/2272 [==============================] - 1s 298us/step - loss: 0.2065 - acc: 0.9029\n",
      "Epoch 147/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2072 - acc: 0.9053\n",
      "Epoch 148/160\n",
      "2272/2272 [==============================] - 1s 307us/step - loss: 0.2053 - acc: 0.9031\n",
      "Epoch 149/160\n",
      "2272/2272 [==============================] - 1s 317us/step - loss: 0.2122 - acc: 0.9013\n",
      "Epoch 150/160\n",
      "2272/2272 [==============================] - 1s 300us/step - loss: 0.2639 - acc: 0.8831\n",
      "Epoch 151/160\n",
      "2272/2272 [==============================] - 1s 306us/step - loss: 0.2314 - acc: 0.8929\n",
      "Epoch 152/160\n",
      "2272/2272 [==============================] - 1s 304us/step - loss: 0.2212 - acc: 0.8950\n",
      "Epoch 153/160\n",
      "2272/2272 [==============================] - 1s 293us/step - loss: 0.2141 - acc: 0.8994\n",
      "Epoch 154/160\n",
      "2272/2272 [==============================] - 1s 314us/step - loss: 0.2148 - acc: 0.8978\n",
      "Epoch 155/160\n",
      "2272/2272 [==============================] - 1s 302us/step - loss: 0.2106 - acc: 0.9003\n",
      "Epoch 156/160\n",
      "2272/2272 [==============================] - 1s 301us/step - loss: 0.2197 - acc: 0.9012\n",
      "Epoch 157/160\n",
      "2272/2272 [==============================] - 1s 305us/step - loss: 0.2038 - acc: 0.9055\n",
      "Epoch 158/160\n",
      "2272/2272 [==============================] - 1s 308us/step - loss: 0.2042 - acc: 0.9043\n",
      "Epoch 159/160\n",
      "2272/2272 [==============================] - 1s 311us/step - loss: 0.2090 - acc: 0.9054\n",
      "Epoch 160/160\n",
      "2272/2272 [==============================] - 1s 318us/step - loss: 0.2064 - acc: 0.9035\n",
      "569/569 [==============================] - 0s 576us/step\n",
      "2272/2272 [==============================] - 0s 74us/step\n",
      "\n",
      "acc: 86.12%\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 1\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[ 58  23   1   1]\n",
      " [ 10 381  19   1]\n",
      " [  1  16  55   0]\n",
      " [  0   1   0   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.84      0.70      0.76        83\n",
      "      Normal       0.90      0.93      0.92       411\n",
      "        Slow       0.73      0.76      0.75        72\n",
      "   Very Fast       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.87       569\n",
      "   macro avg       0.74      0.76      0.75       569\n",
      "weighted avg       0.87      0.87      0.87       569\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8717047451669596"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[df_k.Zone=='market']\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy zone:market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "1272/1272 [==============================] - 3s 2ms/step - loss: 0.4530 - acc: 0.7588\n",
      "Epoch 2/160\n",
      "1272/1272 [==============================] - 1s 414us/step - loss: 0.4233 - acc: 0.7653\n",
      "Epoch 3/160\n",
      "1272/1272 [==============================] - 0s 309us/step - loss: 0.4120 - acc: 0.7761\n",
      "Epoch 4/160\n",
      "1272/1272 [==============================] - 1s 448us/step - loss: 0.4065 - acc: 0.7744\n",
      "Epoch 5/160\n",
      "1272/1272 [==============================] - 1s 455us/step - loss: 0.4008 - acc: 0.7803\n",
      "Epoch 6/160\n",
      "1272/1272 [==============================] - 1s 482us/step - loss: 0.4011 - acc: 0.7744\n",
      "Epoch 7/160\n",
      "1272/1272 [==============================] - 1s 432us/step - loss: 0.3941 - acc: 0.7879\n",
      "Epoch 8/160\n",
      "1272/1272 [==============================] - 1s 480us/step - loss: 0.3885 - acc: 0.7844\n",
      "Epoch 9/160\n",
      "1272/1272 [==============================] - 0s 338us/step - loss: 0.3883 - acc: 0.7824\n",
      "Epoch 10/160\n",
      "1272/1272 [==============================] - 0s 359us/step - loss: 0.3909 - acc: 0.7877\n",
      "Epoch 11/160\n",
      "1272/1272 [==============================] - 0s 317us/step - loss: 0.3853 - acc: 0.7911\n",
      "Epoch 12/160\n",
      "1272/1272 [==============================] - 0s 367us/step - loss: 0.3906 - acc: 0.7842\n",
      "Epoch 13/160\n",
      "1272/1272 [==============================] - 0s 358us/step - loss: 0.3914 - acc: 0.7864\n",
      "Epoch 14/160\n",
      "1272/1272 [==============================] - 1s 404us/step - loss: 0.3824 - acc: 0.7952\n",
      "Epoch 15/160\n",
      "1272/1272 [==============================] - 0s 345us/step - loss: 0.3802 - acc: 0.7995\n",
      "Epoch 16/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3874 - acc: 0.7915\n",
      "Epoch 17/160\n",
      "1272/1272 [==============================] - 0s 391us/step - loss: 0.3791 - acc: 0.7983\n",
      "Epoch 18/160\n",
      "1272/1272 [==============================] - 1s 431us/step - loss: 0.3729 - acc: 0.8058\n",
      "Epoch 19/160\n",
      "1272/1272 [==============================] - 1s 465us/step - loss: 0.3698 - acc: 0.8029\n",
      "Epoch 20/160\n",
      "1272/1272 [==============================] - 1s 448us/step - loss: 0.3696 - acc: 0.8040\n",
      "Epoch 21/160\n",
      "1272/1272 [==============================] - 1s 456us/step - loss: 0.3803 - acc: 0.7921\n",
      "Epoch 22/160\n",
      "1272/1272 [==============================] - 1s 473us/step - loss: 0.3737 - acc: 0.8015\n",
      "Epoch 23/160\n",
      "1272/1272 [==============================] - 1s 401us/step - loss: 0.3689 - acc: 0.8076\n",
      "Epoch 24/160\n",
      "1272/1272 [==============================] - 0s 380us/step - loss: 0.3734 - acc: 0.8046\n",
      "Epoch 25/160\n",
      "1272/1272 [==============================] - 1s 419us/step - loss: 0.3688 - acc: 0.8019\n",
      "Epoch 26/160\n",
      "1272/1272 [==============================] - 0s 375us/step - loss: 0.3745 - acc: 0.8013\n",
      "Epoch 27/160\n",
      "1272/1272 [==============================] - 0s 310us/step - loss: 0.3731 - acc: 0.8113\n",
      "Epoch 28/160\n",
      "1272/1272 [==============================] - 0s 315us/step - loss: 0.3696 - acc: 0.8096\n",
      "Epoch 29/160\n",
      "1272/1272 [==============================] - 0s 289us/step - loss: 0.3610 - acc: 0.8115\n",
      "Epoch 30/160\n",
      "1272/1272 [==============================] - 0s 308us/step - loss: 0.3673 - acc: 0.8017\n",
      "Epoch 31/160\n",
      "1272/1272 [==============================] - 0s 336us/step - loss: 0.3624 - acc: 0.8133\n",
      "Epoch 32/160\n",
      "1272/1272 [==============================] - 0s 376us/step - loss: 0.3664 - acc: 0.8046\n",
      "Epoch 33/160\n",
      "1272/1272 [==============================] - 0s 380us/step - loss: 0.3678 - acc: 0.8068\n",
      "Epoch 34/160\n",
      "1272/1272 [==============================] - 0s 331us/step - loss: 0.3686 - acc: 0.8029\n",
      "Epoch 35/160\n",
      "1272/1272 [==============================] - 0s 300us/step - loss: 0.3629 - acc: 0.8076\n",
      "Epoch 36/160\n",
      "1272/1272 [==============================] - 0s 345us/step - loss: 0.3598 - acc: 0.8123\n",
      "Epoch 37/160\n",
      "1272/1272 [==============================] - 0s 342us/step - loss: 0.3590 - acc: 0.8119\n",
      "Epoch 38/160\n",
      "1272/1272 [==============================] - 0s 348us/step - loss: 0.3694 - acc: 0.8003\n",
      "Epoch 39/160\n",
      "1272/1272 [==============================] - 0s 324us/step - loss: 0.3616 - acc: 0.8084\n",
      "Epoch 40/160\n",
      "1272/1272 [==============================] - 0s 306us/step - loss: 0.3600 - acc: 0.8084\n",
      "Epoch 41/160\n",
      "1272/1272 [==============================] - 0s 316us/step - loss: 0.3584 - acc: 0.8086\n",
      "Epoch 42/160\n",
      "1272/1272 [==============================] - 1s 393us/step - loss: 0.3620 - acc: 0.8094\n",
      "Epoch 43/160\n",
      "1272/1272 [==============================] - 0s 335us/step - loss: 0.3614 - acc: 0.8048\n",
      "Epoch 44/160\n",
      "1272/1272 [==============================] - 0s 310us/step - loss: 0.3676 - acc: 0.8021\n",
      "Epoch 45/160\n",
      "1272/1272 [==============================] - 0s 307us/step - loss: 0.3648 - acc: 0.8023\n",
      "Epoch 46/160\n",
      "1272/1272 [==============================] - 0s 336us/step - loss: 0.3562 - acc: 0.8074\n",
      "Epoch 47/160\n",
      "1272/1272 [==============================] - 0s 309us/step - loss: 0.3665 - acc: 0.7919\n",
      "Epoch 48/160\n",
      "1272/1272 [==============================] - 0s 315us/step - loss: 0.3535 - acc: 0.8137\n",
      "Epoch 49/160\n",
      "1272/1272 [==============================] - 0s 342us/step - loss: 0.3574 - acc: 0.8111\n",
      "Epoch 50/160\n",
      "1272/1272 [==============================] - 0s 301us/step - loss: 0.3570 - acc: 0.8164\n",
      "Epoch 51/160\n",
      "1272/1272 [==============================] - 0s 329us/step - loss: 0.3540 - acc: 0.8154\n",
      "Epoch 52/160\n",
      "1272/1272 [==============================] - 0s 339us/step - loss: 0.3562 - acc: 0.8080\n",
      "Epoch 53/160\n",
      "1272/1272 [==============================] - 0s 328us/step - loss: 0.3562 - acc: 0.8143\n",
      "Epoch 54/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3558 - acc: 0.8099\n",
      "Epoch 55/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3572 - acc: 0.8133\n",
      "Epoch 56/160\n",
      "1272/1272 [==============================] - 0s 307us/step - loss: 0.3536 - acc: 0.8111\n",
      "Epoch 57/160\n",
      "1272/1272 [==============================] - 0s 310us/step - loss: 0.3514 - acc: 0.8097\n",
      "Epoch 58/160\n",
      "1272/1272 [==============================] - 0s 322us/step - loss: 0.3527 - acc: 0.8164\n",
      "Epoch 59/160\n",
      "1272/1272 [==============================] - 0s 298us/step - loss: 0.3579 - acc: 0.8082\n",
      "Epoch 60/160\n",
      "1272/1272 [==============================] - 0s 296us/step - loss: 0.3568 - acc: 0.8208\n",
      "Epoch 61/160\n",
      "1272/1272 [==============================] - 0s 320us/step - loss: 0.3562 - acc: 0.8111\n",
      "Epoch 62/160\n",
      "1272/1272 [==============================] - 0s 297us/step - loss: 0.3523 - acc: 0.8137\n",
      "Epoch 63/160\n",
      "1272/1272 [==============================] - 0s 308us/step - loss: 0.3612 - acc: 0.8147\n",
      "Epoch 64/160\n",
      "1272/1272 [==============================] - 0s 315us/step - loss: 0.3608 - acc: 0.8076\n",
      "Epoch 65/160\n",
      "1272/1272 [==============================] - 0s 311us/step - loss: 0.3567 - acc: 0.8121\n",
      "Epoch 66/160\n",
      "1272/1272 [==============================] - 0s 309us/step - loss: 0.3582 - acc: 0.8084\n",
      "Epoch 67/160\n",
      "1272/1272 [==============================] - 0s 317us/step - loss: 0.3618 - acc: 0.8031\n",
      "Epoch 68/160\n",
      "1272/1272 [==============================] - 0s 306us/step - loss: 0.3530 - acc: 0.8119\n",
      "Epoch 69/160\n",
      "1272/1272 [==============================] - 0s 308us/step - loss: 0.3572 - acc: 0.8133\n",
      "Epoch 70/160\n",
      "1272/1272 [==============================] - 0s 299us/step - loss: 0.3496 - acc: 0.8160\n",
      "Epoch 71/160\n",
      "1272/1272 [==============================] - 0s 292us/step - loss: 0.3454 - acc: 0.8121\n",
      "Epoch 72/160\n",
      "1272/1272 [==============================] - 0s 292us/step - loss: 0.3516 - acc: 0.8131\n",
      "Epoch 73/160\n",
      "1272/1272 [==============================] - 0s 306us/step - loss: 0.3468 - acc: 0.8186\n",
      "Epoch 74/160\n",
      "1272/1272 [==============================] - 0s 321us/step - loss: 0.3504 - acc: 0.8135\n",
      "Epoch 75/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3532 - acc: 0.8153\n",
      "Epoch 76/160\n",
      "1272/1272 [==============================] - 0s 293us/step - loss: 0.3516 - acc: 0.8162\n",
      "Epoch 77/160\n",
      "1272/1272 [==============================] - 0s 313us/step - loss: 0.3487 - acc: 0.8196\n",
      "Epoch 78/160\n",
      "1272/1272 [==============================] - 0s 310us/step - loss: 0.3462 - acc: 0.8194\n",
      "Epoch 79/160\n",
      "1272/1272 [==============================] - 0s 302us/step - loss: 0.3469 - acc: 0.8186\n",
      "Epoch 80/160\n",
      "1272/1272 [==============================] - 0s 311us/step - loss: 0.3495 - acc: 0.8145\n",
      "Epoch 81/160\n",
      "1272/1272 [==============================] - 0s 316us/step - loss: 0.3487 - acc: 0.8172\n",
      "Epoch 82/160\n",
      "1272/1272 [==============================] - 0s 323us/step - loss: 0.3498 - acc: 0.8158\n",
      "Epoch 83/160\n",
      "1272/1272 [==============================] - 0s 316us/step - loss: 0.3522 - acc: 0.8221\n",
      "Epoch 84/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3489 - acc: 0.8196\n",
      "Epoch 85/160\n",
      "1272/1272 [==============================] - 0s 323us/step - loss: 0.3538 - acc: 0.8166\n",
      "Epoch 86/160\n",
      "1272/1272 [==============================] - 0s 296us/step - loss: 0.3468 - acc: 0.8153\n",
      "Epoch 87/160\n",
      "1272/1272 [==============================] - 0s 326us/step - loss: 0.3492 - acc: 0.8119\n",
      "Epoch 88/160\n",
      "1272/1272 [==============================] - 0s 300us/step - loss: 0.3420 - acc: 0.8219\n",
      "Epoch 89/160\n",
      "1272/1272 [==============================] - 0s 301us/step - loss: 0.3491 - acc: 0.8202\n",
      "Epoch 90/160\n",
      "1272/1272 [==============================] - 0s 308us/step - loss: 0.3514 - acc: 0.8154\n",
      "Epoch 91/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3487 - acc: 0.8176\n",
      "Epoch 92/160\n",
      "1272/1272 [==============================] - 0s 306us/step - loss: 0.3488 - acc: 0.8184\n",
      "Epoch 93/160\n",
      "1272/1272 [==============================] - 0s 291us/step - loss: 0.3421 - acc: 0.8237\n",
      "Epoch 94/160\n",
      "1272/1272 [==============================] - 0s 300us/step - loss: 0.3440 - acc: 0.8215\n",
      "Epoch 95/160\n",
      "1272/1272 [==============================] - 0s 374us/step - loss: 0.3395 - acc: 0.8196\n",
      "Epoch 96/160\n",
      "1272/1272 [==============================] - 0s 329us/step - loss: 0.3435 - acc: 0.8227\n",
      "Epoch 97/160\n",
      "1272/1272 [==============================] - 0s 317us/step - loss: 0.3421 - acc: 0.8208\n",
      "Epoch 98/160\n",
      "1272/1272 [==============================] - 0s 331us/step - loss: 0.3430 - acc: 0.8154\n",
      "Epoch 99/160\n",
      "1272/1272 [==============================] - 0s 273us/step - loss: 0.3408 - acc: 0.8213\n",
      "Epoch 100/160\n",
      "1272/1272 [==============================] - 0s 311us/step - loss: 0.3396 - acc: 0.8190\n",
      "Epoch 101/160\n",
      "1272/1272 [==============================] - 0s 369us/step - loss: 0.3414 - acc: 0.8208\n",
      "Epoch 102/160\n",
      "1272/1272 [==============================] - 0s 309us/step - loss: 0.3416 - acc: 0.8217\n",
      "Epoch 103/160\n",
      "1272/1272 [==============================] - 0s 325us/step - loss: 0.3431 - acc: 0.8196\n",
      "Epoch 104/160\n",
      "1272/1272 [==============================] - 0s 319us/step - loss: 0.3418 - acc: 0.8249\n",
      "Epoch 105/160\n",
      "1272/1272 [==============================] - 0s 343us/step - loss: 0.3453 - acc: 0.8200\n",
      "Epoch 106/160\n",
      "1272/1272 [==============================] - 1s 398us/step - loss: 0.3392 - acc: 0.8268\n",
      "Epoch 107/160\n",
      "1272/1272 [==============================] - 0s 375us/step - loss: 0.3410 - acc: 0.8235\n",
      "Epoch 108/160\n",
      "1272/1272 [==============================] - 0s 303us/step - loss: 0.3384 - acc: 0.8219\n",
      "Epoch 109/160\n",
      "1272/1272 [==============================] - 0s 344us/step - loss: 0.3353 - acc: 0.8278\n",
      "Epoch 110/160\n",
      "1272/1272 [==============================] - 0s 388us/step - loss: 0.3375 - acc: 0.8235\n",
      "Epoch 111/160\n",
      "1272/1272 [==============================] - 1s 428us/step - loss: 0.3420 - acc: 0.8206\n",
      "Epoch 112/160\n",
      "1272/1272 [==============================] - 1s 433us/step - loss: 0.3402 - acc: 0.8255\n",
      "Epoch 113/160\n",
      "1272/1272 [==============================] - 1s 394us/step - loss: 0.3418 - acc: 0.8235\n",
      "Epoch 114/160\n",
      "1272/1272 [==============================] - 0s 348us/step - loss: 0.3385 - acc: 0.8239\n",
      "Epoch 115/160\n",
      "1272/1272 [==============================] - 0s 349us/step - loss: 0.3352 - acc: 0.8272\n",
      "Epoch 116/160\n",
      "1272/1272 [==============================] - 0s 300us/step - loss: 0.3414 - acc: 0.8200\n",
      "Epoch 117/160\n",
      "1272/1272 [==============================] - 0s 317us/step - loss: 0.3345 - acc: 0.8268\n",
      "Epoch 118/160\n",
      "1272/1272 [==============================] - 0s 298us/step - loss: 0.3372 - acc: 0.8225\n",
      "Epoch 119/160\n",
      "1272/1272 [==============================] - 0s 306us/step - loss: 0.3338 - acc: 0.8263\n",
      "Epoch 120/160\n",
      "1272/1272 [==============================] - 0s 371us/step - loss: 0.3407 - acc: 0.8210\n",
      "Epoch 121/160\n",
      "1272/1272 [==============================] - 0s 311us/step - loss: 0.3481 - acc: 0.8217\n",
      "Epoch 122/160\n",
      "1272/1272 [==============================] - 0s 305us/step - loss: 0.3459 - acc: 0.8208\n",
      "Epoch 123/160\n",
      "1272/1272 [==============================] - 0s 311us/step - loss: 0.3414 - acc: 0.8247\n",
      "Epoch 124/160\n",
      "1272/1272 [==============================] - 0s 317us/step - loss: 0.3363 - acc: 0.8221\n",
      "Epoch 125/160\n",
      "1272/1272 [==============================] - 0s 312us/step - loss: 0.3436 - acc: 0.8168\n",
      "Epoch 126/160\n",
      "1272/1272 [==============================] - 0s 312us/step - loss: 0.3379 - acc: 0.8267\n",
      "Epoch 127/160\n",
      "1272/1272 [==============================] - 0s 301us/step - loss: 0.3296 - acc: 0.8294\n",
      "Epoch 128/160\n",
      "1272/1272 [==============================] - 0s 301us/step - loss: 0.3276 - acc: 0.8241\n",
      "Epoch 129/160\n",
      "1272/1272 [==============================] - 0s 318us/step - loss: 0.3374 - acc: 0.8184\n",
      "Epoch 130/160\n",
      "1272/1272 [==============================] - 0s 302us/step - loss: 0.3497 - acc: 0.8158\n",
      "Epoch 131/160\n",
      "1272/1272 [==============================] - 0s 300us/step - loss: 0.3377 - acc: 0.8251\n",
      "Epoch 132/160\n",
      "1272/1272 [==============================] - 0s 322us/step - loss: 0.3336 - acc: 0.8243\n",
      "Epoch 133/160\n",
      "1272/1272 [==============================] - 0s 305us/step - loss: 0.3356 - acc: 0.8208\n",
      "Epoch 134/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3334 - acc: 0.8225\n",
      "Epoch 135/160\n",
      "1272/1272 [==============================] - 0s 292us/step - loss: 0.3265 - acc: 0.8318\n",
      "Epoch 136/160\n",
      "1272/1272 [==============================] - 0s 308us/step - loss: 0.3283 - acc: 0.8314\n",
      "Epoch 137/160\n",
      "1272/1272 [==============================] - 0s 304us/step - loss: 0.3305 - acc: 0.8253\n",
      "Epoch 138/160\n",
      "1272/1272 [==============================] - 0s 315us/step - loss: 0.3302 - acc: 0.8247\n",
      "Epoch 139/160\n",
      "1272/1272 [==============================] - 0s 324us/step - loss: 0.3393 - acc: 0.8229\n",
      "Epoch 140/160\n",
      "1272/1272 [==============================] - 0s 312us/step - loss: 0.3319 - acc: 0.8249\n",
      "Epoch 141/160\n",
      "1272/1272 [==============================] - 0s 322us/step - loss: 0.3253 - acc: 0.8324\n",
      "Epoch 142/160\n",
      "1272/1272 [==============================] - 0s 299us/step - loss: 0.3250 - acc: 0.8282\n",
      "Epoch 143/160\n",
      "1272/1272 [==============================] - 0s 306us/step - loss: 0.3311 - acc: 0.8310\n",
      "Epoch 144/160\n",
      "1272/1272 [==============================] - 0s 313us/step - loss: 0.3301 - acc: 0.8261\n",
      "Epoch 145/160\n",
      "1272/1272 [==============================] - 0s 297us/step - loss: 0.3269 - acc: 0.8306\n",
      "Epoch 146/160\n",
      "1272/1272 [==============================] - 0s 317us/step - loss: 0.3264 - acc: 0.8243\n",
      "Epoch 147/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3272 - acc: 0.8272\n",
      "Epoch 148/160\n",
      "1272/1272 [==============================] - 0s 317us/step - loss: 0.3333 - acc: 0.8280\n",
      "Epoch 149/160\n",
      "1272/1272 [==============================] - 0s 297us/step - loss: 0.3373 - acc: 0.8241\n",
      "Epoch 150/160\n",
      "1272/1272 [==============================] - 0s 309us/step - loss: 0.3262 - acc: 0.8282\n",
      "Epoch 151/160\n",
      "1272/1272 [==============================] - 0s 308us/step - loss: 0.3265 - acc: 0.8306\n",
      "Epoch 152/160\n",
      "1272/1272 [==============================] - 0s 295us/step - loss: 0.3253 - acc: 0.8357\n",
      "Epoch 153/160\n",
      "1272/1272 [==============================] - 0s 307us/step - loss: 0.3223 - acc: 0.8355\n",
      "Epoch 154/160\n",
      "1272/1272 [==============================] - 0s 295us/step - loss: 0.3221 - acc: 0.8286\n",
      "Epoch 155/160\n",
      "1272/1272 [==============================] - 0s 324us/step - loss: 0.3245 - acc: 0.8320\n",
      "Epoch 156/160\n",
      "1272/1272 [==============================] - 0s 323us/step - loss: 0.3226 - acc: 0.8278\n",
      "Epoch 157/160\n",
      "1272/1272 [==============================] - 0s 305us/step - loss: 0.3251 - acc: 0.8284\n",
      "Epoch 158/160\n",
      "1272/1272 [==============================] - 0s 303us/step - loss: 0.3197 - acc: 0.8367\n",
      "Epoch 159/160\n",
      "1272/1272 [==============================] - 0s 300us/step - loss: 0.3232 - acc: 0.8294\n",
      "Epoch 160/160\n",
      "1272/1272 [==============================] - 0s 314us/step - loss: 0.3261 - acc: 0.8298\n",
      "319/319 [==============================] - 0s 1ms/step\n",
      "1272/1272 [==============================] - 0s 84us/step\n",
      "\n",
      "acc: 77.19%\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "[[ 78  55   1   1]\n",
      " [ 21 140   3   4]\n",
      " [  0   2   4   0]\n",
      " [  2   4   0   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.77      0.58      0.66       135\n",
      "      Normal       0.70      0.83      0.76       168\n",
      "        Slow       0.50      0.67      0.57         6\n",
      "   Very Fast       0.44      0.40      0.42        10\n",
      "\n",
      "    accuracy                           0.71       319\n",
      "   macro avg       0.60      0.62      0.60       319\n",
      "weighted avg       0.72      0.71      0.70       319\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7084639498432602"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[df_k.Zone=='normal_city']\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy zone:normal_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "185/185 [==============================] - 1s 7ms/step - loss: 0.5263 - acc: 0.7500\n",
      "Epoch 2/160\n",
      "185/185 [==============================] - 0s 357us/step - loss: 0.4417 - acc: 0.7703\n",
      "Epoch 3/160\n",
      "185/185 [==============================] - 0s 429us/step - loss: 0.4498 - acc: 0.7730\n",
      "Epoch 4/160\n",
      "185/185 [==============================] - 0s 352us/step - loss: 0.4379 - acc: 0.7811\n",
      "Epoch 5/160\n",
      "185/185 [==============================] - 0s 377us/step - loss: 0.4399 - acc: 0.7770\n",
      "Epoch 6/160\n",
      "185/185 [==============================] - 0s 385us/step - loss: 0.4312 - acc: 0.7784\n",
      "Epoch 7/160\n",
      "185/185 [==============================] - 0s 395us/step - loss: 0.4265 - acc: 0.7824\n",
      "Epoch 8/160\n",
      "185/185 [==============================] - 0s 415us/step - loss: 0.4280 - acc: 0.7838\n",
      "Epoch 9/160\n",
      "185/185 [==============================] - 0s 378us/step - loss: 0.4227 - acc: 0.7851\n",
      "Epoch 10/160\n",
      "185/185 [==============================] - 0s 403us/step - loss: 0.4195 - acc: 0.7905\n",
      "Epoch 11/160\n",
      "185/185 [==============================] - 0s 361us/step - loss: 0.4211 - acc: 0.7919\n",
      "Epoch 12/160\n",
      "185/185 [==============================] - 0s 357us/step - loss: 0.4186 - acc: 0.7851\n",
      "Epoch 13/160\n",
      "185/185 [==============================] - 0s 345us/step - loss: 0.4176 - acc: 0.7784\n",
      "Epoch 14/160\n",
      "185/185 [==============================] - 0s 418us/step - loss: 0.4106 - acc: 0.7919\n",
      "Epoch 15/160\n",
      "185/185 [==============================] - 0s 372us/step - loss: 0.4054 - acc: 0.7878\n",
      "Epoch 16/160\n",
      "185/185 [==============================] - 0s 423us/step - loss: 0.4045 - acc: 0.7878\n",
      "Epoch 17/160\n",
      "185/185 [==============================] - 0s 361us/step - loss: 0.4012 - acc: 0.7824\n",
      "Epoch 18/160\n",
      "185/185 [==============================] - 0s 360us/step - loss: 0.4067 - acc: 0.7797\n",
      "Epoch 19/160\n",
      "185/185 [==============================] - 0s 352us/step - loss: 0.3909 - acc: 0.7919\n",
      "Epoch 20/160\n",
      "185/185 [==============================] - 0s 351us/step - loss: 0.3885 - acc: 0.7986\n",
      "Epoch 21/160\n",
      "185/185 [==============================] - 0s 426us/step - loss: 0.3976 - acc: 0.7919\n",
      "Epoch 22/160\n",
      "185/185 [==============================] - 0s 360us/step - loss: 0.3996 - acc: 0.7959\n",
      "Epoch 23/160\n",
      "185/185 [==============================] - 0s 349us/step - loss: 0.4003 - acc: 0.7905\n",
      "Epoch 24/160\n",
      "185/185 [==============================] - 0s 414us/step - loss: 0.3982 - acc: 0.7905\n",
      "Epoch 25/160\n",
      "185/185 [==============================] - 0s 415us/step - loss: 0.3956 - acc: 0.7959\n",
      "Epoch 26/160\n",
      "185/185 [==============================] - 0s 400us/step - loss: 0.3961 - acc: 0.7946\n",
      "Epoch 27/160\n",
      "185/185 [==============================] - 0s 355us/step - loss: 0.3932 - acc: 0.7959\n",
      "Epoch 28/160\n",
      "185/185 [==============================] - 0s 368us/step - loss: 0.3954 - acc: 0.7959\n",
      "Epoch 29/160\n",
      "185/185 [==============================] - 0s 340us/step - loss: 0.3945 - acc: 0.7959\n",
      "Epoch 30/160\n",
      "185/185 [==============================] - 0s 366us/step - loss: 0.3882 - acc: 0.7973\n",
      "Epoch 31/160\n",
      "185/185 [==============================] - 0s 416us/step - loss: 0.3910 - acc: 0.8041\n",
      "Epoch 32/160\n",
      "185/185 [==============================] - 0s 383us/step - loss: 0.3926 - acc: 0.7986\n",
      "Epoch 33/160\n",
      "185/185 [==============================] - 0s 336us/step - loss: 0.3867 - acc: 0.8041\n",
      "Epoch 34/160\n",
      "185/185 [==============================] - 0s 364us/step - loss: 0.3875 - acc: 0.8027\n",
      "Epoch 35/160\n",
      "185/185 [==============================] - 0s 456us/step - loss: 0.3780 - acc: 0.8122\n",
      "Epoch 36/160\n",
      "185/185 [==============================] - 0s 380us/step - loss: 0.3819 - acc: 0.7959\n",
      "Epoch 37/160\n",
      "185/185 [==============================] - 0s 403us/step - loss: 0.3768 - acc: 0.8149\n",
      "Epoch 38/160\n",
      "185/185 [==============================] - 0s 360us/step - loss: 0.3812 - acc: 0.8068\n",
      "Epoch 39/160\n",
      "185/185 [==============================] - 0s 399us/step - loss: 0.3757 - acc: 0.8095\n",
      "Epoch 40/160\n",
      "185/185 [==============================] - 0s 381us/step - loss: 0.3892 - acc: 0.7986\n",
      "Epoch 41/160\n",
      "185/185 [==============================] - 0s 363us/step - loss: 0.3961 - acc: 0.8014\n",
      "Epoch 42/160\n",
      "185/185 [==============================] - 0s 400us/step - loss: 0.3915 - acc: 0.8027\n",
      "Epoch 43/160\n",
      "185/185 [==============================] - 0s 345us/step - loss: 0.3876 - acc: 0.8081\n",
      "Epoch 44/160\n",
      "185/185 [==============================] - 0s 361us/step - loss: 0.3825 - acc: 0.8122\n",
      "Epoch 45/160\n",
      "185/185 [==============================] - 0s 366us/step - loss: 0.3796 - acc: 0.8081\n",
      "Epoch 46/160\n",
      "185/185 [==============================] - 0s 389us/step - loss: 0.3804 - acc: 0.8122\n",
      "Epoch 47/160\n",
      "185/185 [==============================] - 0s 379us/step - loss: 0.3724 - acc: 0.8095\n",
      "Epoch 48/160\n",
      "185/185 [==============================] - 0s 457us/step - loss: 0.3822 - acc: 0.8095\n",
      "Epoch 49/160\n",
      "185/185 [==============================] - 0s 361us/step - loss: 0.3721 - acc: 0.8122\n",
      "Epoch 50/160\n",
      "185/185 [==============================] - 0s 376us/step - loss: 0.3732 - acc: 0.8108\n",
      "Epoch 51/160\n",
      "185/185 [==============================] - 0s 371us/step - loss: 0.3788 - acc: 0.8081\n",
      "Epoch 52/160\n",
      "185/185 [==============================] - 0s 404us/step - loss: 0.3707 - acc: 0.8149\n",
      "Epoch 53/160\n",
      "185/185 [==============================] - 0s 379us/step - loss: 0.3714 - acc: 0.8135\n",
      "Epoch 54/160\n",
      "185/185 [==============================] - 0s 370us/step - loss: 0.3799 - acc: 0.8108\n",
      "Epoch 55/160\n",
      "185/185 [==============================] - 0s 356us/step - loss: 0.3676 - acc: 0.8095\n",
      "Epoch 56/160\n",
      "185/185 [==============================] - 0s 404us/step - loss: 0.3774 - acc: 0.8095\n",
      "Epoch 57/160\n",
      "185/185 [==============================] - 0s 384us/step - loss: 0.3715 - acc: 0.8149\n",
      "Epoch 58/160\n",
      "185/185 [==============================] - 0s 352us/step - loss: 0.3753 - acc: 0.8095\n",
      "Epoch 59/160\n",
      "185/185 [==============================] - 0s 368us/step - loss: 0.3656 - acc: 0.8135\n",
      "Epoch 60/160\n",
      "185/185 [==============================] - 0s 367us/step - loss: 0.3758 - acc: 0.8108\n",
      "Epoch 61/160\n",
      "185/185 [==============================] - 0s 322us/step - loss: 0.3652 - acc: 0.8149\n",
      "Epoch 62/160\n",
      "185/185 [==============================] - 0s 348us/step - loss: 0.3687 - acc: 0.8095\n",
      "Epoch 63/160\n",
      "185/185 [==============================] - 0s 388us/step - loss: 0.3741 - acc: 0.8068\n",
      "Epoch 64/160\n",
      "185/185 [==============================] - 0s 360us/step - loss: 0.3658 - acc: 0.8162\n",
      "Epoch 65/160\n",
      "185/185 [==============================] - 0s 393us/step - loss: 0.3638 - acc: 0.8135\n",
      "Epoch 66/160\n",
      "185/185 [==============================] - 0s 381us/step - loss: 0.3691 - acc: 0.8149\n",
      "Epoch 67/160\n",
      "185/185 [==============================] - 0s 408us/step - loss: 0.3676 - acc: 0.8203\n",
      "Epoch 68/160\n",
      "185/185 [==============================] - 0s 355us/step - loss: 0.3655 - acc: 0.8216\n",
      "Epoch 69/160\n",
      "185/185 [==============================] - 0s 342us/step - loss: 0.3606 - acc: 0.8189\n",
      "Epoch 70/160\n",
      "185/185 [==============================] - 0s 397us/step - loss: 0.3654 - acc: 0.8108\n",
      "Epoch 71/160\n",
      "185/185 [==============================] - 0s 363us/step - loss: 0.3642 - acc: 0.8162\n",
      "Epoch 72/160\n",
      "185/185 [==============================] - 0s 375us/step - loss: 0.3652 - acc: 0.8108\n",
      "Epoch 73/160\n",
      "185/185 [==============================] - 0s 365us/step - loss: 0.3560 - acc: 0.8108\n",
      "Epoch 74/160\n",
      "185/185 [==============================] - 0s 394us/step - loss: 0.3624 - acc: 0.8149\n",
      "Epoch 75/160\n",
      "185/185 [==============================] - 0s 359us/step - loss: 0.3588 - acc: 0.8216\n",
      "Epoch 76/160\n",
      "185/185 [==============================] - 0s 372us/step - loss: 0.3597 - acc: 0.8243\n",
      "Epoch 77/160\n",
      "185/185 [==============================] - 0s 417us/step - loss: 0.3566 - acc: 0.8189\n",
      "Epoch 78/160\n",
      "185/185 [==============================] - 0s 401us/step - loss: 0.3557 - acc: 0.8149\n",
      "Epoch 79/160\n",
      "185/185 [==============================] - 0s 361us/step - loss: 0.3487 - acc: 0.8162\n",
      "Epoch 80/160\n",
      "185/185 [==============================] - 0s 375us/step - loss: 0.3583 - acc: 0.8149\n",
      "Epoch 81/160\n",
      "185/185 [==============================] - 0s 414us/step - loss: 0.3617 - acc: 0.8122\n",
      "Epoch 82/160\n",
      "185/185 [==============================] - 0s 343us/step - loss: 0.3604 - acc: 0.8135\n",
      "Epoch 83/160\n",
      "185/185 [==============================] - 0s 369us/step - loss: 0.3615 - acc: 0.8095\n",
      "Epoch 84/160\n",
      "185/185 [==============================] - 0s 519us/step - loss: 0.3548 - acc: 0.8189\n",
      "Epoch 85/160\n",
      "185/185 [==============================] - 0s 412us/step - loss: 0.3741 - acc: 0.7973\n",
      "Epoch 86/160\n",
      "185/185 [==============================] - 0s 430us/step - loss: 0.3680 - acc: 0.8095\n",
      "Epoch 87/160\n",
      "185/185 [==============================] - 0s 434us/step - loss: 0.3678 - acc: 0.8122\n",
      "Epoch 88/160\n",
      "185/185 [==============================] - 0s 369us/step - loss: 0.3685 - acc: 0.8108\n",
      "Epoch 89/160\n",
      "185/185 [==============================] - 0s 343us/step - loss: 0.3693 - acc: 0.8041\n",
      "Epoch 90/160\n",
      "185/185 [==============================] - 0s 362us/step - loss: 0.3692 - acc: 0.8041\n",
      "Epoch 91/160\n",
      "185/185 [==============================] - 0s 435us/step - loss: 0.3589 - acc: 0.8108\n",
      "Epoch 92/160\n",
      "185/185 [==============================] - 0s 420us/step - loss: 0.3540 - acc: 0.8135\n",
      "Epoch 93/160\n",
      "185/185 [==============================] - 0s 441us/step - loss: 0.3551 - acc: 0.8189\n",
      "Epoch 94/160\n",
      "185/185 [==============================] - 0s 408us/step - loss: 0.3491 - acc: 0.8230\n",
      "Epoch 95/160\n",
      "185/185 [==============================] - 0s 447us/step - loss: 0.3539 - acc: 0.8108\n",
      "Epoch 96/160\n",
      "185/185 [==============================] - 0s 484us/step - loss: 0.3521 - acc: 0.8189\n",
      "Epoch 97/160\n",
      "185/185 [==============================] - 0s 441us/step - loss: 0.3535 - acc: 0.8203\n",
      "Epoch 98/160\n",
      "185/185 [==============================] - 0s 363us/step - loss: 0.3580 - acc: 0.8243\n",
      "Epoch 99/160\n",
      "185/185 [==============================] - 0s 344us/step - loss: 0.3622 - acc: 0.8297\n",
      "Epoch 100/160\n",
      "185/185 [==============================] - 0s 412us/step - loss: 0.3583 - acc: 0.8230\n",
      "Epoch 101/160\n",
      "185/185 [==============================] - 0s 344us/step - loss: 0.3726 - acc: 0.8122\n",
      "Epoch 102/160\n",
      "185/185 [==============================] - 0s 370us/step - loss: 0.3719 - acc: 0.8149\n",
      "Epoch 103/160\n",
      "185/185 [==============================] - 0s 373us/step - loss: 0.4324 - acc: 0.8068\n",
      "Epoch 104/160\n",
      "185/185 [==============================] - 0s 349us/step - loss: 0.4048 - acc: 0.8203\n",
      "Epoch 105/160\n",
      "185/185 [==============================] - 0s 376us/step - loss: 0.3916 - acc: 0.8135\n",
      "Epoch 106/160\n",
      "185/185 [==============================] - 0s 311us/step - loss: 0.3795 - acc: 0.7986\n",
      "Epoch 107/160\n",
      "185/185 [==============================] - 0s 419us/step - loss: 0.3804 - acc: 0.8162\n",
      "Epoch 108/160\n",
      "185/185 [==============================] - 0s 335us/step - loss: 0.3757 - acc: 0.8108\n",
      "Epoch 109/160\n",
      "185/185 [==============================] - 0s 413us/step - loss: 0.3832 - acc: 0.8027\n",
      "Epoch 110/160\n",
      "185/185 [==============================] - 0s 406us/step - loss: 0.3877 - acc: 0.8014\n",
      "Epoch 111/160\n",
      "185/185 [==============================] - 0s 341us/step - loss: 0.3721 - acc: 0.8122\n",
      "Epoch 112/160\n",
      "185/185 [==============================] - 0s 326us/step - loss: 0.3598 - acc: 0.8189\n",
      "Epoch 113/160\n",
      "185/185 [==============================] - 0s 377us/step - loss: 0.3648 - acc: 0.8176\n",
      "Epoch 114/160\n",
      "185/185 [==============================] - 0s 423us/step - loss: 0.3623 - acc: 0.8176\n",
      "Epoch 115/160\n",
      "185/185 [==============================] - 0s 301us/step - loss: 0.3593 - acc: 0.8230\n",
      "Epoch 116/160\n",
      "185/185 [==============================] - 0s 328us/step - loss: 0.3655 - acc: 0.8230\n",
      "Epoch 117/160\n",
      "185/185 [==============================] - 0s 408us/step - loss: 0.3623 - acc: 0.8122\n",
      "Epoch 118/160\n",
      "185/185 [==============================] - 0s 377us/step - loss: 0.3601 - acc: 0.8135\n",
      "Epoch 119/160\n",
      "185/185 [==============================] - 0s 324us/step - loss: 0.3522 - acc: 0.8176\n",
      "Epoch 120/160\n",
      "185/185 [==============================] - 0s 408us/step - loss: 0.3621 - acc: 0.8108\n",
      "Epoch 121/160\n",
      "185/185 [==============================] - 0s 400us/step - loss: 0.3529 - acc: 0.8257\n",
      "Epoch 122/160\n",
      "185/185 [==============================] - 0s 356us/step - loss: 0.3550 - acc: 0.8243\n",
      "Epoch 123/160\n",
      "185/185 [==============================] - 0s 331us/step - loss: 0.3598 - acc: 0.8149\n",
      "Epoch 124/160\n",
      "185/185 [==============================] - 0s 363us/step - loss: 0.3693 - acc: 0.8108\n",
      "Epoch 125/160\n",
      "185/185 [==============================] - 0s 432us/step - loss: 0.3578 - acc: 0.8176\n",
      "Epoch 126/160\n",
      "185/185 [==============================] - 0s 310us/step - loss: 0.3522 - acc: 0.8257\n",
      "Epoch 127/160\n",
      "185/185 [==============================] - 0s 352us/step - loss: 0.3506 - acc: 0.8270\n",
      "Epoch 128/160\n",
      "185/185 [==============================] - 0s 346us/step - loss: 0.3511 - acc: 0.8284\n",
      "Epoch 129/160\n",
      "185/185 [==============================] - 0s 377us/step - loss: 0.3464 - acc: 0.8243\n",
      "Epoch 130/160\n",
      "185/185 [==============================] - 0s 405us/step - loss: 0.3490 - acc: 0.8230\n",
      "Epoch 131/160\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 0.3436 - acc: 0.8243\n",
      "Epoch 132/160\n",
      "185/185 [==============================] - 0s 400us/step - loss: 0.3466 - acc: 0.8243\n",
      "Epoch 133/160\n",
      "185/185 [==============================] - 0s 329us/step - loss: 0.3447 - acc: 0.8257\n",
      "Epoch 134/160\n",
      "185/185 [==============================] - 0s 306us/step - loss: 0.3488 - acc: 0.8216\n",
      "Epoch 135/160\n",
      "185/185 [==============================] - 0s 375us/step - loss: 0.3565 - acc: 0.8203\n",
      "Epoch 136/160\n",
      "185/185 [==============================] - 0s 331us/step - loss: 0.3504 - acc: 0.8230\n",
      "Epoch 137/160\n",
      "185/185 [==============================] - 0s 385us/step - loss: 0.3499 - acc: 0.8230\n",
      "Epoch 138/160\n",
      "185/185 [==============================] - 0s 358us/step - loss: 0.3484 - acc: 0.8243\n",
      "Epoch 139/160\n",
      "185/185 [==============================] - 0s 363us/step - loss: 0.3434 - acc: 0.8243\n",
      "Epoch 140/160\n",
      "185/185 [==============================] - 0s 350us/step - loss: 0.3509 - acc: 0.8216\n",
      "Epoch 141/160\n",
      "185/185 [==============================] - 0s 387us/step - loss: 0.3503 - acc: 0.8230\n",
      "Epoch 142/160\n",
      "185/185 [==============================] - 0s 366us/step - loss: 0.3456 - acc: 0.8243\n",
      "Epoch 143/160\n",
      "185/185 [==============================] - 0s 434us/step - loss: 0.3525 - acc: 0.8216\n",
      "Epoch 144/160\n",
      "185/185 [==============================] - 0s 415us/step - loss: 0.3566 - acc: 0.8081\n",
      "Epoch 145/160\n",
      "185/185 [==============================] - 0s 396us/step - loss: 0.3467 - acc: 0.8216\n",
      "Epoch 146/160\n",
      "185/185 [==============================] - 0s 419us/step - loss: 0.3595 - acc: 0.8149\n",
      "Epoch 147/160\n",
      "185/185 [==============================] - 0s 360us/step - loss: 0.3449 - acc: 0.8176\n",
      "Epoch 148/160\n",
      "185/185 [==============================] - 0s 360us/step - loss: 0.3493 - acc: 0.8216\n",
      "Epoch 149/160\n",
      "185/185 [==============================] - 0s 414us/step - loss: 0.3571 - acc: 0.8122\n",
      "Epoch 150/160\n",
      "185/185 [==============================] - 0s 382us/step - loss: 0.3531 - acc: 0.8189\n",
      "Epoch 151/160\n",
      "185/185 [==============================] - 0s 405us/step - loss: 0.3559 - acc: 0.8203\n",
      "Epoch 152/160\n",
      "185/185 [==============================] - 0s 388us/step - loss: 0.3484 - acc: 0.8189\n",
      "Epoch 153/160\n",
      "185/185 [==============================] - 0s 398us/step - loss: 0.3519 - acc: 0.8203\n",
      "Epoch 154/160\n",
      "185/185 [==============================] - 0s 404us/step - loss: 0.3498 - acc: 0.8284\n",
      "Epoch 155/160\n",
      "185/185 [==============================] - 0s 388us/step - loss: 0.3402 - acc: 0.8257\n",
      "Epoch 156/160\n",
      "185/185 [==============================] - 0s 358us/step - loss: 0.3455 - acc: 0.8270\n",
      "Epoch 157/160\n",
      "185/185 [==============================] - 0s 380us/step - loss: 0.3442 - acc: 0.8270\n",
      "Epoch 158/160\n",
      "185/185 [==============================] - 0s 387us/step - loss: 0.3561 - acc: 0.8149\n",
      "Epoch 159/160\n",
      "185/185 [==============================] - 0s 327us/step - loss: 0.3541 - acc: 0.8189\n",
      "Epoch 160/160\n",
      "185/185 [==============================] - 0s 373us/step - loss: 0.3454 - acc: 0.8230\n",
      "47/47 [==============================] - 0s 9ms/step\n",
      "185/185 [==============================] - 0s 98us/step\n",
      "\n",
      "acc: 79.26%\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[ 9  9  0  0]\n",
      " [ 0 26  1  0]\n",
      " [ 0  0  1  0]\n",
      " [ 0  1  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       1.00      0.50      0.67        18\n",
      "      Normal       0.72      0.96      0.83        27\n",
      "        Slow       0.50      1.00      0.67         1\n",
      "   Very Fast       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.77        47\n",
      "   macro avg       0.56      0.62      0.54        47\n",
      "weighted avg       0.81      0.77      0.74        47\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7659574468085106"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='normal_city') & (df_k.Timelevel==1)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy: normal_city and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "358/358 [==============================] - 2s 5ms/step - loss: 0.4808 - acc: 0.7486\n",
      "Epoch 2/160\n",
      "358/358 [==============================] - 0s 363us/step - loss: 0.4334 - acc: 0.7374\n",
      "Epoch 3/160\n",
      "358/358 [==============================] - 0s 358us/step - loss: 0.4292 - acc: 0.7563\n",
      "Epoch 4/160\n",
      "358/358 [==============================] - 0s 364us/step - loss: 0.4008 - acc: 0.7465\n",
      "Epoch 5/160\n",
      "358/358 [==============================] - 0s 382us/step - loss: 0.4006 - acc: 0.7591\n",
      "Epoch 6/160\n",
      "358/358 [==============================] - 0s 336us/step - loss: 0.3972 - acc: 0.7640\n",
      "Epoch 7/160\n",
      "358/358 [==============================] - 0s 419us/step - loss: 0.3927 - acc: 0.7703\n",
      "Epoch 8/160\n",
      "358/358 [==============================] - 0s 354us/step - loss: 0.3927 - acc: 0.7751\n",
      "Epoch 9/160\n",
      "358/358 [==============================] - 0s 412us/step - loss: 0.3879 - acc: 0.7793\n",
      "Epoch 10/160\n",
      "358/358 [==============================] - 0s 352us/step - loss: 0.3891 - acc: 0.7961\n",
      "Epoch 11/160\n",
      "358/358 [==============================] - 0s 418us/step - loss: 0.3989 - acc: 0.7528\n",
      "Epoch 12/160\n",
      "358/358 [==============================] - 0s 390us/step - loss: 0.3873 - acc: 0.7877\n",
      "Epoch 13/160\n",
      "358/358 [==============================] - 0s 340us/step - loss: 0.3836 - acc: 0.7905\n",
      "Epoch 14/160\n",
      "358/358 [==============================] - 0s 387us/step - loss: 0.3826 - acc: 0.7940\n",
      "Epoch 15/160\n",
      "358/358 [==============================] - 0s 325us/step - loss: 0.3839 - acc: 0.7933\n",
      "Epoch 16/160\n",
      "358/358 [==============================] - 0s 411us/step - loss: 0.3840 - acc: 0.7849\n",
      "Epoch 17/160\n",
      "358/358 [==============================] - 0s 366us/step - loss: 0.3783 - acc: 0.7996\n",
      "Epoch 18/160\n",
      "358/358 [==============================] - 0s 402us/step - loss: 0.3787 - acc: 0.8010\n",
      "Epoch 19/160\n",
      "358/358 [==============================] - 0s 352us/step - loss: 0.3771 - acc: 0.7954\n",
      "Epoch 20/160\n",
      "358/358 [==============================] - 0s 350us/step - loss: 0.3858 - acc: 0.7772\n",
      "Epoch 21/160\n",
      "358/358 [==============================] - 0s 366us/step - loss: 0.3762 - acc: 0.7891\n",
      "Epoch 22/160\n",
      "358/358 [==============================] - 0s 388us/step - loss: 0.3750 - acc: 0.8010\n",
      "Epoch 23/160\n",
      "358/358 [==============================] - 0s 393us/step - loss: 0.3708 - acc: 0.7947\n",
      "Epoch 24/160\n",
      "358/358 [==============================] - 0s 364us/step - loss: 0.3740 - acc: 0.8010\n",
      "Epoch 25/160\n",
      "358/358 [==============================] - 0s 381us/step - loss: 0.3670 - acc: 0.8031\n",
      "Epoch 26/160\n",
      "358/358 [==============================] - 0s 366us/step - loss: 0.3736 - acc: 0.7919\n",
      "Epoch 27/160\n",
      "358/358 [==============================] - 0s 412us/step - loss: 0.3666 - acc: 0.7891\n",
      "Epoch 28/160\n",
      "358/358 [==============================] - 0s 383us/step - loss: 0.3931 - acc: 0.7723\n",
      "Epoch 29/160\n",
      "358/358 [==============================] - 0s 358us/step - loss: 0.3799 - acc: 0.7807\n",
      "Epoch 30/160\n",
      "358/358 [==============================] - 0s 369us/step - loss: 0.3759 - acc: 0.7779\n",
      "Epoch 31/160\n",
      "358/358 [==============================] - 0s 340us/step - loss: 0.3710 - acc: 0.7919\n",
      "Epoch 32/160\n",
      "358/358 [==============================] - 0s 389us/step - loss: 0.3675 - acc: 0.7982\n",
      "Epoch 33/160\n",
      "358/358 [==============================] - 0s 368us/step - loss: 0.3787 - acc: 0.7723\n",
      "Epoch 34/160\n",
      "358/358 [==============================] - 0s 372us/step - loss: 0.3780 - acc: 0.7828\n",
      "Epoch 35/160\n",
      "358/358 [==============================] - 0s 374us/step - loss: 0.3709 - acc: 0.7856\n",
      "Epoch 36/160\n",
      "358/358 [==============================] - 0s 447us/step - loss: 0.3678 - acc: 0.7891\n",
      "Epoch 37/160\n",
      "358/358 [==============================] - 0s 415us/step - loss: 0.3714 - acc: 0.7863\n",
      "Epoch 38/160\n",
      "358/358 [==============================] - 0s 376us/step - loss: 0.3817 - acc: 0.7758\n",
      "Epoch 39/160\n",
      "358/358 [==============================] - 0s 363us/step - loss: 0.3938 - acc: 0.7633\n",
      "Epoch 40/160\n",
      "358/358 [==============================] - 0s 402us/step - loss: 0.3747 - acc: 0.7793\n",
      "Epoch 41/160\n",
      "358/358 [==============================] - 0s 405us/step - loss: 0.3694 - acc: 0.7954 0s - loss: 0.3605 - acc: 0.81\n",
      "Epoch 42/160\n",
      "358/358 [==============================] - 0s 363us/step - loss: 0.3685 - acc: 0.7912\n",
      "Epoch 43/160\n",
      "358/358 [==============================] - 0s 381us/step - loss: 0.3663 - acc: 0.7877\n",
      "Epoch 44/160\n",
      "358/358 [==============================] - 0s 367us/step - loss: 0.3623 - acc: 0.7926\n",
      "Epoch 45/160\n",
      "358/358 [==============================] - 0s 398us/step - loss: 0.3598 - acc: 0.7954\n",
      "Epoch 46/160\n",
      "358/358 [==============================] - 0s 351us/step - loss: 0.3685 - acc: 0.7996\n",
      "Epoch 47/160\n",
      "358/358 [==============================] - 0s 403us/step - loss: 0.3673 - acc: 0.7947\n",
      "Epoch 48/160\n",
      "358/358 [==============================] - 0s 337us/step - loss: 0.3708 - acc: 0.7947\n",
      "Epoch 49/160\n",
      "358/358 [==============================] - 0s 354us/step - loss: 0.3722 - acc: 0.7863\n",
      "Epoch 50/160\n",
      "358/358 [==============================] - 0s 381us/step - loss: 0.3610 - acc: 0.8128\n",
      "Epoch 51/160\n",
      "358/358 [==============================] - 0s 380us/step - loss: 0.3645 - acc: 0.8135\n",
      "Epoch 52/160\n",
      "358/358 [==============================] - 0s 397us/step - loss: 0.3607 - acc: 0.8010\n",
      "Epoch 53/160\n",
      "358/358 [==============================] - 0s 402us/step - loss: 0.3577 - acc: 0.8101\n",
      "Epoch 54/160\n",
      "358/358 [==============================] - 0s 375us/step - loss: 0.3541 - acc: 0.8128\n",
      "Epoch 55/160\n",
      "358/358 [==============================] - 0s 347us/step - loss: 0.3639 - acc: 0.8122\n",
      "Epoch 56/160\n",
      "358/358 [==============================] - 0s 403us/step - loss: 0.3631 - acc: 0.8108\n",
      "Epoch 57/160\n",
      "358/358 [==============================] - 0s 347us/step - loss: 0.3592 - acc: 0.8101\n",
      "Epoch 58/160\n",
      "358/358 [==============================] - 0s 399us/step - loss: 0.3518 - acc: 0.8170\n",
      "Epoch 59/160\n",
      "358/358 [==============================] - 0s 345us/step - loss: 0.3546 - acc: 0.8219\n",
      "Epoch 60/160\n",
      "358/358 [==============================] - 0s 399us/step - loss: 0.3502 - acc: 0.8226\n",
      "Epoch 61/160\n",
      "358/358 [==============================] - 0s 344us/step - loss: 0.3523 - acc: 0.8219\n",
      "Epoch 62/160\n",
      "358/358 [==============================] - 0s 357us/step - loss: 0.3517 - acc: 0.8156\n",
      "Epoch 63/160\n",
      "358/358 [==============================] - 0s 323us/step - loss: 0.3585 - acc: 0.8101\n",
      "Epoch 64/160\n",
      "358/358 [==============================] - 0s 367us/step - loss: 0.3564 - acc: 0.8170\n",
      "Epoch 65/160\n",
      "358/358 [==============================] - 0s 330us/step - loss: 0.3519 - acc: 0.8149\n",
      "Epoch 66/160\n",
      "358/358 [==============================] - 0s 397us/step - loss: 0.3533 - acc: 0.8122\n",
      "Epoch 67/160\n",
      "358/358 [==============================] - 0s 392us/step - loss: 0.3494 - acc: 0.8240\n",
      "Epoch 68/160\n",
      "358/358 [==============================] - 0s 371us/step - loss: 0.3442 - acc: 0.8303\n",
      "Epoch 69/160\n",
      "358/358 [==============================] - 0s 355us/step - loss: 0.3528 - acc: 0.8094\n",
      "Epoch 70/160\n",
      "358/358 [==============================] - 0s 335us/step - loss: 0.3538 - acc: 0.8163\n",
      "Epoch 71/160\n",
      "358/358 [==============================] - 0s 371us/step - loss: 0.3535 - acc: 0.8073\n",
      "Epoch 72/160\n",
      "358/358 [==============================] - 0s 334us/step - loss: 0.3492 - acc: 0.8177\n",
      "Epoch 73/160\n",
      "358/358 [==============================] - 0s 400us/step - loss: 0.3658 - acc: 0.8010\n",
      "Epoch 74/160\n",
      "358/358 [==============================] - 0s 338us/step - loss: 0.3626 - acc: 0.7926\n",
      "Epoch 75/160\n",
      "358/358 [==============================] - 0s 393us/step - loss: 0.3516 - acc: 0.8128\n",
      "Epoch 76/160\n",
      "358/358 [==============================] - 0s 338us/step - loss: 0.3602 - acc: 0.8045\n",
      "Epoch 77/160\n",
      "358/358 [==============================] - 0s 372us/step - loss: 0.3583 - acc: 0.7996\n",
      "Epoch 78/160\n",
      "358/358 [==============================] - 0s 363us/step - loss: 0.3527 - acc: 0.8122\n",
      "Epoch 79/160\n",
      "358/358 [==============================] - 0s 354us/step - loss: 0.3543 - acc: 0.8226\n",
      "Epoch 80/160\n",
      "358/358 [==============================] - 0s 348us/step - loss: 0.3495 - acc: 0.8156\n",
      "Epoch 81/160\n",
      "358/358 [==============================] - 0s 371us/step - loss: 0.3568 - acc: 0.8024\n",
      "Epoch 82/160\n",
      "358/358 [==============================] - 0s 341us/step - loss: 0.3619 - acc: 0.8017\n",
      "Epoch 83/160\n",
      "358/358 [==============================] - 0s 405us/step - loss: 0.3667 - acc: 0.7982\n",
      "Epoch 84/160\n",
      "358/358 [==============================] - 0s 337us/step - loss: 0.3618 - acc: 0.7982\n",
      "Epoch 85/160\n",
      "358/358 [==============================] - 0s 396us/step - loss: 0.3617 - acc: 0.8073\n",
      "Epoch 86/160\n",
      "358/358 [==============================] - 0s 366us/step - loss: 0.3538 - acc: 0.8149\n",
      "Epoch 87/160\n",
      "358/358 [==============================] - 0s 337us/step - loss: 0.3484 - acc: 0.8142\n",
      "Epoch 88/160\n",
      "358/358 [==============================] - 0s 321us/step - loss: 0.3459 - acc: 0.8219\n",
      "Epoch 89/160\n",
      "358/358 [==============================] - 0s 355us/step - loss: 0.3398 - acc: 0.8268\n",
      "Epoch 90/160\n",
      "358/358 [==============================] - 0s 337us/step - loss: 0.3484 - acc: 0.8212\n",
      "Epoch 91/160\n",
      "358/358 [==============================] - 0s 342us/step - loss: 0.3431 - acc: 0.8163\n",
      "Epoch 92/160\n",
      "358/358 [==============================] - 0s 366us/step - loss: 0.3443 - acc: 0.8170\n",
      "Epoch 93/160\n",
      "358/358 [==============================] - 0s 336us/step - loss: 0.3452 - acc: 0.8184\n",
      "Epoch 94/160\n",
      "358/358 [==============================] - 0s 347us/step - loss: 0.3383 - acc: 0.8268\n",
      "Epoch 95/160\n",
      "358/358 [==============================] - 0s 338us/step - loss: 0.3436 - acc: 0.8191\n",
      "Epoch 96/160\n",
      "358/358 [==============================] - 0s 371us/step - loss: 0.3493 - acc: 0.8156\n",
      "Epoch 97/160\n",
      "358/358 [==============================] - 0s 416us/step - loss: 0.3358 - acc: 0.8219\n",
      "Epoch 98/160\n",
      "358/358 [==============================] - 0s 413us/step - loss: 0.3388 - acc: 0.8233\n",
      "Epoch 99/160\n",
      "358/358 [==============================] - 0s 379us/step - loss: 0.3374 - acc: 0.8310\n",
      "Epoch 100/160\n",
      "358/358 [==============================] - 0s 368us/step - loss: 0.3578 - acc: 0.8170\n",
      "Epoch 101/160\n",
      "358/358 [==============================] - 0s 329us/step - loss: 0.3557 - acc: 0.8191\n",
      "Epoch 102/160\n",
      "358/358 [==============================] - 0s 352us/step - loss: 0.3463 - acc: 0.8205\n",
      "Epoch 103/160\n",
      "358/358 [==============================] - 0s 312us/step - loss: 0.3500 - acc: 0.8108\n",
      "Epoch 104/160\n",
      "358/358 [==============================] - 0s 352us/step - loss: 0.3430 - acc: 0.8038\n",
      "Epoch 105/160\n",
      "358/358 [==============================] - 0s 342us/step - loss: 0.3471 - acc: 0.8135\n",
      "Epoch 106/160\n",
      "358/358 [==============================] - 0s 354us/step - loss: 0.3426 - acc: 0.8205\n",
      "Epoch 107/160\n",
      "358/358 [==============================] - 0s 329us/step - loss: 0.3398 - acc: 0.8219\n",
      "Epoch 108/160\n",
      "358/358 [==============================] - 0s 328us/step - loss: 0.3460 - acc: 0.8115\n",
      "Epoch 109/160\n",
      "358/358 [==============================] - 0s 362us/step - loss: 0.3519 - acc: 0.8163\n",
      "Epoch 110/160\n",
      "358/358 [==============================] - 0s 385us/step - loss: 0.3535 - acc: 0.8170\n",
      "Epoch 111/160\n",
      "358/358 [==============================] - 0s 350us/step - loss: 0.3491 - acc: 0.8191\n",
      "Epoch 112/160\n",
      "358/358 [==============================] - 0s 359us/step - loss: 0.3414 - acc: 0.8233\n",
      "Epoch 113/160\n",
      "358/358 [==============================] - 0s 352us/step - loss: 0.3411 - acc: 0.8275\n",
      "Epoch 114/160\n",
      "358/358 [==============================] - 0s 354us/step - loss: 0.3444 - acc: 0.8135\n",
      "Epoch 115/160\n",
      "358/358 [==============================] - 0s 325us/step - loss: 0.3372 - acc: 0.8296\n",
      "Epoch 116/160\n",
      "358/358 [==============================] - 0s 375us/step - loss: 0.3383 - acc: 0.8191\n",
      "Epoch 117/160\n",
      "358/358 [==============================] - 0s 332us/step - loss: 0.3421 - acc: 0.8275\n",
      "Epoch 118/160\n",
      "358/358 [==============================] - 0s 485us/step - loss: 0.3328 - acc: 0.8261\n",
      "Epoch 119/160\n",
      "358/358 [==============================] - 0s 513us/step - loss: 0.3313 - acc: 0.8296\n",
      "Epoch 120/160\n",
      "358/358 [==============================] - 0s 385us/step - loss: 0.3353 - acc: 0.8289\n",
      "Epoch 121/160\n",
      "358/358 [==============================] - 0s 477us/step - loss: 0.3474 - acc: 0.8122\n",
      "Epoch 122/160\n",
      "358/358 [==============================] - 0s 453us/step - loss: 0.3467 - acc: 0.7989\n",
      "Epoch 123/160\n",
      "358/358 [==============================] - 0s 339us/step - loss: 0.3355 - acc: 0.8233\n",
      "Epoch 124/160\n",
      "358/358 [==============================] - 0s 399us/step - loss: 0.3347 - acc: 0.8205\n",
      "Epoch 125/160\n",
      "358/358 [==============================] - 0s 373us/step - loss: 0.3445 - acc: 0.8108\n",
      "Epoch 126/160\n",
      "358/358 [==============================] - 0s 354us/step - loss: 0.3306 - acc: 0.8303\n",
      "Epoch 127/160\n",
      "358/358 [==============================] - 0s 350us/step - loss: 0.3337 - acc: 0.8345\n",
      "Epoch 128/160\n",
      "358/358 [==============================] - 0s 389us/step - loss: 0.3375 - acc: 0.8247\n",
      "Epoch 129/160\n",
      "358/358 [==============================] - 0s 399us/step - loss: 0.3371 - acc: 0.8268\n",
      "Epoch 130/160\n",
      "358/358 [==============================] - 0s 538us/step - loss: 0.3274 - acc: 0.8380\n",
      "Epoch 131/160\n",
      "358/358 [==============================] - 0s 466us/step - loss: 0.3413 - acc: 0.8142\n",
      "Epoch 132/160\n",
      "358/358 [==============================] - 0s 482us/step - loss: 0.3387 - acc: 0.8198\n",
      "Epoch 133/160\n",
      "358/358 [==============================] - 0s 388us/step - loss: 0.3409 - acc: 0.8198\n",
      "Epoch 134/160\n",
      "358/358 [==============================] - 0s 373us/step - loss: 0.3402 - acc: 0.8233\n",
      "Epoch 135/160\n",
      "358/358 [==============================] - 0s 346us/step - loss: 0.3385 - acc: 0.8261\n",
      "Epoch 136/160\n",
      "358/358 [==============================] - 0s 360us/step - loss: 0.3364 - acc: 0.8254\n",
      "Epoch 137/160\n",
      "358/358 [==============================] - 0s 346us/step - loss: 0.3434 - acc: 0.8226\n",
      "Epoch 138/160\n",
      "358/358 [==============================] - 0s 366us/step - loss: 0.3313 - acc: 0.8289\n",
      "Epoch 139/160\n",
      "358/358 [==============================] - 0s 338us/step - loss: 0.3345 - acc: 0.8212\n",
      "Epoch 140/160\n",
      "358/358 [==============================] - 0s 378us/step - loss: 0.3314 - acc: 0.8198\n",
      "Epoch 141/160\n",
      "358/358 [==============================] - 0s 340us/step - loss: 0.3395 - acc: 0.8170\n",
      "Epoch 142/160\n",
      "358/358 [==============================] - 0s 428us/step - loss: 0.3406 - acc: 0.8212\n",
      "Epoch 143/160\n",
      "358/358 [==============================] - 0s 473us/step - loss: 0.3342 - acc: 0.8289\n",
      "Epoch 144/160\n",
      "358/358 [==============================] - 0s 371us/step - loss: 0.3379 - acc: 0.8247\n",
      "Epoch 145/160\n",
      "358/358 [==============================] - 0s 436us/step - loss: 0.3329 - acc: 0.8268\n",
      "Epoch 146/160\n",
      "358/358 [==============================] - 0s 379us/step - loss: 0.3390 - acc: 0.8198\n",
      "Epoch 147/160\n",
      "358/358 [==============================] - 0s 366us/step - loss: 0.3329 - acc: 0.8247\n",
      "Epoch 148/160\n",
      "358/358 [==============================] - 0s 367us/step - loss: 0.3250 - acc: 0.8352\n",
      "Epoch 149/160\n",
      "358/358 [==============================] - 0s 365us/step - loss: 0.3388 - acc: 0.8233\n",
      "Epoch 150/160\n",
      "358/358 [==============================] - 0s 416us/step - loss: 0.3347 - acc: 0.8261\n",
      "Epoch 151/160\n",
      "358/358 [==============================] - 0s 354us/step - loss: 0.3306 - acc: 0.8275\n",
      "Epoch 152/160\n",
      "358/358 [==============================] - 0s 352us/step - loss: 0.3404 - acc: 0.8142\n",
      "Epoch 153/160\n",
      "358/358 [==============================] - 0s 358us/step - loss: 0.3402 - acc: 0.8170\n",
      "Epoch 154/160\n",
      "358/358 [==============================] - 0s 368us/step - loss: 0.3473 - acc: 0.8142\n",
      "Epoch 155/160\n",
      "358/358 [==============================] - 0s 435us/step - loss: 0.3339 - acc: 0.8233\n",
      "Epoch 156/160\n",
      "358/358 [==============================] - 0s 367us/step - loss: 0.3331 - acc: 0.8317\n",
      "Epoch 157/160\n",
      "358/358 [==============================] - 0s 388us/step - loss: 0.3271 - acc: 0.8303\n",
      "Epoch 158/160\n",
      "358/358 [==============================] - 0s 373us/step - loss: 0.3270 - acc: 0.8261\n",
      "Epoch 159/160\n",
      "358/358 [==============================] - 0s 409us/step - loss: 0.3285 - acc: 0.8226\n",
      "Epoch 160/160\n",
      "358/358 [==============================] - 0s 385us/step - loss: 0.3282 - acc: 0.8317\n",
      "90/90 [==============================] - 1s 6ms/step\n",
      "358/358 [==============================] - 0s 137us/step\n",
      "\n",
      "acc: 72.78%\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "[[22 14  0  0]\n",
      " [12 35  0  0]\n",
      " [ 1  0  1  0]\n",
      " [ 3  1  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.58      0.61      0.59        36\n",
      "      Normal       0.70      0.74      0.72        47\n",
      "        Slow       1.00      0.50      0.67         2\n",
      "   Very Fast       1.00      0.20      0.33         5\n",
      "\n",
      "    accuracy                           0.66        90\n",
      "   macro avg       0.82      0.51      0.58        90\n",
      "weighted avg       0.67      0.66      0.65        90\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6555555555555556"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='normal_city') & (df_k.Timelevel==2)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy:normal_city and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "337/337 [==============================] - 2s 7ms/step - loss: 0.4633 - acc: 0.7552\n",
      "Epoch 2/160\n",
      "337/337 [==============================] - 0s 358us/step - loss: 0.3873 - acc: 0.7596\n",
      "Epoch 3/160\n",
      "337/337 [==============================] - 0s 374us/step - loss: 0.3923 - acc: 0.7270\n",
      "Epoch 4/160\n",
      "337/337 [==============================] - 0s 349us/step - loss: 0.3813 - acc: 0.7559\n",
      "Epoch 5/160\n",
      "337/337 [==============================] - 0s 334us/step - loss: 0.3716 - acc: 0.7619\n",
      "Epoch 6/160\n",
      "337/337 [==============================] - 0s 358us/step - loss: 0.3639 - acc: 0.7797\n",
      "Epoch 7/160\n",
      "337/337 [==============================] - 0s 335us/step - loss: 0.3611 - acc: 0.7812\n",
      "Epoch 8/160\n",
      "337/337 [==============================] - 0s 382us/step - loss: 0.3606 - acc: 0.7797\n",
      "Epoch 9/160\n",
      "337/337 [==============================] - 0s 338us/step - loss: 0.3578 - acc: 0.7982\n",
      "Epoch 10/160\n",
      "337/337 [==============================] - 0s 345us/step - loss: 0.3573 - acc: 0.7878\n",
      "Epoch 11/160\n",
      "337/337 [==============================] - 0s 342us/step - loss: 0.3487 - acc: 0.7908\n",
      "Epoch 12/160\n",
      "337/337 [==============================] - 0s 362us/step - loss: 0.3521 - acc: 0.7774\n",
      "Epoch 13/160\n",
      "337/337 [==============================] - 0s 357us/step - loss: 0.3559 - acc: 0.7715\n",
      "Epoch 14/160\n",
      "337/337 [==============================] - 0s 367us/step - loss: 0.3532 - acc: 0.7923\n",
      "Epoch 15/160\n",
      "337/337 [==============================] - 0s 346us/step - loss: 0.3467 - acc: 0.7953\n",
      "Epoch 16/160\n",
      "337/337 [==============================] - 0s 379us/step - loss: 0.3438 - acc: 0.7901\n",
      "Epoch 17/160\n",
      "337/337 [==============================] - 0s 331us/step - loss: 0.3444 - acc: 0.7997\n",
      "Epoch 18/160\n",
      "337/337 [==============================] - 0s 366us/step - loss: 0.3403 - acc: 0.8012\n",
      "Epoch 19/160\n",
      "337/337 [==============================] - 0s 361us/step - loss: 0.3387 - acc: 0.7953\n",
      "Epoch 20/160\n",
      "337/337 [==============================] - 0s 356us/step - loss: 0.3457 - acc: 0.8012\n",
      "Epoch 21/160\n",
      "337/337 [==============================] - 0s 356us/step - loss: 0.3469 - acc: 0.7856\n",
      "Epoch 22/160\n",
      "337/337 [==============================] - 0s 356us/step - loss: 0.3393 - acc: 0.7915\n",
      "Epoch 23/160\n",
      "337/337 [==============================] - 0s 378us/step - loss: 0.3326 - acc: 0.8093\n",
      "Epoch 24/160\n",
      "337/337 [==============================] - 0s 329us/step - loss: 0.3300 - acc: 0.7960\n",
      "Epoch 25/160\n",
      "337/337 [==============================] - 0s 401us/step - loss: 0.3260 - acc: 0.8027\n",
      "Epoch 26/160\n",
      "337/337 [==============================] - 0s 378us/step - loss: 0.3361 - acc: 0.8101\n",
      "Epoch 27/160\n",
      "337/337 [==============================] - 0s 347us/step - loss: 0.3317 - acc: 0.8042\n",
      "Epoch 28/160\n",
      "337/337 [==============================] - 0s 400us/step - loss: 0.3321 - acc: 0.8034\n",
      "Epoch 29/160\n",
      "337/337 [==============================] - 0s 343us/step - loss: 0.3489 - acc: 0.7774\n",
      "Epoch 30/160\n",
      "337/337 [==============================] - 0s 375us/step - loss: 0.3386 - acc: 0.7856\n",
      "Epoch 31/160\n",
      "337/337 [==============================] - 0s 356us/step - loss: 0.3324 - acc: 0.8056\n",
      "Epoch 32/160\n",
      "337/337 [==============================] - 0s 388us/step - loss: 0.3258 - acc: 0.8116\n",
      "Epoch 33/160\n",
      "337/337 [==============================] - 0s 321us/step - loss: 0.3247 - acc: 0.8027\n",
      "Epoch 34/160\n",
      "337/337 [==============================] - 0s 402us/step - loss: 0.3270 - acc: 0.8004\n",
      "Epoch 35/160\n",
      "337/337 [==============================] - 0s 324us/step - loss: 0.3276 - acc: 0.8049\n",
      "Epoch 36/160\n",
      "337/337 [==============================] - 0s 364us/step - loss: 0.3216 - acc: 0.8049\n",
      "Epoch 37/160\n",
      "337/337 [==============================] - 0s 334us/step - loss: 0.3272 - acc: 0.8049\n",
      "Epoch 38/160\n",
      "337/337 [==============================] - 0s 359us/step - loss: 0.3261 - acc: 0.8049\n",
      "Epoch 39/160\n",
      "337/337 [==============================] - 0s 352us/step - loss: 0.3229 - acc: 0.8056\n",
      "Epoch 40/160\n",
      "337/337 [==============================] - 0s 354us/step - loss: 0.3271 - acc: 0.7990\n",
      "Epoch 41/160\n",
      "337/337 [==============================] - 0s 473us/step - loss: 0.3180 - acc: 0.8086\n",
      "Epoch 42/160\n",
      "337/337 [==============================] - 0s 360us/step - loss: 0.3194 - acc: 0.8123\n",
      "Epoch 43/160\n",
      "337/337 [==============================] - 0s 365us/step - loss: 0.3215 - acc: 0.8101\n",
      "Epoch 44/160\n",
      "337/337 [==============================] - 0s 384us/step - loss: 0.3168 - acc: 0.8197\n",
      "Epoch 45/160\n",
      "337/337 [==============================] - 0s 343us/step - loss: 0.3254 - acc: 0.7953\n",
      "Epoch 46/160\n",
      "337/337 [==============================] - 0s 343us/step - loss: 0.3255 - acc: 0.8123\n",
      "Epoch 47/160\n",
      "337/337 [==============================] - 0s 364us/step - loss: 0.3299 - acc: 0.7856\n",
      "Epoch 48/160\n",
      "337/337 [==============================] - 0s 361us/step - loss: 0.3371 - acc: 0.8079\n",
      "Epoch 49/160\n",
      "337/337 [==============================] - 0s 375us/step - loss: 0.3201 - acc: 0.7938\n",
      "Epoch 50/160\n",
      "337/337 [==============================] - 0s 346us/step - loss: 0.3168 - acc: 0.8138\n",
      "Epoch 51/160\n",
      "337/337 [==============================] - 0s 356us/step - loss: 0.3178 - acc: 0.8182\n",
      "Epoch 52/160\n",
      "337/337 [==============================] - 0s 373us/step - loss: 0.3143 - acc: 0.8160\n",
      "Epoch 53/160\n",
      "337/337 [==============================] - 0s 349us/step - loss: 0.3100 - acc: 0.8175\n",
      "Epoch 54/160\n",
      "337/337 [==============================] - 0s 384us/step - loss: 0.3158 - acc: 0.8153\n",
      "Epoch 55/160\n",
      "337/337 [==============================] - 0s 365us/step - loss: 0.3145 - acc: 0.8257\n",
      "Epoch 56/160\n",
      "337/337 [==============================] - 0s 337us/step - loss: 0.3173 - acc: 0.8168\n",
      "Epoch 57/160\n",
      "337/337 [==============================] - 0s 372us/step - loss: 0.3217 - acc: 0.8123\n",
      "Epoch 58/160\n",
      "337/337 [==============================] - 0s 318us/step - loss: 0.3198 - acc: 0.8034\n",
      "Epoch 59/160\n",
      "337/337 [==============================] - 0s 394us/step - loss: 0.3120 - acc: 0.8175\n",
      "Epoch 60/160\n",
      "337/337 [==============================] - 0s 361us/step - loss: 0.3112 - acc: 0.8175\n",
      "Epoch 61/160\n",
      "337/337 [==============================] - 0s 330us/step - loss: 0.3169 - acc: 0.7960\n",
      "Epoch 62/160\n",
      "337/337 [==============================] - 0s 350us/step - loss: 0.3132 - acc: 0.8190\n",
      "Epoch 63/160\n",
      "337/337 [==============================] - 0s 362us/step - loss: 0.3153 - acc: 0.8108\n",
      "Epoch 64/160\n",
      "337/337 [==============================] - 0s 371us/step - loss: 0.3244 - acc: 0.7975\n",
      "Epoch 65/160\n",
      "337/337 [==============================] - 0s 368us/step - loss: 0.3158 - acc: 0.8153\n",
      "Epoch 66/160\n",
      "337/337 [==============================] - 0s 329us/step - loss: 0.3265 - acc: 0.8108\n",
      "Epoch 67/160\n",
      "337/337 [==============================] - 0s 362us/step - loss: 0.3162 - acc: 0.8086\n",
      "Epoch 68/160\n",
      "337/337 [==============================] - 0s 334us/step - loss: 0.3137 - acc: 0.8153\n",
      "Epoch 69/160\n",
      "337/337 [==============================] - 0s 409us/step - loss: 0.3158 - acc: 0.8234\n",
      "Epoch 70/160\n",
      "337/337 [==============================] - 0s 329us/step - loss: 0.3178 - acc: 0.8160\n",
      "Epoch 71/160\n",
      "337/337 [==============================] - 0s 342us/step - loss: 0.3238 - acc: 0.8019\n",
      "Epoch 72/160\n",
      "337/337 [==============================] - 0s 354us/step - loss: 0.3123 - acc: 0.8205\n",
      "Epoch 73/160\n",
      "337/337 [==============================] - 0s 373us/step - loss: 0.3111 - acc: 0.8279\n",
      "Epoch 74/160\n",
      "337/337 [==============================] - 0s 322us/step - loss: 0.3167 - acc: 0.8190\n",
      "Epoch 75/160\n",
      "337/337 [==============================] - 0s 380us/step - loss: 0.3093 - acc: 0.8272\n",
      "Epoch 76/160\n",
      "337/337 [==============================] - 0s 332us/step - loss: 0.3017 - acc: 0.8309\n",
      "Epoch 77/160\n",
      "337/337 [==============================] - 0s 360us/step - loss: 0.3058 - acc: 0.8227\n",
      "Epoch 78/160\n",
      "337/337 [==============================] - 0s 410us/step - loss: 0.3196 - acc: 0.8027\n",
      "Epoch 79/160\n",
      "337/337 [==============================] - 0s 329us/step - loss: 0.3184 - acc: 0.8190\n",
      "Epoch 80/160\n",
      "337/337 [==============================] - 0s 333us/step - loss: 0.3157 - acc: 0.8131\n",
      "Epoch 81/160\n",
      "337/337 [==============================] - 0s 403us/step - loss: 0.3219 - acc: 0.8123\n",
      "Epoch 82/160\n",
      "337/337 [==============================] - 0s 355us/step - loss: 0.3122 - acc: 0.8027\n",
      "Epoch 83/160\n",
      "337/337 [==============================] - 0s 365us/step - loss: 0.3060 - acc: 0.8212\n",
      "Epoch 84/160\n",
      "337/337 [==============================] - 0s 310us/step - loss: 0.3083 - acc: 0.8279\n",
      "Epoch 85/160\n",
      "337/337 [==============================] - 0s 363us/step - loss: 0.3148 - acc: 0.8168\n",
      "Epoch 86/160\n",
      "337/337 [==============================] - 0s 330us/step - loss: 0.3075 - acc: 0.8361\n",
      "Epoch 87/160\n",
      "337/337 [==============================] - 0s 349us/step - loss: 0.3081 - acc: 0.8309\n",
      "Epoch 88/160\n",
      "337/337 [==============================] - 0s 328us/step - loss: 0.3177 - acc: 0.8205\n",
      "Epoch 89/160\n",
      "337/337 [==============================] - 0s 331us/step - loss: 0.3113 - acc: 0.8086\n",
      "Epoch 90/160\n",
      "337/337 [==============================] - 0s 371us/step - loss: 0.3106 - acc: 0.8042\n",
      "Epoch 91/160\n",
      "337/337 [==============================] - 0s 354us/step - loss: 0.3073 - acc: 0.8242\n",
      "Epoch 92/160\n",
      "337/337 [==============================] - 0s 363us/step - loss: 0.3196 - acc: 0.8049\n",
      "Epoch 93/160\n",
      "337/337 [==============================] - 0s 330us/step - loss: 0.3144 - acc: 0.8205\n",
      "Epoch 94/160\n",
      "337/337 [==============================] - 0s 359us/step - loss: 0.3073 - acc: 0.8182\n",
      "Epoch 95/160\n",
      "337/337 [==============================] - 0s 335us/step - loss: 0.3142 - acc: 0.8093\n",
      "Epoch 96/160\n",
      "337/337 [==============================] - 0s 396us/step - loss: 0.3077 - acc: 0.8190\n",
      "Epoch 97/160\n",
      "337/337 [==============================] - 0s 305us/step - loss: 0.3085 - acc: 0.8153\n",
      "Epoch 98/160\n",
      "337/337 [==============================] - 0s 392us/step - loss: 0.2988 - acc: 0.8108\n",
      "Epoch 99/160\n",
      "337/337 [==============================] - 0s 325us/step - loss: 0.3129 - acc: 0.8160\n",
      "Epoch 100/160\n",
      "337/337 [==============================] - 0s 353us/step - loss: 0.3145 - acc: 0.8131\n",
      "Epoch 101/160\n",
      "337/337 [==============================] - 0s 343us/step - loss: 0.3134 - acc: 0.8190\n",
      "Epoch 102/160\n",
      "337/337 [==============================] - 0s 294us/step - loss: 0.3064 - acc: 0.8309\n",
      "Epoch 103/160\n",
      "337/337 [==============================] - 0s 323us/step - loss: 0.2999 - acc: 0.8153\n",
      "Epoch 104/160\n",
      "337/337 [==============================] - 0s 358us/step - loss: 0.2995 - acc: 0.8294\n",
      "Epoch 105/160\n",
      "337/337 [==============================] - 0s 324us/step - loss: 0.2931 - acc: 0.8398\n",
      "Epoch 106/160\n",
      "337/337 [==============================] - 0s 342us/step - loss: 0.2979 - acc: 0.8346\n",
      "Epoch 107/160\n",
      "337/337 [==============================] - 0s 353us/step - loss: 0.3040 - acc: 0.8182\n",
      "Epoch 108/160\n",
      "337/337 [==============================] - 0s 345us/step - loss: 0.3011 - acc: 0.8123\n",
      "Epoch 109/160\n",
      "337/337 [==============================] - 0s 354us/step - loss: 0.2954 - acc: 0.8294\n",
      "Epoch 110/160\n",
      "337/337 [==============================] - 0s 317us/step - loss: 0.2980 - acc: 0.8412\n",
      "Epoch 111/160\n",
      "337/337 [==============================] - 0s 383us/step - loss: 0.3062 - acc: 0.8168\n",
      "Epoch 112/160\n",
      "337/337 [==============================] - 0s 342us/step - loss: 0.3108 - acc: 0.8301\n",
      "Epoch 113/160\n",
      "337/337 [==============================] - 0s 370us/step - loss: 0.3207 - acc: 0.8182\n",
      "Epoch 114/160\n",
      "337/337 [==============================] - 0s 318us/step - loss: 0.3123 - acc: 0.8175\n",
      "Epoch 115/160\n",
      "337/337 [==============================] - 0s 370us/step - loss: 0.3125 - acc: 0.8108\n",
      "Epoch 116/160\n",
      "337/337 [==============================] - 0s 327us/step - loss: 0.3067 - acc: 0.8160\n",
      "Epoch 117/160\n",
      "337/337 [==============================] - 0s 331us/step - loss: 0.3013 - acc: 0.8398\n",
      "Epoch 118/160\n",
      "337/337 [==============================] - 0s 337us/step - loss: 0.2994 - acc: 0.8294\n",
      "Epoch 119/160\n",
      "337/337 [==============================] - 0s 374us/step - loss: 0.2957 - acc: 0.8353\n",
      "Epoch 120/160\n",
      "337/337 [==============================] - 0s 324us/step - loss: 0.2962 - acc: 0.8272\n",
      "Epoch 121/160\n",
      "337/337 [==============================] - 0s 294us/step - loss: 0.2908 - acc: 0.8405\n",
      "Epoch 122/160\n",
      "337/337 [==============================] - 0s 341us/step - loss: 0.2968 - acc: 0.8279\n",
      "Epoch 123/160\n",
      "337/337 [==============================] - 0s 349us/step - loss: 0.2901 - acc: 0.8257\n",
      "Epoch 124/160\n",
      "337/337 [==============================] - 0s 312us/step - loss: 0.3180 - acc: 0.8116\n",
      "Epoch 125/160\n",
      "337/337 [==============================] - 0s 341us/step - loss: 0.3080 - acc: 0.8272\n",
      "Epoch 126/160\n",
      "337/337 [==============================] - 0s 388us/step - loss: 0.2995 - acc: 0.8294\n",
      "Epoch 127/160\n",
      "337/337 [==============================] - 0s 292us/step - loss: 0.2950 - acc: 0.8323\n",
      "Epoch 128/160\n",
      "337/337 [==============================] - 0s 378us/step - loss: 0.2940 - acc: 0.8205\n",
      "Epoch 129/160\n",
      "337/337 [==============================] - 0s 324us/step - loss: 0.2995 - acc: 0.8168\n",
      "Epoch 130/160\n",
      "337/337 [==============================] - 0s 346us/step - loss: 0.2976 - acc: 0.8331\n",
      "Epoch 131/160\n",
      "337/337 [==============================] - 0s 371us/step - loss: 0.2927 - acc: 0.8309\n",
      "Epoch 132/160\n",
      "337/337 [==============================] - 0s 319us/step - loss: 0.2953 - acc: 0.8361\n",
      "Epoch 133/160\n",
      "337/337 [==============================] - 0s 314us/step - loss: 0.2997 - acc: 0.8286\n",
      "Epoch 134/160\n",
      "337/337 [==============================] - 0s 375us/step - loss: 0.2963 - acc: 0.8190\n",
      "Epoch 135/160\n",
      "337/337 [==============================] - 0s 317us/step - loss: 0.3057 - acc: 0.8205\n",
      "Epoch 136/160\n",
      "337/337 [==============================] - 0s 341us/step - loss: 0.2938 - acc: 0.8398\n",
      "Epoch 137/160\n",
      "337/337 [==============================] - 0s 340us/step - loss: 0.2941 - acc: 0.8390\n",
      "Epoch 138/160\n",
      "337/337 [==============================] - 0s 287us/step - loss: 0.2873 - acc: 0.8361\n",
      "Epoch 139/160\n",
      "337/337 [==============================] - 0s 368us/step - loss: 0.3024 - acc: 0.8175\n",
      "Epoch 140/160\n",
      "337/337 [==============================] - 0s 310us/step - loss: 0.2911 - acc: 0.8279\n",
      "Epoch 141/160\n",
      "337/337 [==============================] - 0s 358us/step - loss: 0.2889 - acc: 0.8286\n",
      "Epoch 142/160\n",
      "337/337 [==============================] - 0s 326us/step - loss: 0.2870 - acc: 0.8383\n",
      "Epoch 143/160\n",
      "337/337 [==============================] - 0s 348us/step - loss: 0.2856 - acc: 0.8405\n",
      "Epoch 144/160\n",
      "337/337 [==============================] - 0s 310us/step - loss: 0.2911 - acc: 0.8450\n",
      "Epoch 145/160\n",
      "337/337 [==============================] - 0s 334us/step - loss: 0.2923 - acc: 0.8412\n",
      "Epoch 146/160\n",
      "337/337 [==============================] - 0s 346us/step - loss: 0.2926 - acc: 0.8353\n",
      "Epoch 147/160\n",
      "337/337 [==============================] - 0s 332us/step - loss: 0.2975 - acc: 0.8435\n",
      "Epoch 148/160\n",
      "337/337 [==============================] - 0s 335us/step - loss: 0.2888 - acc: 0.8412\n",
      "Epoch 149/160\n",
      "337/337 [==============================] - 0s 346us/step - loss: 0.3047 - acc: 0.8116\n",
      "Epoch 150/160\n",
      "337/337 [==============================] - 0s 340us/step - loss: 0.3149 - acc: 0.8309\n",
      "Epoch 151/160\n",
      "337/337 [==============================] - 0s 296us/step - loss: 0.3286 - acc: 0.7930\n",
      "Epoch 152/160\n",
      "337/337 [==============================] - 0s 378us/step - loss: 0.3110 - acc: 0.8160\n",
      "Epoch 153/160\n",
      "337/337 [==============================] - 0s 297us/step - loss: 0.3002 - acc: 0.8227\n",
      "Epoch 154/160\n",
      "337/337 [==============================] - 0s 367us/step - loss: 0.2975 - acc: 0.8220\n",
      "Epoch 155/160\n",
      "337/337 [==============================] - 0s 317us/step - loss: 0.2905 - acc: 0.8316\n",
      "Epoch 156/160\n",
      "337/337 [==============================] - 0s 376us/step - loss: 0.2955 - acc: 0.8190\n",
      "Epoch 157/160\n",
      "337/337 [==============================] - 0s 321us/step - loss: 0.2921 - acc: 0.8323\n",
      "Epoch 158/160\n",
      "337/337 [==============================] - 0s 345us/step - loss: 0.2869 - acc: 0.8309\n",
      "Epoch 159/160\n",
      "337/337 [==============================] - 0s 347us/step - loss: 0.2850 - acc: 0.8450\n",
      "Epoch 160/160\n",
      "337/337 [==============================] - 0s 337us/step - loss: 0.2922 - acc: 0.8390\n",
      "337/337 [==============================] - 1s 3ms/step\n",
      "\n",
      "acc: 85.24%\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[33 12  0]\n",
      " [ 8 31  0]\n",
      " [ 0  1  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.80      0.73      0.77        45\n",
      "      Normal       0.70      0.79      0.75        39\n",
      "        Slow       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.75        85\n",
      "   macro avg       0.50      0.51      0.50        85\n",
      "weighted avg       0.75      0.75      0.75        85\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7529411764705882"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='normal_city') & (df_k.Timelevel==3)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "      #  if y_test_2.iloc[j][3]==1:\n",
    "            #y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normal_city and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very_fast absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.5185 - acc: 0.7621\n",
      "Epoch 2/160\n",
      "391/391 [==============================] - 0s 374us/step - loss: 0.4170 - acc: 0.7992\n",
      "Epoch 3/160\n",
      "391/391 [==============================] - 0s 391us/step - loss: 0.4042 - acc: 0.8063\n",
      "Epoch 4/160\n",
      "391/391 [==============================] - 0s 384us/step - loss: 0.3980 - acc: 0.8120\n",
      "Epoch 5/160\n",
      "391/391 [==============================] - 0s 409us/step - loss: 0.3952 - acc: 0.8120\n",
      "Epoch 6/160\n",
      "391/391 [==============================] - 0s 351us/step - loss: 0.3935 - acc: 0.8120\n",
      "Epoch 7/160\n",
      "391/391 [==============================] - 0s 380us/step - loss: 0.3965 - acc: 0.8133\n",
      "Epoch 8/160\n",
      "391/391 [==============================] - 0s 333us/step - loss: 0.3920 - acc: 0.8075\n",
      "Epoch 9/160\n",
      "391/391 [==============================] - 0s 411us/step - loss: 0.3896 - acc: 0.8075\n",
      "Epoch 10/160\n",
      "391/391 [==============================] - 0s 415us/step - loss: 0.3933 - acc: 0.8152\n",
      "Epoch 11/160\n",
      "391/391 [==============================] - 0s 502us/step - loss: 0.3990 - acc: 0.8120\n",
      "Epoch 12/160\n",
      "391/391 [==============================] - 0s 601us/step - loss: 0.3941 - acc: 0.8107\n",
      "Epoch 13/160\n",
      "391/391 [==============================] - 0s 344us/step - loss: 0.3913 - acc: 0.8107\n",
      "Epoch 14/160\n",
      "391/391 [==============================] - 0s 293us/step - loss: 0.3887 - acc: 0.8114\n",
      "Epoch 15/160\n",
      "391/391 [==============================] - 0s 332us/step - loss: 0.3895 - acc: 0.8133\n",
      "Epoch 16/160\n",
      "391/391 [==============================] - 0s 314us/step - loss: 0.3850 - acc: 0.8197\n",
      "Epoch 17/160\n",
      "391/391 [==============================] - 0s 537us/step - loss: 0.3847 - acc: 0.8152\n",
      "Epoch 18/160\n",
      "391/391 [==============================] - 0s 657us/step - loss: 0.3865 - acc: 0.8101\n",
      "Epoch 19/160\n",
      "391/391 [==============================] - 0s 629us/step - loss: 0.3823 - acc: 0.8120\n",
      "Epoch 20/160\n",
      "391/391 [==============================] - 0s 648us/step - loss: 0.3842 - acc: 0.8146\n",
      "Epoch 21/160\n",
      "391/391 [==============================] - 0s 540us/step - loss: 0.3802 - acc: 0.8146\n",
      "Epoch 22/160\n",
      "391/391 [==============================] - 0s 438us/step - loss: 0.3805 - acc: 0.8107\n",
      "Epoch 23/160\n",
      "391/391 [==============================] - 0s 400us/step - loss: 0.3840 - acc: 0.8146\n",
      "Epoch 24/160\n",
      "391/391 [==============================] - 0s 444us/step - loss: 0.3903 - acc: 0.8146\n",
      "Epoch 25/160\n",
      "391/391 [==============================] - 0s 466us/step - loss: 0.3901 - acc: 0.8075\n",
      "Epoch 26/160\n",
      "391/391 [==============================] - 0s 458us/step - loss: 0.3860 - acc: 0.8197\n",
      "Epoch 27/160\n",
      "391/391 [==============================] - 0s 338us/step - loss: 0.3778 - acc: 0.8191\n",
      "Epoch 28/160\n",
      "391/391 [==============================] - 0s 342us/step - loss: 0.3789 - acc: 0.8165\n",
      "Epoch 29/160\n",
      "391/391 [==============================] - 0s 441us/step - loss: 0.3771 - acc: 0.8152\n",
      "Epoch 30/160\n",
      "391/391 [==============================] - 0s 448us/step - loss: 0.3783 - acc: 0.8171\n",
      "Epoch 31/160\n",
      "391/391 [==============================] - 0s 395us/step - loss: 0.3736 - acc: 0.8165\n",
      "Epoch 32/160\n",
      "391/391 [==============================] - 0s 414us/step - loss: 0.3764 - acc: 0.8171\n",
      "Epoch 33/160\n",
      "391/391 [==============================] - 0s 420us/step - loss: 0.3749 - acc: 0.8197\n",
      "Epoch 34/160\n",
      "391/391 [==============================] - 0s 401us/step - loss: 0.3802 - acc: 0.8139\n",
      "Epoch 35/160\n",
      "391/391 [==============================] - 0s 369us/step - loss: 0.3755 - acc: 0.8184\n",
      "Epoch 36/160\n",
      "391/391 [==============================] - 0s 433us/step - loss: 0.3785 - acc: 0.8165\n",
      "Epoch 37/160\n",
      "391/391 [==============================] - 0s 372us/step - loss: 0.3752 - acc: 0.8203\n",
      "Epoch 38/160\n",
      "391/391 [==============================] - 0s 394us/step - loss: 0.3739 - acc: 0.8191\n",
      "Epoch 39/160\n",
      "391/391 [==============================] - 0s 427us/step - loss: 0.3737 - acc: 0.8191\n",
      "Epoch 40/160\n",
      "391/391 [==============================] - 0s 386us/step - loss: 0.3760 - acc: 0.8171\n",
      "Epoch 41/160\n",
      "391/391 [==============================] - 0s 430us/step - loss: 0.3808 - acc: 0.8184\n",
      "Epoch 42/160\n",
      "391/391 [==============================] - 0s 380us/step - loss: 0.3734 - acc: 0.8229\n",
      "Epoch 43/160\n",
      "391/391 [==============================] - 0s 365us/step - loss: 0.3757 - acc: 0.8223\n",
      "Epoch 44/160\n",
      "391/391 [==============================] - 0s 379us/step - loss: 0.3740 - acc: 0.8165\n",
      "Epoch 45/160\n",
      "391/391 [==============================] - 0s 376us/step - loss: 0.3774 - acc: 0.8184\n",
      "Epoch 46/160\n",
      "391/391 [==============================] - 0s 375us/step - loss: 0.3686 - acc: 0.8191\n",
      "Epoch 47/160\n",
      "391/391 [==============================] - 0s 332us/step - loss: 0.3678 - acc: 0.8216\n",
      "Epoch 48/160\n",
      "391/391 [==============================] - 0s 360us/step - loss: 0.3663 - acc: 0.8286\n",
      "Epoch 49/160\n",
      "391/391 [==============================] - 0s 394us/step - loss: 0.3689 - acc: 0.8261\n",
      "Epoch 50/160\n",
      "391/391 [==============================] - 0s 335us/step - loss: 0.3618 - acc: 0.8223\n",
      "Epoch 51/160\n",
      "391/391 [==============================] - 0s 376us/step - loss: 0.3736 - acc: 0.8229\n",
      "Epoch 52/160\n",
      "391/391 [==============================] - 0s 350us/step - loss: 0.3660 - acc: 0.8152\n",
      "Epoch 53/160\n",
      "391/391 [==============================] - 0s 410us/step - loss: 0.3681 - acc: 0.8210\n",
      "Epoch 54/160\n",
      "391/391 [==============================] - 0s 359us/step - loss: 0.3669 - acc: 0.8223\n",
      "Epoch 55/160\n",
      "391/391 [==============================] - 0s 348us/step - loss: 0.3609 - acc: 0.8274\n",
      "Epoch 56/160\n",
      "391/391 [==============================] - 0s 362us/step - loss: 0.3637 - acc: 0.8261\n",
      "Epoch 57/160\n",
      "391/391 [==============================] - 0s 332us/step - loss: 0.3654 - acc: 0.8286\n",
      "Epoch 58/160\n",
      "391/391 [==============================] - 0s 347us/step - loss: 0.3626 - acc: 0.8261\n",
      "Epoch 59/160\n",
      "391/391 [==============================] - 0s 321us/step - loss: 0.3628 - acc: 0.8223\n",
      "Epoch 60/160\n",
      "391/391 [==============================] - 0s 345us/step - loss: 0.3713 - acc: 0.8159\n",
      "Epoch 61/160\n",
      "391/391 [==============================] - 0s 364us/step - loss: 0.3844 - acc: 0.8229\n",
      "Epoch 62/160\n",
      "391/391 [==============================] - 0s 355us/step - loss: 0.3803 - acc: 0.8223\n",
      "Epoch 63/160\n",
      "391/391 [==============================] - 0s 361us/step - loss: 0.3794 - acc: 0.8165\n",
      "Epoch 64/160\n",
      "391/391 [==============================] - 0s 349us/step - loss: 0.3701 - acc: 0.8203\n",
      "Epoch 65/160\n",
      "391/391 [==============================] - 0s 345us/step - loss: 0.3716 - acc: 0.8178\n",
      "Epoch 66/160\n",
      "391/391 [==============================] - 0s 297us/step - loss: 0.3673 - acc: 0.8197\n",
      "Epoch 67/160\n",
      "391/391 [==============================] - 0s 415us/step - loss: 0.3652 - acc: 0.8203\n",
      "Epoch 68/160\n",
      "391/391 [==============================] - 0s 340us/step - loss: 0.3658 - acc: 0.8178\n",
      "Epoch 69/160\n",
      "391/391 [==============================] - 0s 377us/step - loss: 0.3630 - acc: 0.8229\n",
      "Epoch 70/160\n",
      "391/391 [==============================] - 0s 345us/step - loss: 0.3638 - acc: 0.8274\n",
      "Epoch 71/160\n",
      "391/391 [==============================] - 0s 392us/step - loss: 0.3638 - acc: 0.8197\n",
      "Epoch 72/160\n",
      "391/391 [==============================] - 0s 373us/step - loss: 0.3610 - acc: 0.8261\n",
      "Epoch 73/160\n",
      "391/391 [==============================] - 0s 307us/step - loss: 0.3608 - acc: 0.8286\n",
      "Epoch 74/160\n",
      "391/391 [==============================] - 0s 417us/step - loss: 0.3606 - acc: 0.8267\n",
      "Epoch 75/160\n",
      "391/391 [==============================] - 0s 340us/step - loss: 0.3665 - acc: 0.8184\n",
      "Epoch 76/160\n",
      "391/391 [==============================] - 0s 361us/step - loss: 0.3586 - acc: 0.8274\n",
      "Epoch 77/160\n",
      "391/391 [==============================] - 0s 344us/step - loss: 0.3552 - acc: 0.8299\n",
      "Epoch 78/160\n",
      "391/391 [==============================] - 0s 326us/step - loss: 0.3593 - acc: 0.8280\n",
      "Epoch 79/160\n",
      "391/391 [==============================] - 0s 403us/step - loss: 0.3711 - acc: 0.8184\n",
      "Epoch 80/160\n",
      "391/391 [==============================] - 0s 384us/step - loss: 0.3638 - acc: 0.8293\n",
      "Epoch 81/160\n",
      "391/391 [==============================] - 0s 406us/step - loss: 0.3603 - acc: 0.8229\n",
      "Epoch 82/160\n",
      "391/391 [==============================] - 0s 344us/step - loss: 0.3525 - acc: 0.8312\n",
      "Epoch 83/160\n",
      "391/391 [==============================] - 0s 379us/step - loss: 0.3507 - acc: 0.8312\n",
      "Epoch 84/160\n",
      "391/391 [==============================] - 0s 392us/step - loss: 0.3521 - acc: 0.8299\n",
      "Epoch 85/160\n",
      "391/391 [==============================] - 0s 333us/step - loss: 0.3548 - acc: 0.8286\n",
      "Epoch 86/160\n",
      "391/391 [==============================] - 0s 334us/step - loss: 0.3527 - acc: 0.8293\n",
      "Epoch 87/160\n",
      "391/391 [==============================] - 0s 330us/step - loss: 0.3589 - acc: 0.8254\n",
      "Epoch 88/160\n",
      "391/391 [==============================] - 0s 357us/step - loss: 0.3674 - acc: 0.8210\n",
      "Epoch 89/160\n",
      "391/391 [==============================] - 0s 367us/step - loss: 0.3614 - acc: 0.8229\n",
      "Epoch 90/160\n",
      "391/391 [==============================] - 0s 330us/step - loss: 0.3690 - acc: 0.8274\n",
      "Epoch 91/160\n",
      "391/391 [==============================] - 0s 347us/step - loss: 0.3647 - acc: 0.8248\n",
      "Epoch 92/160\n",
      "391/391 [==============================] - 0s 341us/step - loss: 0.3645 - acc: 0.8254\n",
      "Epoch 93/160\n",
      "391/391 [==============================] - 0s 371us/step - loss: 0.3612 - acc: 0.8248\n",
      "Epoch 94/160\n",
      "391/391 [==============================] - 0s 346us/step - loss: 0.3581 - acc: 0.8274\n",
      "Epoch 95/160\n",
      "391/391 [==============================] - 0s 359us/step - loss: 0.3563 - acc: 0.8191\n",
      "Epoch 96/160\n",
      "391/391 [==============================] - 0s 315us/step - loss: 0.3542 - acc: 0.8286\n",
      "Epoch 97/160\n",
      "391/391 [==============================] - 0s 345us/step - loss: 0.3501 - acc: 0.8338\n",
      "Epoch 98/160\n",
      "391/391 [==============================] - 0s 322us/step - loss: 0.3562 - acc: 0.8254\n",
      "Epoch 99/160\n",
      "391/391 [==============================] - 0s 362us/step - loss: 0.3504 - acc: 0.8312\n",
      "Epoch 100/160\n",
      "391/391 [==============================] - 0s 331us/step - loss: 0.3565 - acc: 0.8312\n",
      "Epoch 101/160\n",
      "391/391 [==============================] - 0s 336us/step - loss: 0.3451 - acc: 0.8376\n",
      "Epoch 102/160\n",
      "391/391 [==============================] - 0s 359us/step - loss: 0.3627 - acc: 0.8312\n",
      "Epoch 103/160\n",
      "391/391 [==============================] - 0s 337us/step - loss: 0.3504 - acc: 0.8338\n",
      "Epoch 104/160\n",
      "391/391 [==============================] - 0s 364us/step - loss: 0.3466 - acc: 0.8350\n",
      "Epoch 105/160\n",
      "391/391 [==============================] - 0s 333us/step - loss: 0.3465 - acc: 0.8370\n",
      "Epoch 106/160\n",
      "391/391 [==============================] - 0s 363us/step - loss: 0.3457 - acc: 0.8382\n",
      "Epoch 107/160\n",
      "391/391 [==============================] - 0s 341us/step - loss: 0.3477 - acc: 0.8344\n",
      "Epoch 108/160\n",
      "391/391 [==============================] - 0s 383us/step - loss: 0.3470 - acc: 0.8312\n",
      "Epoch 109/160\n",
      "391/391 [==============================] - 0s 342us/step - loss: 0.3512 - acc: 0.8363\n",
      "Epoch 110/160\n",
      "391/391 [==============================] - 0s 383us/step - loss: 0.3562 - acc: 0.8261\n",
      "Epoch 111/160\n",
      "391/391 [==============================] - 0s 339us/step - loss: 0.3615 - acc: 0.8223\n",
      "Epoch 112/160\n",
      "391/391 [==============================] - 0s 373us/step - loss: 0.3588 - acc: 0.8261\n",
      "Epoch 113/160\n",
      "391/391 [==============================] - 0s 369us/step - loss: 0.3455 - acc: 0.8363\n",
      "Epoch 114/160\n",
      "391/391 [==============================] - 0s 352us/step - loss: 0.3470 - acc: 0.8331\n",
      "Epoch 115/160\n",
      "391/391 [==============================] - 0s 344us/step - loss: 0.3478 - acc: 0.8363\n",
      "Epoch 116/160\n",
      "391/391 [==============================] - 0s 345us/step - loss: 0.3415 - acc: 0.8331\n",
      "Epoch 117/160\n",
      "391/391 [==============================] - 0s 366us/step - loss: 0.3367 - acc: 0.8427\n",
      "Epoch 118/160\n",
      "391/391 [==============================] - 0s 351us/step - loss: 0.3424 - acc: 0.8267\n",
      "Epoch 119/160\n",
      "391/391 [==============================] - 0s 328us/step - loss: 0.3589 - acc: 0.8331\n",
      "Epoch 120/160\n",
      "391/391 [==============================] - 0s 323us/step - loss: 0.3634 - acc: 0.8248\n",
      "Epoch 121/160\n",
      "391/391 [==============================] - 0s 359us/step - loss: 0.3503 - acc: 0.8325\n",
      "Epoch 122/160\n",
      "391/391 [==============================] - 0s 375us/step - loss: 0.3529 - acc: 0.8274\n",
      "Epoch 123/160\n",
      "391/391 [==============================] - 0s 333us/step - loss: 0.3485 - acc: 0.8344\n",
      "Epoch 124/160\n",
      "391/391 [==============================] - 0s 372us/step - loss: 0.3433 - acc: 0.8350\n",
      "Epoch 125/160\n",
      "391/391 [==============================] - 0s 361us/step - loss: 0.3407 - acc: 0.8408\n",
      "Epoch 126/160\n",
      "391/391 [==============================] - 0s 368us/step - loss: 0.3382 - acc: 0.8382\n",
      "Epoch 127/160\n",
      "391/391 [==============================] - 0s 343us/step - loss: 0.3523 - acc: 0.8325\n",
      "Epoch 128/160\n",
      "391/391 [==============================] - 0s 426us/step - loss: 0.3487 - acc: 0.8325\n",
      "Epoch 129/160\n",
      "391/391 [==============================] - 0s 380us/step - loss: 0.3443 - acc: 0.8318\n",
      "Epoch 130/160\n",
      "391/391 [==============================] - 0s 376us/step - loss: 0.3383 - acc: 0.8421\n",
      "Epoch 131/160\n",
      "391/391 [==============================] - 0s 326us/step - loss: 0.3504 - acc: 0.8293\n",
      "Epoch 132/160\n",
      "391/391 [==============================] - 0s 318us/step - loss: 0.3394 - acc: 0.8325\n",
      "Epoch 133/160\n",
      "391/391 [==============================] - 0s 340us/step - loss: 0.3393 - acc: 0.8370\n",
      "Epoch 134/160\n",
      "391/391 [==============================] - 0s 327us/step - loss: 0.3378 - acc: 0.8382\n",
      "Epoch 135/160\n",
      "391/391 [==============================] - 0s 375us/step - loss: 0.3410 - acc: 0.8363\n",
      "Epoch 136/160\n",
      "391/391 [==============================] - 0s 316us/step - loss: 0.3521 - acc: 0.8248\n",
      "Epoch 137/160\n",
      "391/391 [==============================] - 0s 358us/step - loss: 0.3311 - acc: 0.8395\n",
      "Epoch 138/160\n",
      "391/391 [==============================] - 0s 365us/step - loss: 0.3402 - acc: 0.8363\n",
      "Epoch 139/160\n",
      "391/391 [==============================] - 0s 322us/step - loss: 0.3372 - acc: 0.8465\n",
      "Epoch 140/160\n",
      "391/391 [==============================] - 0s 345us/step - loss: 0.3432 - acc: 0.8338\n",
      "Epoch 141/160\n",
      "391/391 [==============================] - 0s 308us/step - loss: 0.3410 - acc: 0.8389\n",
      "Epoch 142/160\n",
      "391/391 [==============================] - 0s 328us/step - loss: 0.3511 - acc: 0.8344\n",
      "Epoch 143/160\n",
      "391/391 [==============================] - 0s 325us/step - loss: 0.3445 - acc: 0.8363\n",
      "Epoch 144/160\n",
      "391/391 [==============================] - 0s 384us/step - loss: 0.3530 - acc: 0.8274\n",
      "Epoch 145/160\n",
      "391/391 [==============================] - 0s 317us/step - loss: 0.3490 - acc: 0.8318\n",
      "Epoch 146/160\n",
      "391/391 [==============================] - 0s 321us/step - loss: 0.3428 - acc: 0.8338\n",
      "Epoch 147/160\n",
      "391/391 [==============================] - 0s 329us/step - loss: 0.3365 - acc: 0.8344\n",
      "Epoch 148/160\n",
      "391/391 [==============================] - 0s 319us/step - loss: 0.3380 - acc: 0.8338\n",
      "Epoch 149/160\n",
      "391/391 [==============================] - 0s 352us/step - loss: 0.3312 - acc: 0.8440\n",
      "Epoch 150/160\n",
      "391/391 [==============================] - 0s 339us/step - loss: 0.3386 - acc: 0.8376\n",
      "Epoch 151/160\n",
      "391/391 [==============================] - 0s 326us/step - loss: 0.3364 - acc: 0.8389\n",
      "Epoch 152/160\n",
      "391/391 [==============================] - 0s 340us/step - loss: 0.3311 - acc: 0.8459\n",
      "Epoch 153/160\n",
      "391/391 [==============================] - 0s 334us/step - loss: 0.3321 - acc: 0.8408\n",
      "Epoch 154/160\n",
      "391/391 [==============================] - 0s 313us/step - loss: 0.3246 - acc: 0.8434\n",
      "Epoch 155/160\n",
      "391/391 [==============================] - 0s 324us/step - loss: 0.3334 - acc: 0.8421\n",
      "Epoch 156/160\n",
      "391/391 [==============================] - 0s 337us/step - loss: 0.3339 - acc: 0.8408\n",
      "Epoch 157/160\n",
      "391/391 [==============================] - 0s 381us/step - loss: 0.3277 - acc: 0.8421\n",
      "Epoch 158/160\n",
      "391/391 [==============================] - 0s 309us/step - loss: 0.3335 - acc: 0.8338\n",
      "Epoch 159/160\n",
      "391/391 [==============================] - 0s 355us/step - loss: 0.3335 - acc: 0.8338\n",
      "Epoch 160/160\n",
      "391/391 [==============================] - 0s 307us/step - loss: 0.3285 - acc: 0.8370\n",
      "98/98 [==============================] - 1s 9ms/step\n",
      "391/391 [==============================] - 0s 116us/step\n",
      "\n",
      "acc: 84.69%\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[12 10  0  0]\n",
      " [ 2 62  0  1]\n",
      " [ 0  0  5  1]\n",
      " [ 1  1  0  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.80      0.55      0.65        22\n",
      "      Normal       0.85      0.95      0.90        65\n",
      "        Slow       1.00      0.83      0.91         6\n",
      "   Very Fast       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.84        98\n",
      "   macro avg       0.81      0.73      0.76        98\n",
      "weighted avg       0.83      0.84      0.83        98\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8367346938775511"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='normal_city') & (df_k.Timelevel==4)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy normal_city and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "131/131 [==============================] - 1s 6ms/step - loss: 0.5565 - acc: 0.7500\n",
      "Epoch 2/160\n",
      "131/131 [==============================] - 0s 367us/step - loss: 0.5139 - acc: 0.7500\n",
      "Epoch 3/160\n",
      "131/131 [==============================] - 0s 366us/step - loss: 0.5006 - acc: 0.7214\n",
      "Epoch 4/160\n",
      "131/131 [==============================] - 0s 356us/step - loss: 0.4813 - acc: 0.7538\n",
      "Epoch 5/160\n",
      "131/131 [==============================] - 0s 359us/step - loss: 0.4514 - acc: 0.7691\n",
      "Epoch 6/160\n",
      "131/131 [==============================] - 0s 430us/step - loss: 0.4342 - acc: 0.8149\n",
      "Epoch 7/160\n",
      "131/131 [==============================] - 0s 420us/step - loss: 0.4161 - acc: 0.8187\n",
      "Epoch 8/160\n",
      "131/131 [==============================] - 0s 356us/step - loss: 0.4046 - acc: 0.8168\n",
      "Epoch 9/160\n",
      "131/131 [==============================] - 0s 365us/step - loss: 0.4082 - acc: 0.8111\n",
      "Epoch 10/160\n",
      "131/131 [==============================] - 0s 375us/step - loss: 0.3991 - acc: 0.8187\n",
      "Epoch 11/160\n",
      "131/131 [==============================] - 0s 384us/step - loss: 0.4043 - acc: 0.8149\n",
      "Epoch 12/160\n",
      "131/131 [==============================] - 0s 334us/step - loss: 0.4046 - acc: 0.8130\n",
      "Epoch 13/160\n",
      "131/131 [==============================] - 0s 346us/step - loss: 0.3858 - acc: 0.8168\n",
      "Epoch 14/160\n",
      "131/131 [==============================] - 0s 353us/step - loss: 0.3952 - acc: 0.8168\n",
      "Epoch 15/160\n",
      "131/131 [==============================] - 0s 394us/step - loss: 0.3979 - acc: 0.8206\n",
      "Epoch 16/160\n",
      "131/131 [==============================] - 0s 409us/step - loss: 0.3904 - acc: 0.8168\n",
      "Epoch 17/160\n",
      "131/131 [==============================] - 0s 363us/step - loss: 0.3939 - acc: 0.8149\n",
      "Epoch 18/160\n",
      "131/131 [==============================] - 0s 308us/step - loss: 0.3954 - acc: 0.8130\n",
      "Epoch 19/160\n",
      "131/131 [==============================] - 0s 369us/step - loss: 0.3850 - acc: 0.8168\n",
      "Epoch 20/160\n",
      "131/131 [==============================] - 0s 352us/step - loss: 0.3846 - acc: 0.8149\n",
      "Epoch 21/160\n",
      "131/131 [==============================] - 0s 384us/step - loss: 0.3828 - acc: 0.8130\n",
      "Epoch 22/160\n",
      "131/131 [==============================] - 0s 359us/step - loss: 0.3780 - acc: 0.8263\n",
      "Epoch 23/160\n",
      "131/131 [==============================] - 0s 446us/step - loss: 0.3875 - acc: 0.8092\n",
      "Epoch 24/160\n",
      "131/131 [==============================] - 0s 417us/step - loss: 0.3766 - acc: 0.8111\n",
      "Epoch 25/160\n",
      "131/131 [==============================] - 0s 448us/step - loss: 0.3739 - acc: 0.8206\n",
      "Epoch 26/160\n",
      "131/131 [==============================] - 0s 383us/step - loss: 0.3737 - acc: 0.8187\n",
      "Epoch 27/160\n",
      "131/131 [==============================] - 0s 388us/step - loss: 0.3751 - acc: 0.8225\n",
      "Epoch 28/160\n",
      "131/131 [==============================] - 0s 428us/step - loss: 0.3703 - acc: 0.8149\n",
      "Epoch 29/160\n",
      "131/131 [==============================] - 0s 414us/step - loss: 0.3737 - acc: 0.8130\n",
      "Epoch 30/160\n",
      "131/131 [==============================] - 0s 431us/step - loss: 0.3704 - acc: 0.8149\n",
      "Epoch 31/160\n",
      "131/131 [==============================] - 0s 404us/step - loss: 0.3679 - acc: 0.8302\n",
      "Epoch 32/160\n",
      "131/131 [==============================] - 0s 394us/step - loss: 0.3693 - acc: 0.8149\n",
      "Epoch 33/160\n",
      "131/131 [==============================] - 0s 332us/step - loss: 0.3582 - acc: 0.8302\n",
      "Epoch 34/160\n",
      "131/131 [==============================] - 0s 377us/step - loss: 0.3689 - acc: 0.8263\n",
      "Epoch 35/160\n",
      "131/131 [==============================] - 0s 358us/step - loss: 0.3636 - acc: 0.8263\n",
      "Epoch 36/160\n",
      "131/131 [==============================] - 0s 380us/step - loss: 0.3709 - acc: 0.8187\n",
      "Epoch 37/160\n",
      "131/131 [==============================] - 0s 297us/step - loss: 0.3731 - acc: 0.8187\n",
      "Epoch 38/160\n",
      "131/131 [==============================] - 0s 359us/step - loss: 0.3662 - acc: 0.8206\n",
      "Epoch 39/160\n",
      "131/131 [==============================] - 0s 358us/step - loss: 0.3823 - acc: 0.8206\n",
      "Epoch 40/160\n",
      "131/131 [==============================] - 0s 407us/step - loss: 0.3786 - acc: 0.8263\n",
      "Epoch 41/160\n",
      "131/131 [==============================] - 0s 279us/step - loss: 0.3668 - acc: 0.8225\n",
      "Epoch 42/160\n",
      "131/131 [==============================] - 0s 377us/step - loss: 0.3732 - acc: 0.8130\n",
      "Epoch 43/160\n",
      "131/131 [==============================] - 0s 366us/step - loss: 0.3785 - acc: 0.8225\n",
      "Epoch 44/160\n",
      "131/131 [==============================] - 0s 373us/step - loss: 0.3627 - acc: 0.8282\n",
      "Epoch 45/160\n",
      "131/131 [==============================] - 0s 441us/step - loss: 0.3629 - acc: 0.8263\n",
      "Epoch 46/160\n",
      "131/131 [==============================] - 0s 367us/step - loss: 0.3611 - acc: 0.8187\n",
      "Epoch 47/160\n",
      "131/131 [==============================] - 0s 315us/step - loss: 0.3616 - acc: 0.8340\n",
      "Epoch 48/160\n",
      "131/131 [==============================] - 0s 353us/step - loss: 0.3583 - acc: 0.8435\n",
      "Epoch 49/160\n",
      "131/131 [==============================] - 0s 354us/step - loss: 0.3632 - acc: 0.8187\n",
      "Epoch 50/160\n",
      "131/131 [==============================] - 0s 384us/step - loss: 0.3650 - acc: 0.8206\n",
      "Epoch 51/160\n",
      "131/131 [==============================] - 0s 351us/step - loss: 0.3529 - acc: 0.8282\n",
      "Epoch 52/160\n",
      "131/131 [==============================] - 0s 358us/step - loss: 0.3590 - acc: 0.8340\n",
      "Epoch 53/160\n",
      "131/131 [==============================] - 0s 349us/step - loss: 0.3584 - acc: 0.8302\n",
      "Epoch 54/160\n",
      "131/131 [==============================] - 0s 350us/step - loss: 0.3624 - acc: 0.8244\n",
      "Epoch 55/160\n",
      "131/131 [==============================] - 0s 382us/step - loss: 0.3618 - acc: 0.8149\n",
      "Epoch 56/160\n",
      "131/131 [==============================] - 0s 268us/step - loss: 0.3586 - acc: 0.8244\n",
      "Epoch 57/160\n",
      "131/131 [==============================] - 0s 407us/step - loss: 0.3586 - acc: 0.8340\n",
      "Epoch 58/160\n",
      "131/131 [==============================] - 0s 376us/step - loss: 0.3780 - acc: 0.8111\n",
      "Epoch 59/160\n",
      "131/131 [==============================] - 0s 332us/step - loss: 0.3716 - acc: 0.8130\n",
      "Epoch 60/160\n",
      "131/131 [==============================] - 0s 383us/step - loss: 0.3623 - acc: 0.8302\n",
      "Epoch 61/160\n",
      "131/131 [==============================] - 0s 384us/step - loss: 0.3630 - acc: 0.8149\n",
      "Epoch 62/160\n",
      "131/131 [==============================] - 0s 390us/step - loss: 0.3598 - acc: 0.8321\n",
      "Epoch 63/160\n",
      "131/131 [==============================] - 0s 487us/step - loss: 0.3611 - acc: 0.8340\n",
      "Epoch 64/160\n",
      "131/131 [==============================] - 0s 398us/step - loss: 0.3550 - acc: 0.8340\n",
      "Epoch 65/160\n",
      "131/131 [==============================] - 0s 485us/step - loss: 0.3627 - acc: 0.8225\n",
      "Epoch 66/160\n",
      "131/131 [==============================] - 0s 398us/step - loss: 0.3540 - acc: 0.8225\n",
      "Epoch 67/160\n",
      "131/131 [==============================] - 0s 366us/step - loss: 0.3576 - acc: 0.8263\n",
      "Epoch 68/160\n",
      "131/131 [==============================] - 0s 426us/step - loss: 0.3623 - acc: 0.8263\n",
      "Epoch 69/160\n",
      "131/131 [==============================] - 0s 484us/step - loss: 0.3486 - acc: 0.8359\n",
      "Epoch 70/160\n",
      "131/131 [==============================] - 0s 610us/step - loss: 0.3409 - acc: 0.8302\n",
      "Epoch 71/160\n",
      "131/131 [==============================] - 0s 427us/step - loss: 0.3535 - acc: 0.8473\n",
      "Epoch 72/160\n",
      "131/131 [==============================] - 0s 442us/step - loss: 0.3621 - acc: 0.8321\n",
      "Epoch 73/160\n",
      "131/131 [==============================] - 0s 425us/step - loss: 0.3518 - acc: 0.8244\n",
      "Epoch 74/160\n",
      "131/131 [==============================] - 0s 440us/step - loss: 0.3600 - acc: 0.8263\n",
      "Epoch 75/160\n",
      "131/131 [==============================] - 0s 394us/step - loss: 0.3520 - acc: 0.8321\n",
      "Epoch 76/160\n",
      "131/131 [==============================] - 0s 375us/step - loss: 0.3612 - acc: 0.8225\n",
      "Epoch 77/160\n",
      "131/131 [==============================] - 0s 386us/step - loss: 0.3560 - acc: 0.8321\n",
      "Epoch 78/160\n",
      "131/131 [==============================] - 0s 385us/step - loss: 0.3516 - acc: 0.8263\n",
      "Epoch 79/160\n",
      "131/131 [==============================] - 0s 392us/step - loss: 0.3599 - acc: 0.8302\n",
      "Epoch 80/160\n",
      "131/131 [==============================] - 0s 326us/step - loss: 0.3512 - acc: 0.8282\n",
      "Epoch 81/160\n",
      "131/131 [==============================] - 0s 334us/step - loss: 0.3517 - acc: 0.8263\n",
      "Epoch 82/160\n",
      "131/131 [==============================] - 0s 381us/step - loss: 0.3560 - acc: 0.8321\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 0s 407us/step - loss: 0.3579 - acc: 0.8092\n",
      "Epoch 84/160\n",
      "131/131 [==============================] - 0s 351us/step - loss: 0.3558 - acc: 0.8225\n",
      "Epoch 85/160\n",
      "131/131 [==============================] - 0s 361us/step - loss: 0.3493 - acc: 0.8321\n",
      "Epoch 86/160\n",
      "131/131 [==============================] - 0s 370us/step - loss: 0.3551 - acc: 0.8187\n",
      "Epoch 87/160\n",
      "131/131 [==============================] - 0s 360us/step - loss: 0.3530 - acc: 0.8244\n",
      "Epoch 88/160\n",
      "131/131 [==============================] - 0s 411us/step - loss: 0.3545 - acc: 0.8321\n",
      "Epoch 89/160\n",
      "131/131 [==============================] - 0s 355us/step - loss: 0.3475 - acc: 0.8340\n",
      "Epoch 90/160\n",
      "131/131 [==============================] - 0s 389us/step - loss: 0.3466 - acc: 0.8263\n",
      "Epoch 91/160\n",
      "131/131 [==============================] - 0s 357us/step - loss: 0.3461 - acc: 0.8302\n",
      "Epoch 92/160\n",
      "131/131 [==============================] - 0s 423us/step - loss: 0.3484 - acc: 0.8282\n",
      "Epoch 93/160\n",
      "131/131 [==============================] - 0s 373us/step - loss: 0.3555 - acc: 0.8206\n",
      "Epoch 94/160\n",
      "131/131 [==============================] - 0s 348us/step - loss: 0.3540 - acc: 0.8225\n",
      "Epoch 95/160\n",
      "131/131 [==============================] - 0s 335us/step - loss: 0.3510 - acc: 0.8340\n",
      "Epoch 96/160\n",
      "131/131 [==============================] - 0s 321us/step - loss: 0.3538 - acc: 0.8302\n",
      "Epoch 97/160\n",
      "131/131 [==============================] - 0s 354us/step - loss: 0.3511 - acc: 0.8282\n",
      "Epoch 98/160\n",
      "131/131 [==============================] - 0s 403us/step - loss: 0.3579 - acc: 0.8206\n",
      "Epoch 99/160\n",
      "131/131 [==============================] - 0s 376us/step - loss: 0.3489 - acc: 0.8359\n",
      "Epoch 100/160\n",
      "131/131 [==============================] - 0s 405us/step - loss: 0.3561 - acc: 0.8263\n",
      "Epoch 101/160\n",
      "131/131 [==============================] - 0s 343us/step - loss: 0.3553 - acc: 0.8244\n",
      "Epoch 102/160\n",
      "131/131 [==============================] - 0s 392us/step - loss: 0.3520 - acc: 0.8378\n",
      "Epoch 103/160\n",
      "131/131 [==============================] - 0s 365us/step - loss: 0.3599 - acc: 0.8187\n",
      "Epoch 104/160\n",
      "131/131 [==============================] - 0s 344us/step - loss: 0.3517 - acc: 0.8225\n",
      "Epoch 105/160\n",
      "131/131 [==============================] - 0s 375us/step - loss: 0.3454 - acc: 0.8244\n",
      "Epoch 106/160\n",
      "131/131 [==============================] - 0s 398us/step - loss: 0.3476 - acc: 0.8378\n",
      "Epoch 107/160\n",
      "131/131 [==============================] - 0s 348us/step - loss: 0.3444 - acc: 0.8397\n",
      "Epoch 108/160\n",
      "131/131 [==============================] - 0s 421us/step - loss: 0.3478 - acc: 0.8263\n",
      "Epoch 109/160\n",
      "131/131 [==============================] - 0s 335us/step - loss: 0.3485 - acc: 0.8359\n",
      "Epoch 110/160\n",
      "131/131 [==============================] - 0s 372us/step - loss: 0.3410 - acc: 0.8340\n",
      "Epoch 111/160\n",
      "131/131 [==============================] - 0s 321us/step - loss: 0.3440 - acc: 0.8225\n",
      "Epoch 112/160\n",
      "131/131 [==============================] - 0s 399us/step - loss: 0.3410 - acc: 0.8282\n",
      "Epoch 113/160\n",
      "131/131 [==============================] - 0s 378us/step - loss: 0.3480 - acc: 0.8416\n",
      "Epoch 114/160\n",
      "131/131 [==============================] - 0s 367us/step - loss: 0.3358 - acc: 0.8397\n",
      "Epoch 115/160\n",
      "131/131 [==============================] - 0s 348us/step - loss: 0.3438 - acc: 0.8454\n",
      "Epoch 116/160\n",
      "131/131 [==============================] - 0s 353us/step - loss: 0.3352 - acc: 0.8473\n",
      "Epoch 117/160\n",
      "131/131 [==============================] - 0s 422us/step - loss: 0.3420 - acc: 0.8244\n",
      "Epoch 118/160\n",
      "131/131 [==============================] - 0s 461us/step - loss: 0.3480 - acc: 0.8359\n",
      "Epoch 119/160\n",
      "131/131 [==============================] - 0s 414us/step - loss: 0.3445 - acc: 0.8340\n",
      "Epoch 120/160\n",
      "131/131 [==============================] - 0s 386us/step - loss: 0.3466 - acc: 0.8340\n",
      "Epoch 121/160\n",
      "131/131 [==============================] - 0s 329us/step - loss: 0.3444 - acc: 0.8302\n",
      "Epoch 122/160\n",
      "131/131 [==============================] - 0s 422us/step - loss: 0.3407 - acc: 0.8340\n",
      "Epoch 123/160\n",
      "131/131 [==============================] - 0s 361us/step - loss: 0.3462 - acc: 0.8340\n",
      "Epoch 124/160\n",
      "131/131 [==============================] - 0s 393us/step - loss: 0.3386 - acc: 0.8359\n",
      "Epoch 125/160\n",
      "131/131 [==============================] - 0s 350us/step - loss: 0.3493 - acc: 0.8282\n",
      "Epoch 126/160\n",
      "131/131 [==============================] - 0s 367us/step - loss: 0.3458 - acc: 0.8321\n",
      "Epoch 127/160\n",
      "131/131 [==============================] - 0s 372us/step - loss: 0.3463 - acc: 0.8187\n",
      "Epoch 128/160\n",
      "131/131 [==============================] - 0s 319us/step - loss: 0.3422 - acc: 0.8244\n",
      "Epoch 129/160\n",
      "131/131 [==============================] - 0s 322us/step - loss: 0.3316 - acc: 0.8435\n",
      "Epoch 130/160\n",
      "131/131 [==============================] - 0s 341us/step - loss: 0.3427 - acc: 0.8263\n",
      "Epoch 131/160\n",
      "131/131 [==============================] - 0s 348us/step - loss: 0.3326 - acc: 0.8454\n",
      "Epoch 132/160\n",
      "131/131 [==============================] - 0s 1ms/step - loss: 0.3284 - acc: 0.8359\n",
      "Epoch 133/160\n",
      "131/131 [==============================] - 0s 350us/step - loss: 0.3332 - acc: 0.8435\n",
      "Epoch 134/160\n",
      "131/131 [==============================] - 0s 318us/step - loss: 0.3369 - acc: 0.8397\n",
      "Epoch 135/160\n",
      "131/131 [==============================] - 0s 428us/step - loss: 0.3371 - acc: 0.8263\n",
      "Epoch 136/160\n",
      "131/131 [==============================] - 0s 376us/step - loss: 0.3470 - acc: 0.8340\n",
      "Epoch 137/160\n",
      "131/131 [==============================] - 0s 391us/step - loss: 0.3345 - acc: 0.8340\n",
      "Epoch 138/160\n",
      "131/131 [==============================] - 0s 353us/step - loss: 0.3447 - acc: 0.8282\n",
      "Epoch 139/160\n",
      "131/131 [==============================] - 0s 317us/step - loss: 0.3428 - acc: 0.8378\n",
      "Epoch 140/160\n",
      "131/131 [==============================] - 0s 376us/step - loss: 0.3479 - acc: 0.8282\n",
      "Epoch 141/160\n",
      "131/131 [==============================] - 0s 359us/step - loss: 0.3415 - acc: 0.8302\n",
      "Epoch 142/160\n",
      "131/131 [==============================] - 0s 338us/step - loss: 0.3793 - acc: 0.8225\n",
      "Epoch 143/160\n",
      "131/131 [==============================] - 0s 331us/step - loss: 0.3606 - acc: 0.8321\n",
      "Epoch 144/160\n",
      "131/131 [==============================] - 0s 366us/step - loss: 0.3547 - acc: 0.8225\n",
      "Epoch 145/160\n",
      "131/131 [==============================] - 0s 371us/step - loss: 0.3525 - acc: 0.8244\n",
      "Epoch 146/160\n",
      "131/131 [==============================] - 0s 401us/step - loss: 0.3428 - acc: 0.8321\n",
      "Epoch 147/160\n",
      "131/131 [==============================] - 0s 359us/step - loss: 0.3569 - acc: 0.8302\n",
      "Epoch 148/160\n",
      "131/131 [==============================] - 0s 358us/step - loss: 0.3524 - acc: 0.8168\n",
      "Epoch 149/160\n",
      "131/131 [==============================] - 0s 297us/step - loss: 0.3491 - acc: 0.8206\n",
      "Epoch 150/160\n",
      "131/131 [==============================] - 0s 404us/step - loss: 0.3404 - acc: 0.8321\n",
      "Epoch 151/160\n",
      "131/131 [==============================] - 0s 419us/step - loss: 0.3407 - acc: 0.8397\n",
      "Epoch 152/160\n",
      "131/131 [==============================] - 0s 392us/step - loss: 0.3321 - acc: 0.8282\n",
      "Epoch 153/160\n",
      "131/131 [==============================] - 0s 350us/step - loss: 0.3351 - acc: 0.8416\n",
      "Epoch 154/160\n",
      "131/131 [==============================] - 0s 403us/step - loss: 0.3405 - acc: 0.8263\n",
      "Epoch 155/160\n",
      "131/131 [==============================] - 0s 473us/step - loss: 0.3368 - acc: 0.8321\n",
      "Epoch 156/160\n",
      "131/131 [==============================] - 0s 416us/step - loss: 0.3330 - acc: 0.8454\n",
      "Epoch 157/160\n",
      "131/131 [==============================] - 0s 446us/step - loss: 0.3307 - acc: 0.8435\n",
      "Epoch 158/160\n",
      "131/131 [==============================] - 0s 479us/step - loss: 0.3392 - acc: 0.8340\n",
      "Epoch 159/160\n",
      "131/131 [==============================] - 0s 443us/step - loss: 0.3404 - acc: 0.8321\n",
      "Epoch 160/160\n",
      "131/131 [==============================] - 0s 404us/step - loss: 0.3368 - acc: 0.8378\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "\n",
      "acc: 83.97%\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "[[ 5  0  0  5]\n",
      " [ 0  1  0  1]\n",
      " [ 0  0  2 19]\n",
      " [ 0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       1.00      0.50      0.67        10\n",
      "      Normal       1.00      0.50      0.67         2\n",
      "        Slow       1.00      0.10      0.17        21\n",
      "   Very Fast       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.24        33\n",
      "   macro avg       0.75      0.27      0.38        33\n",
      "weighted avg       1.00      0.24      0.35        33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='highway') & (df_k.Timelevel==1)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "       # if y_test_2.iloc[j][3]==1:\n",
    "        #    y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: highway timelevel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "332/332 [==============================] - 1s 3ms/step - loss: 0.5090 - acc: 0.7560\n",
      "Epoch 2/160\n",
      "332/332 [==============================] - 0s 337us/step - loss: 0.4502 - acc: 0.7756\n",
      "Epoch 3/160\n",
      "332/332 [==============================] - 0s 319us/step - loss: 0.4164 - acc: 0.8080\n",
      "Epoch 4/160\n",
      "332/332 [==============================] - 0s 344us/step - loss: 0.3945 - acc: 0.8208\n",
      "Epoch 5/160\n",
      "332/332 [==============================] - 0s 290us/step - loss: 0.3838 - acc: 0.8268\n",
      "Epoch 6/160\n",
      "332/332 [==============================] - 0s 356us/step - loss: 0.3921 - acc: 0.8283\n",
      "Epoch 7/160\n",
      "332/332 [==============================] - 0s 301us/step - loss: 0.3663 - acc: 0.8268\n",
      "Epoch 8/160\n",
      "332/332 [==============================] - 0s 331us/step - loss: 0.3692 - acc: 0.8336\n",
      "Epoch 9/160\n",
      "332/332 [==============================] - 0s 307us/step - loss: 0.3688 - acc: 0.8366\n",
      "Epoch 10/160\n",
      "332/332 [==============================] - 0s 317us/step - loss: 0.3603 - acc: 0.8381\n",
      "Epoch 11/160\n",
      "332/332 [==============================] - 0s 352us/step - loss: 0.3774 - acc: 0.8298\n",
      "Epoch 12/160\n",
      "332/332 [==============================] - 0s 317us/step - loss: 0.3677 - acc: 0.8381\n",
      "Epoch 13/160\n",
      "332/332 [==============================] - 0s 348us/step - loss: 0.3717 - acc: 0.8313\n",
      "Epoch 14/160\n",
      "332/332 [==============================] - 0s 315us/step - loss: 0.3569 - acc: 0.8441\n",
      "Epoch 15/160\n",
      "332/332 [==============================] - 0s 317us/step - loss: 0.3546 - acc: 0.8396\n",
      "Epoch 16/160\n",
      "332/332 [==============================] - 0s 316us/step - loss: 0.3625 - acc: 0.8313\n",
      "Epoch 17/160\n",
      "332/332 [==============================] - 0s 306us/step - loss: 0.3728 - acc: 0.8321\n",
      "Epoch 18/160\n",
      "332/332 [==============================] - 0s 356us/step - loss: 0.3615 - acc: 0.8404\n",
      "Epoch 19/160\n",
      "332/332 [==============================] - 0s 315us/step - loss: 0.3577 - acc: 0.8464\n",
      "Epoch 20/160\n",
      "332/332 [==============================] - 0s 326us/step - loss: 0.3580 - acc: 0.8389\n",
      "Epoch 21/160\n",
      "332/332 [==============================] - 0s 315us/step - loss: 0.3704 - acc: 0.8358\n",
      "Epoch 22/160\n",
      "332/332 [==============================] - 0s 353us/step - loss: 0.3699 - acc: 0.8351\n",
      "Epoch 23/160\n",
      "332/332 [==============================] - 0s 307us/step - loss: 0.3516 - acc: 0.8441\n",
      "Epoch 24/160\n",
      "332/332 [==============================] - 0s 308us/step - loss: 0.3499 - acc: 0.8464\n",
      "Epoch 25/160\n",
      "332/332 [==============================] - 0s 314us/step - loss: 0.3491 - acc: 0.8434\n",
      "Epoch 26/160\n",
      "332/332 [==============================] - 0s 329us/step - loss: 0.3477 - acc: 0.8509\n",
      "Epoch 27/160\n",
      "332/332 [==============================] - 0s 357us/step - loss: 0.3505 - acc: 0.8486\n",
      "Epoch 28/160\n",
      "332/332 [==============================] - 0s 281us/step - loss: 0.3591 - acc: 0.8486\n",
      "Epoch 29/160\n",
      "332/332 [==============================] - 0s 344us/step - loss: 0.3578 - acc: 0.8434\n",
      "Epoch 30/160\n",
      "332/332 [==============================] - 0s 325us/step - loss: 0.3438 - acc: 0.8517\n",
      "Epoch 31/160\n",
      "332/332 [==============================] - 0s 361us/step - loss: 0.3472 - acc: 0.8471\n",
      "Epoch 32/160\n",
      "332/332 [==============================] - 0s 296us/step - loss: 0.3488 - acc: 0.8471\n",
      "Epoch 33/160\n",
      "332/332 [==============================] - 0s 338us/step - loss: 0.3392 - acc: 0.8509\n",
      "Epoch 34/160\n",
      "332/332 [==============================] - 0s 331us/step - loss: 0.3483 - acc: 0.8486\n",
      "Epoch 35/160\n",
      "332/332 [==============================] - 0s 297us/step - loss: 0.3447 - acc: 0.8502\n",
      "Epoch 36/160\n",
      "332/332 [==============================] - 0s 391us/step - loss: 0.3561 - acc: 0.8449\n",
      "Epoch 37/160\n",
      "332/332 [==============================] - 0s 338us/step - loss: 0.3495 - acc: 0.8517\n",
      "Epoch 38/160\n",
      "332/332 [==============================] - 0s 321us/step - loss: 0.3426 - acc: 0.8517\n",
      "Epoch 39/160\n",
      "332/332 [==============================] - 0s 296us/step - loss: 0.3534 - acc: 0.8381\n",
      "Epoch 40/160\n",
      "332/332 [==============================] - 0s 337us/step - loss: 0.3553 - acc: 0.8373\n",
      "Epoch 41/160\n",
      "332/332 [==============================] - 0s 317us/step - loss: 0.3470 - acc: 0.8449\n",
      "Epoch 42/160\n",
      "332/332 [==============================] - 0s 300us/step - loss: 0.3474 - acc: 0.8471\n",
      "Epoch 43/160\n",
      "332/332 [==============================] - 0s 344us/step - loss: 0.3545 - acc: 0.8471\n",
      "Epoch 44/160\n",
      "332/332 [==============================] - 0s 303us/step - loss: 0.3460 - acc: 0.8502\n",
      "Epoch 45/160\n",
      "332/332 [==============================] - 0s 336us/step - loss: 0.3485 - acc: 0.8464\n",
      "Epoch 46/160\n",
      "332/332 [==============================] - 0s 315us/step - loss: 0.3456 - acc: 0.8486\n",
      "Epoch 47/160\n",
      "332/332 [==============================] - 0s 307us/step - loss: 0.3397 - acc: 0.8494\n",
      "Epoch 48/160\n",
      "332/332 [==============================] - 0s 318us/step - loss: 0.3399 - acc: 0.8449\n",
      "Epoch 49/160\n",
      "332/332 [==============================] - 0s 319us/step - loss: 0.3363 - acc: 0.8479\n",
      "Epoch 50/160\n",
      "332/332 [==============================] - 0s 344us/step - loss: 0.3378 - acc: 0.8569\n",
      "Epoch 51/160\n",
      "332/332 [==============================] - 0s 297us/step - loss: 0.3311 - acc: 0.8547\n",
      "Epoch 52/160\n",
      "332/332 [==============================] - 0s 324us/step - loss: 0.3337 - acc: 0.8547\n",
      "Epoch 53/160\n",
      "332/332 [==============================] - 0s 298us/step - loss: 0.3330 - acc: 0.8547\n",
      "Epoch 54/160\n",
      "332/332 [==============================] - 0s 335us/step - loss: 0.3367 - acc: 0.8584\n",
      "Epoch 55/160\n",
      "332/332 [==============================] - 0s 317us/step - loss: 0.3361 - acc: 0.8509\n",
      "Epoch 56/160\n",
      "332/332 [==============================] - 0s 286us/step - loss: 0.3318 - acc: 0.8577\n",
      "Epoch 57/160\n",
      "332/332 [==============================] - 0s 323us/step - loss: 0.3335 - acc: 0.8554\n",
      "Epoch 58/160\n",
      "332/332 [==============================] - 0s 308us/step - loss: 0.3414 - acc: 0.8517\n",
      "Epoch 59/160\n",
      "332/332 [==============================] - 0s 339us/step - loss: 0.3337 - acc: 0.8539\n",
      "Epoch 60/160\n",
      "332/332 [==============================] - 0s 305us/step - loss: 0.3450 - acc: 0.8479\n",
      "Epoch 61/160\n",
      "332/332 [==============================] - 0s 325us/step - loss: 0.3436 - acc: 0.8434\n",
      "Epoch 62/160\n",
      "332/332 [==============================] - 0s 315us/step - loss: 0.3410 - acc: 0.8434\n",
      "Epoch 63/160\n",
      "332/332 [==============================] - 0s 334us/step - loss: 0.3328 - acc: 0.8547\n",
      "Epoch 64/160\n",
      "332/332 [==============================] - 0s 327us/step - loss: 0.3444 - acc: 0.8456\n",
      "Epoch 65/160\n",
      "332/332 [==============================] - 0s 333us/step - loss: 0.3352 - acc: 0.8524\n",
      "Epoch 66/160\n",
      "332/332 [==============================] - 0s 328us/step - loss: 0.3464 - acc: 0.8509\n",
      "Epoch 67/160\n",
      "332/332 [==============================] - 0s 331us/step - loss: 0.3390 - acc: 0.8554\n",
      "Epoch 68/160\n",
      "332/332 [==============================] - 0s 364us/step - loss: 0.3380 - acc: 0.8494\n",
      "Epoch 69/160\n",
      "332/332 [==============================] - 0s 317us/step - loss: 0.3382 - acc: 0.8517\n",
      "Epoch 70/160\n",
      "332/332 [==============================] - 0s 333us/step - loss: 0.3352 - acc: 0.8524\n",
      "Epoch 71/160\n",
      "332/332 [==============================] - 0s 331us/step - loss: 0.3326 - acc: 0.8509\n",
      "Epoch 72/160\n",
      "332/332 [==============================] - 0s 358us/step - loss: 0.3294 - acc: 0.8569\n",
      "Epoch 73/160\n",
      "332/332 [==============================] - 0s 343us/step - loss: 0.3298 - acc: 0.8524\n",
      "Epoch 74/160\n",
      "332/332 [==============================] - 0s 326us/step - loss: 0.3250 - acc: 0.8614\n",
      "Epoch 75/160\n",
      "332/332 [==============================] - 0s 356us/step - loss: 0.3232 - acc: 0.8592\n",
      "Epoch 76/160\n",
      "332/332 [==============================] - 0s 356us/step - loss: 0.3260 - acc: 0.8607\n",
      "Epoch 77/160\n",
      "332/332 [==============================] - 0s 357us/step - loss: 0.3238 - acc: 0.8599\n",
      "Epoch 78/160\n",
      "332/332 [==============================] - 0s 310us/step - loss: 0.3297 - acc: 0.8539\n",
      "Epoch 79/160\n",
      "332/332 [==============================] - 0s 361us/step - loss: 0.3306 - acc: 0.8599\n",
      "Epoch 80/160\n",
      "332/332 [==============================] - 0s 352us/step - loss: 0.3275 - acc: 0.8547\n",
      "Epoch 81/160\n",
      "332/332 [==============================] - 0s 356us/step - loss: 0.3178 - acc: 0.8637\n",
      "Epoch 82/160\n",
      "332/332 [==============================] - 0s 312us/step - loss: 0.3292 - acc: 0.8569\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/332 [==============================] - 0s 319us/step - loss: 0.3267 - acc: 0.8592\n",
      "Epoch 84/160\n",
      "332/332 [==============================] - 0s 335us/step - loss: 0.3279 - acc: 0.8524\n",
      "Epoch 85/160\n",
      "332/332 [==============================] - 0s 325us/step - loss: 0.3184 - acc: 0.8569\n",
      "Epoch 86/160\n",
      "332/332 [==============================] - 0s 336us/step - loss: 0.3275 - acc: 0.8547\n",
      "Epoch 87/160\n",
      "332/332 [==============================] - 0s 459us/step - loss: 0.3256 - acc: 0.8547\n",
      "Epoch 88/160\n",
      "332/332 [==============================] - 0s 441us/step - loss: 0.3313 - acc: 0.8486\n",
      "Epoch 89/160\n",
      "332/332 [==============================] - 0s 425us/step - loss: 0.3311 - acc: 0.8532\n",
      "Epoch 90/160\n",
      "332/332 [==============================] - 0s 434us/step - loss: 0.3329 - acc: 0.8569\n",
      "Epoch 91/160\n",
      "332/332 [==============================] - 0s 340us/step - loss: 0.3348 - acc: 0.8584\n",
      "Epoch 92/160\n",
      "332/332 [==============================] - 0s 337us/step - loss: 0.3400 - acc: 0.8494\n",
      "Epoch 93/160\n",
      "332/332 [==============================] - 0s 387us/step - loss: 0.3268 - acc: 0.8577\n",
      "Epoch 94/160\n",
      "332/332 [==============================] - 0s 475us/step - loss: 0.3332 - acc: 0.8539\n",
      "Epoch 95/160\n",
      "332/332 [==============================] - 0s 347us/step - loss: 0.3257 - acc: 0.8577\n",
      "Epoch 96/160\n",
      "332/332 [==============================] - 0s 362us/step - loss: 0.3244 - acc: 0.8645\n",
      "Epoch 97/160\n",
      "332/332 [==============================] - 0s 354us/step - loss: 0.3225 - acc: 0.8532\n",
      "Epoch 98/160\n",
      "332/332 [==============================] - 0s 342us/step - loss: 0.3341 - acc: 0.8471\n",
      "Epoch 99/160\n",
      "332/332 [==============================] - 0s 368us/step - loss: 0.3242 - acc: 0.8569\n",
      "Epoch 100/160\n",
      "332/332 [==============================] - 0s 349us/step - loss: 0.3200 - acc: 0.8577\n",
      "Epoch 101/160\n",
      "332/332 [==============================] - 0s 374us/step - loss: 0.3193 - acc: 0.8614\n",
      "Epoch 102/160\n",
      "332/332 [==============================] - 0s 332us/step - loss: 0.3248 - acc: 0.8599\n",
      "Epoch 103/160\n",
      "332/332 [==============================] - 0s 384us/step - loss: 0.3235 - acc: 0.8554\n",
      "Epoch 104/160\n",
      "332/332 [==============================] - 0s 308us/step - loss: 0.3134 - acc: 0.8622\n",
      "Epoch 105/160\n",
      "332/332 [==============================] - 0s 359us/step - loss: 0.3213 - acc: 0.8607\n",
      "Epoch 106/160\n",
      "332/332 [==============================] - 0s 347us/step - loss: 0.3355 - acc: 0.8479\n",
      "Epoch 107/160\n",
      "332/332 [==============================] - 0s 363us/step - loss: 0.3193 - acc: 0.8554\n",
      "Epoch 108/160\n",
      "332/332 [==============================] - 0s 332us/step - loss: 0.3316 - acc: 0.8577\n",
      "Epoch 109/160\n",
      "332/332 [==============================] - 0s 351us/step - loss: 0.3350 - acc: 0.8539\n",
      "Epoch 110/160\n",
      "332/332 [==============================] - 0s 371us/step - loss: 0.3215 - acc: 0.8592\n",
      "Epoch 111/160\n",
      "332/332 [==============================] - 0s 362us/step - loss: 0.3255 - acc: 0.8652\n",
      "Epoch 112/160\n",
      "332/332 [==============================] - 0s 338us/step - loss: 0.3255 - acc: 0.8524\n",
      "Epoch 113/160\n",
      "332/332 [==============================] - 0s 327us/step - loss: 0.3258 - acc: 0.8599\n",
      "Epoch 114/160\n",
      "332/332 [==============================] - 0s 339us/step - loss: 0.3183 - acc: 0.8539\n",
      "Epoch 115/160\n",
      "332/332 [==============================] - 0s 332us/step - loss: 0.3229 - acc: 0.8547\n",
      "Epoch 116/160\n",
      "332/332 [==============================] - 0s 359us/step - loss: 0.3224 - acc: 0.8517\n",
      "Epoch 117/160\n",
      "332/332 [==============================] - 0s 333us/step - loss: 0.3186 - acc: 0.8569\n",
      "Epoch 118/160\n",
      "332/332 [==============================] - 0s 331us/step - loss: 0.3194 - acc: 0.8592\n",
      "Epoch 119/160\n",
      "332/332 [==============================] - 0s 338us/step - loss: 0.3132 - acc: 0.8592\n",
      "Epoch 120/160\n",
      "332/332 [==============================] - 0s 354us/step - loss: 0.3175 - acc: 0.8637\n",
      "Epoch 121/160\n",
      "332/332 [==============================] - 0s 343us/step - loss: 0.3083 - acc: 0.8607\n",
      "Epoch 122/160\n",
      "332/332 [==============================] - 0s 381us/step - loss: 0.3185 - acc: 0.8539\n",
      "Epoch 123/160\n",
      "332/332 [==============================] - 0s 333us/step - loss: 0.3149 - acc: 0.8630\n",
      "Epoch 124/160\n",
      "332/332 [==============================] - 0s 371us/step - loss: 0.3222 - acc: 0.8577\n",
      "Epoch 125/160\n",
      "332/332 [==============================] - 0s 355us/step - loss: 0.3134 - acc: 0.8532\n",
      "Epoch 126/160\n",
      "332/332 [==============================] - 0s 306us/step - loss: 0.3106 - acc: 0.8630\n",
      "Epoch 127/160\n",
      "332/332 [==============================] - 0s 348us/step - loss: 0.3156 - acc: 0.8562\n",
      "Epoch 128/160\n",
      "332/332 [==============================] - 0s 324us/step - loss: 0.3116 - acc: 0.8607\n",
      "Epoch 129/160\n",
      "332/332 [==============================] - 0s 398us/step - loss: 0.3166 - acc: 0.8630\n",
      "Epoch 130/160\n",
      "332/332 [==============================] - 0s 299us/step - loss: 0.3118 - acc: 0.8584\n",
      "Epoch 131/160\n",
      "332/332 [==============================] - 0s 377us/step - loss: 0.3160 - acc: 0.8599\n",
      "Epoch 132/160\n",
      "332/332 [==============================] - 0s 324us/step - loss: 0.3161 - acc: 0.8607\n",
      "Epoch 133/160\n",
      "332/332 [==============================] - 0s 335us/step - loss: 0.3172 - acc: 0.8592\n",
      "Epoch 134/160\n",
      "332/332 [==============================] - 0s 354us/step - loss: 0.3222 - acc: 0.8622\n",
      "Epoch 135/160\n",
      "332/332 [==============================] - 0s 352us/step - loss: 0.3283 - acc: 0.8494\n",
      "Epoch 136/160\n",
      "332/332 [==============================] - 0s 348us/step - loss: 0.3232 - acc: 0.8539\n",
      "Epoch 137/160\n",
      "332/332 [==============================] - 0s 386us/step - loss: 0.3208 - acc: 0.8547\n",
      "Epoch 138/160\n",
      "332/332 [==============================] - 0s 354us/step - loss: 0.3177 - acc: 0.8554\n",
      "Epoch 139/160\n",
      "332/332 [==============================] - 0s 344us/step - loss: 0.3145 - acc: 0.8630\n",
      "Epoch 140/160\n",
      "332/332 [==============================] - 0s 326us/step - loss: 0.3224 - acc: 0.8562\n",
      "Epoch 141/160\n",
      "332/332 [==============================] - 0s 365us/step - loss: 0.3193 - acc: 0.8645\n",
      "Epoch 142/160\n",
      "332/332 [==============================] - 0s 354us/step - loss: 0.3211 - acc: 0.8547\n",
      "Epoch 143/160\n",
      "332/332 [==============================] - 0s 322us/step - loss: 0.3259 - acc: 0.8622\n",
      "Epoch 144/160\n",
      "332/332 [==============================] - 0s 323us/step - loss: 0.3255 - acc: 0.8532\n",
      "Epoch 145/160\n",
      "332/332 [==============================] - 0s 326us/step - loss: 0.3222 - acc: 0.8562\n",
      "Epoch 146/160\n",
      "332/332 [==============================] - 0s 355us/step - loss: 0.3228 - acc: 0.8592\n",
      "Epoch 147/160\n",
      "332/332 [==============================] - 0s 334us/step - loss: 0.3092 - acc: 0.8660\n",
      "Epoch 148/160\n",
      "332/332 [==============================] - 0s 378us/step - loss: 0.3173 - acc: 0.8584\n",
      "Epoch 149/160\n",
      "332/332 [==============================] - 0s 306us/step - loss: 0.3050 - acc: 0.8667\n",
      "Epoch 150/160\n",
      "332/332 [==============================] - 0s 330us/step - loss: 0.3175 - acc: 0.8599\n",
      "Epoch 151/160\n",
      "332/332 [==============================] - 0s 340us/step - loss: 0.3161 - acc: 0.8607\n",
      "Epoch 152/160\n",
      "332/332 [==============================] - 0s 341us/step - loss: 0.3116 - acc: 0.8622\n",
      "Epoch 153/160\n",
      "332/332 [==============================] - 0s 353us/step - loss: 0.3155 - acc: 0.8584\n",
      "Epoch 154/160\n",
      "332/332 [==============================] - 0s 345us/step - loss: 0.3103 - acc: 0.8622\n",
      "Epoch 155/160\n",
      "332/332 [==============================] - 0s 351us/step - loss: 0.3142 - acc: 0.8614\n",
      "Epoch 156/160\n",
      "332/332 [==============================] - 0s 480us/step - loss: 0.3118 - acc: 0.8599\n",
      "Epoch 157/160\n",
      "332/332 [==============================] - 0s 472us/step - loss: 0.3077 - acc: 0.8584\n",
      "Epoch 158/160\n",
      "332/332 [==============================] - 0s 375us/step - loss: 0.3024 - acc: 0.8682\n",
      "Epoch 159/160\n",
      "332/332 [==============================] - 0s 335us/step - loss: 0.3026 - acc: 0.8652\n",
      "Epoch 160/160\n",
      "332/332 [==============================] - 0s 333us/step - loss: 0.3010 - acc: 0.8622\n",
      "84/84 [==============================] - 0s 2ms/step\n",
      "332/332 [==============================] - 0s 94us/step\n",
      "\n",
      "acc: 75.89%\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "0 0 0 1\n",
      "[[16  5  0  9]\n",
      " [ 4  4  0  8]\n",
      " [ 0  1  2  1]\n",
      " [ 2  1  0 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.73      0.53      0.62        30\n",
      "      Normal       0.36      0.25      0.30        16\n",
      "        Slow       1.00      0.50      0.67         4\n",
      "   Very Fast       0.63      0.91      0.75        34\n",
      "\n",
      "    accuracy                           0.63        84\n",
      "   macro avg       0.68      0.55      0.58        84\n",
      "weighted avg       0.63      0.63      0.61        84\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6309523809523809"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='highway') & (df_k.Timelevel==2)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy zone: highway and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "128/128 [==============================] - 3s 20ms/step - loss: 0.6188 - acc: 0.6693\n",
      "Epoch 2/160\n",
      "128/128 [==============================] - 0s 484us/step - loss: 0.6176 - acc: 0.7005\n",
      "Epoch 3/160\n",
      "128/128 [==============================] - 0s 482us/step - loss: 0.5815 - acc: 0.7135\n",
      "Epoch 4/160\n",
      "128/128 [==============================] - 0s 575us/step - loss: 0.5771 - acc: 0.7083\n",
      "Epoch 5/160\n",
      "128/128 [==============================] - 0s 443us/step - loss: 0.5687 - acc: 0.7031\n",
      "Epoch 6/160\n",
      "128/128 [==============================] - 0s 410us/step - loss: 0.5542 - acc: 0.7083\n",
      "Epoch 7/160\n",
      "128/128 [==============================] - 0s 376us/step - loss: 0.5314 - acc: 0.7240\n",
      "Epoch 8/160\n",
      "128/128 [==============================] - 0s 396us/step - loss: 0.5168 - acc: 0.7344\n",
      "Epoch 9/160\n",
      "128/128 [==============================] - 0s 469us/step - loss: 0.5179 - acc: 0.7344\n",
      "Epoch 10/160\n",
      "128/128 [==============================] - 0s 402us/step - loss: 0.5122 - acc: 0.7578\n",
      "Epoch 11/160\n",
      "128/128 [==============================] - 0s 363us/step - loss: 0.5142 - acc: 0.7448\n",
      "Epoch 12/160\n",
      "128/128 [==============================] - 0s 403us/step - loss: 0.4989 - acc: 0.7422\n",
      "Epoch 13/160\n",
      "128/128 [==============================] - 0s 425us/step - loss: 0.5166 - acc: 0.7578\n",
      "Epoch 14/160\n",
      "128/128 [==============================] - 0s 365us/step - loss: 0.5146 - acc: 0.7318\n",
      "Epoch 15/160\n",
      "128/128 [==============================] - 0s 337us/step - loss: 0.5082 - acc: 0.7526\n",
      "Epoch 16/160\n",
      "128/128 [==============================] - 0s 412us/step - loss: 0.5160 - acc: 0.7448\n",
      "Epoch 17/160\n",
      "128/128 [==============================] - 0s 394us/step - loss: 0.4989 - acc: 0.7604\n",
      "Epoch 18/160\n",
      "128/128 [==============================] - 0s 375us/step - loss: 0.5146 - acc: 0.7292\n",
      "Epoch 19/160\n",
      "128/128 [==============================] - 0s 369us/step - loss: 0.4970 - acc: 0.7474\n",
      "Epoch 20/160\n",
      "128/128 [==============================] - 0s 381us/step - loss: 0.5200 - acc: 0.7396\n",
      "Epoch 21/160\n",
      "128/128 [==============================] - 0s 349us/step - loss: 0.4994 - acc: 0.7448\n",
      "Epoch 22/160\n",
      "128/128 [==============================] - 0s 398us/step - loss: 0.4963 - acc: 0.7552\n",
      "Epoch 23/160\n",
      "128/128 [==============================] - 0s 419us/step - loss: 0.4922 - acc: 0.7474\n",
      "Epoch 24/160\n",
      "128/128 [==============================] - 0s 400us/step - loss: 0.4915 - acc: 0.7630\n",
      "Epoch 25/160\n",
      "128/128 [==============================] - 0s 366us/step - loss: 0.4852 - acc: 0.7760\n",
      "Epoch 26/160\n",
      "128/128 [==============================] - 0s 342us/step - loss: 0.4820 - acc: 0.7526\n",
      "Epoch 27/160\n",
      "128/128 [==============================] - 0s 436us/step - loss: 0.4874 - acc: 0.7396\n",
      "Epoch 28/160\n",
      "128/128 [==============================] - 0s 426us/step - loss: 0.4817 - acc: 0.7578\n",
      "Epoch 29/160\n",
      "128/128 [==============================] - 0s 375us/step - loss: 0.4905 - acc: 0.7578\n",
      "Epoch 30/160\n",
      "128/128 [==============================] - 0s 382us/step - loss: 0.4726 - acc: 0.7760\n",
      "Epoch 31/160\n",
      "128/128 [==============================] - 0s 359us/step - loss: 0.5374 - acc: 0.7240\n",
      "Epoch 32/160\n",
      "128/128 [==============================] - 0s 392us/step - loss: 0.4903 - acc: 0.7422\n",
      "Epoch 33/160\n",
      "128/128 [==============================] - 0s 484us/step - loss: 0.4830 - acc: 0.7656\n",
      "Epoch 34/160\n",
      "128/128 [==============================] - 0s 306us/step - loss: 0.4781 - acc: 0.7500\n",
      "Epoch 35/160\n",
      "128/128 [==============================] - 0s 398us/step - loss: 0.4817 - acc: 0.7500\n",
      "Epoch 36/160\n",
      "128/128 [==============================] - 0s 353us/step - loss: 0.4611 - acc: 0.7865\n",
      "Epoch 37/160\n",
      "128/128 [==============================] - 0s 371us/step - loss: 0.4680 - acc: 0.7969\n",
      "Epoch 38/160\n",
      "128/128 [==============================] - 0s 320us/step - loss: 0.4565 - acc: 0.7865\n",
      "Epoch 39/160\n",
      "128/128 [==============================] - 0s 378us/step - loss: 0.4611 - acc: 0.7760\n",
      "Epoch 40/160\n",
      "128/128 [==============================] - 0s 316us/step - loss: 0.4491 - acc: 0.7917\n",
      "Epoch 41/160\n",
      "128/128 [==============================] - 0s 315us/step - loss: 0.4399 - acc: 0.7943\n",
      "Epoch 42/160\n",
      "128/128 [==============================] - 0s 343us/step - loss: 0.4455 - acc: 0.7812\n",
      "Epoch 43/160\n",
      "128/128 [==============================] - 0s 342us/step - loss: 0.4462 - acc: 0.7891\n",
      "Epoch 44/160\n",
      "128/128 [==============================] - 0s 327us/step - loss: 0.4398 - acc: 0.7865\n",
      "Epoch 45/160\n",
      "128/128 [==============================] - 0s 391us/step - loss: 0.4328 - acc: 0.7969\n",
      "Epoch 46/160\n",
      "128/128 [==============================] - 0s 363us/step - loss: 0.4434 - acc: 0.7891\n",
      "Epoch 47/160\n",
      "128/128 [==============================] - 0s 386us/step - loss: 0.4459 - acc: 0.7891\n",
      "Epoch 48/160\n",
      "128/128 [==============================] - 0s 401us/step - loss: 0.4318 - acc: 0.7917\n",
      "Epoch 49/160\n",
      "128/128 [==============================] - 0s 371us/step - loss: 0.4512 - acc: 0.7865\n",
      "Epoch 50/160\n",
      "128/128 [==============================] - 0s 355us/step - loss: 0.4507 - acc: 0.7760\n",
      "Epoch 51/160\n",
      "128/128 [==============================] - 0s 381us/step - loss: 0.4418 - acc: 0.7865\n",
      "Epoch 52/160\n",
      "128/128 [==============================] - 0s 391us/step - loss: 0.4611 - acc: 0.7760\n",
      "Epoch 53/160\n",
      "128/128 [==============================] - 0s 386us/step - loss: 0.4301 - acc: 0.7969\n",
      "Epoch 54/160\n",
      "128/128 [==============================] - 0s 348us/step - loss: 0.4439 - acc: 0.7865\n",
      "Epoch 55/160\n",
      "128/128 [==============================] - 0s 379us/step - loss: 0.4337 - acc: 0.7917\n",
      "Epoch 56/160\n",
      "128/128 [==============================] - 0s 367us/step - loss: 0.4190 - acc: 0.8099\n",
      "Epoch 57/160\n",
      "128/128 [==============================] - 0s 373us/step - loss: 0.4132 - acc: 0.8073\n",
      "Epoch 58/160\n",
      "128/128 [==============================] - 0s 356us/step - loss: 0.4118 - acc: 0.7943\n",
      "Epoch 59/160\n",
      "128/128 [==============================] - 0s 409us/step - loss: 0.4439 - acc: 0.8073\n",
      "Epoch 60/160\n",
      "128/128 [==============================] - 0s 434us/step - loss: 0.4216 - acc: 0.8047\n",
      "Epoch 61/160\n",
      "128/128 [==============================] - 0s 375us/step - loss: 0.4528 - acc: 0.7708\n",
      "Epoch 62/160\n",
      "128/128 [==============================] - 0s 386us/step - loss: 0.4391 - acc: 0.8021\n",
      "Epoch 63/160\n",
      "128/128 [==============================] - 0s 459us/step - loss: 0.4365 - acc: 0.7812\n",
      "Epoch 64/160\n",
      "128/128 [==============================] - 0s 396us/step - loss: 0.4310 - acc: 0.7943\n",
      "Epoch 65/160\n",
      "128/128 [==============================] - 0s 410us/step - loss: 0.4327 - acc: 0.7995\n",
      "Epoch 66/160\n",
      "128/128 [==============================] - 0s 405us/step - loss: 0.4258 - acc: 0.7943\n",
      "Epoch 67/160\n",
      "128/128 [==============================] - 0s 414us/step - loss: 0.4156 - acc: 0.7995\n",
      "Epoch 68/160\n",
      "128/128 [==============================] - 0s 416us/step - loss: 0.4156 - acc: 0.8177\n",
      "Epoch 69/160\n",
      "128/128 [==============================] - 0s 481us/step - loss: 0.4145 - acc: 0.7995\n",
      "Epoch 70/160\n",
      "128/128 [==============================] - 0s 420us/step - loss: 0.4100 - acc: 0.7995\n",
      "Epoch 71/160\n",
      "128/128 [==============================] - 0s 473us/step - loss: 0.4098 - acc: 0.8073\n",
      "Epoch 72/160\n",
      "128/128 [==============================] - 0s 589us/step - loss: 0.4186 - acc: 0.7943\n",
      "Epoch 73/160\n",
      "128/128 [==============================] - 0s 444us/step - loss: 0.4266 - acc: 0.7995\n",
      "Epoch 74/160\n",
      "128/128 [==============================] - 0s 534us/step - loss: 0.4135 - acc: 0.8229\n",
      "Epoch 75/160\n",
      "128/128 [==============================] - 0s 517us/step - loss: 0.4417 - acc: 0.7734\n",
      "Epoch 76/160\n",
      "128/128 [==============================] - 0s 450us/step - loss: 0.4218 - acc: 0.7969\n",
      "Epoch 77/160\n",
      "128/128 [==============================] - 0s 416us/step - loss: 0.4225 - acc: 0.8099\n",
      "Epoch 78/160\n",
      "128/128 [==============================] - 0s 479us/step - loss: 0.4182 - acc: 0.8047\n",
      "Epoch 79/160\n",
      "128/128 [==============================] - 0s 508us/step - loss: 0.4390 - acc: 0.7943\n",
      "Epoch 80/160\n",
      "128/128 [==============================] - 0s 392us/step - loss: 0.4095 - acc: 0.8125\n",
      "Epoch 81/160\n",
      "128/128 [==============================] - 0s 358us/step - loss: 0.4210 - acc: 0.7995\n",
      "Epoch 82/160\n",
      "128/128 [==============================] - 0s 382us/step - loss: 0.4175 - acc: 0.8047\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 430us/step - loss: 0.3863 - acc: 0.8047\n",
      "Epoch 84/160\n",
      "128/128 [==============================] - 0s 476us/step - loss: 0.4252 - acc: 0.8073\n",
      "Epoch 85/160\n",
      "128/128 [==============================] - 0s 478us/step - loss: 0.3985 - acc: 0.8021\n",
      "Epoch 86/160\n",
      "128/128 [==============================] - 0s 482us/step - loss: 0.3961 - acc: 0.8047\n",
      "Epoch 87/160\n",
      "128/128 [==============================] - 0s 425us/step - loss: 0.4058 - acc: 0.8047\n",
      "Epoch 88/160\n",
      "128/128 [==============================] - 0s 478us/step - loss: 0.3950 - acc: 0.8151\n",
      "Epoch 89/160\n",
      "128/128 [==============================] - 0s 419us/step - loss: 0.3879 - acc: 0.8125\n",
      "Epoch 90/160\n",
      "128/128 [==============================] - 0s 400us/step - loss: 0.3866 - acc: 0.8151\n",
      "Epoch 91/160\n",
      "128/128 [==============================] - 0s 397us/step - loss: 0.3876 - acc: 0.8177\n",
      "Epoch 92/160\n",
      "128/128 [==============================] - 0s 379us/step - loss: 0.3872 - acc: 0.8203\n",
      "Epoch 93/160\n",
      "128/128 [==============================] - 0s 476us/step - loss: 0.3936 - acc: 0.8047\n",
      "Epoch 94/160\n",
      "128/128 [==============================] - 0s 469us/step - loss: 0.3999 - acc: 0.8047\n",
      "Epoch 95/160\n",
      "128/128 [==============================] - 0s 368us/step - loss: 0.4232 - acc: 0.8021\n",
      "Epoch 96/160\n",
      "128/128 [==============================] - 0s 395us/step - loss: 0.3809 - acc: 0.8203\n",
      "Epoch 97/160\n",
      "128/128 [==============================] - 0s 417us/step - loss: 0.4278 - acc: 0.8047\n",
      "Epoch 98/160\n",
      "128/128 [==============================] - 0s 425us/step - loss: 0.3877 - acc: 0.8021\n",
      "Epoch 99/160\n",
      "128/128 [==============================] - 0s 402us/step - loss: 0.4037 - acc: 0.7943\n",
      "Epoch 100/160\n",
      "128/128 [==============================] - 0s 452us/step - loss: 0.3920 - acc: 0.8047\n",
      "Epoch 101/160\n",
      "128/128 [==============================] - 0s 424us/step - loss: 0.3810 - acc: 0.8047\n",
      "Epoch 102/160\n",
      "128/128 [==============================] - 0s 420us/step - loss: 0.3917 - acc: 0.8307\n",
      "Epoch 103/160\n",
      "128/128 [==============================] - 0s 471us/step - loss: 0.3829 - acc: 0.8177\n",
      "Epoch 104/160\n",
      "128/128 [==============================] - 0s 437us/step - loss: 0.3910 - acc: 0.8021\n",
      "Epoch 105/160\n",
      "128/128 [==============================] - 0s 451us/step - loss: 0.4013 - acc: 0.8073\n",
      "Epoch 106/160\n",
      "128/128 [==============================] - 0s 490us/step - loss: 0.3985 - acc: 0.8151\n",
      "Epoch 107/160\n",
      "128/128 [==============================] - 0s 450us/step - loss: 0.3943 - acc: 0.8047\n",
      "Epoch 108/160\n",
      "128/128 [==============================] - 0s 428us/step - loss: 0.3893 - acc: 0.8125\n",
      "Epoch 109/160\n",
      "128/128 [==============================] - 0s 435us/step - loss: 0.4093 - acc: 0.8177\n",
      "Epoch 110/160\n",
      "128/128 [==============================] - 0s 493us/step - loss: 0.4021 - acc: 0.8047\n",
      "Epoch 111/160\n",
      "128/128 [==============================] - 0s 368us/step - loss: 0.3931 - acc: 0.8177\n",
      "Epoch 112/160\n",
      "128/128 [==============================] - 0s 373us/step - loss: 0.4167 - acc: 0.8073\n",
      "Epoch 113/160\n",
      "128/128 [==============================] - 0s 461us/step - loss: 0.4158 - acc: 0.7943\n",
      "Epoch 114/160\n",
      "128/128 [==============================] - 0s 419us/step - loss: 0.3860 - acc: 0.8177\n",
      "Epoch 115/160\n",
      "128/128 [==============================] - 0s 399us/step - loss: 0.4102 - acc: 0.7786\n",
      "Epoch 116/160\n",
      "128/128 [==============================] - 0s 455us/step - loss: 0.3823 - acc: 0.8229\n",
      "Epoch 117/160\n",
      "128/128 [==============================] - 0s 417us/step - loss: 0.4081 - acc: 0.7891\n",
      "Epoch 118/160\n",
      "128/128 [==============================] - 0s 415us/step - loss: 0.4062 - acc: 0.8047\n",
      "Epoch 119/160\n",
      "128/128 [==============================] - 0s 461us/step - loss: 0.3963 - acc: 0.8229\n",
      "Epoch 120/160\n",
      "128/128 [==============================] - 0s 380us/step - loss: 0.4030 - acc: 0.8047\n",
      "Epoch 121/160\n",
      "128/128 [==============================] - 0s 377us/step - loss: 0.4044 - acc: 0.7969\n",
      "Epoch 122/160\n",
      "128/128 [==============================] - 0s 405us/step - loss: 0.4053 - acc: 0.7969\n",
      "Epoch 123/160\n",
      "128/128 [==============================] - 0s 431us/step - loss: 0.4030 - acc: 0.8125\n",
      "Epoch 124/160\n",
      "128/128 [==============================] - 0s 466us/step - loss: 0.3994 - acc: 0.7995\n",
      "Epoch 125/160\n",
      "128/128 [==============================] - 0s 463us/step - loss: 0.3830 - acc: 0.8021\n",
      "Epoch 126/160\n",
      "128/128 [==============================] - 0s 414us/step - loss: 0.3759 - acc: 0.8359\n",
      "Epoch 127/160\n",
      "128/128 [==============================] - 0s 387us/step - loss: 0.3860 - acc: 0.8255\n",
      "Epoch 128/160\n",
      "128/128 [==============================] - 0s 379us/step - loss: 0.3914 - acc: 0.8073\n",
      "Epoch 129/160\n",
      "128/128 [==============================] - 0s 392us/step - loss: 0.3700 - acc: 0.8203\n",
      "Epoch 130/160\n",
      "128/128 [==============================] - 0s 407us/step - loss: 0.3813 - acc: 0.8177\n",
      "Epoch 131/160\n",
      "128/128 [==============================] - 0s 368us/step - loss: 0.3671 - acc: 0.8333\n",
      "Epoch 132/160\n",
      "128/128 [==============================] - 0s 434us/step - loss: 0.3834 - acc: 0.7995\n",
      "Epoch 133/160\n",
      "128/128 [==============================] - 0s 425us/step - loss: 0.3779 - acc: 0.8151\n",
      "Epoch 134/160\n",
      "128/128 [==============================] - 0s 406us/step - loss: 0.3716 - acc: 0.8255\n",
      "Epoch 135/160\n",
      "128/128 [==============================] - 0s 354us/step - loss: 0.3679 - acc: 0.8177\n",
      "Epoch 136/160\n",
      "128/128 [==============================] - 0s 435us/step - loss: 0.3654 - acc: 0.8151\n",
      "Epoch 137/160\n",
      "128/128 [==============================] - 0s 394us/step - loss: 0.3836 - acc: 0.8021\n",
      "Epoch 138/160\n",
      "128/128 [==============================] - 0s 492us/step - loss: 0.3991 - acc: 0.8151\n",
      "Epoch 139/160\n",
      "128/128 [==============================] - 0s 371us/step - loss: 0.3683 - acc: 0.8203\n",
      "Epoch 140/160\n",
      "128/128 [==============================] - 0s 361us/step - loss: 0.3740 - acc: 0.8099\n",
      "Epoch 141/160\n",
      "128/128 [==============================] - 0s 388us/step - loss: 0.3714 - acc: 0.8125\n",
      "Epoch 142/160\n",
      "128/128 [==============================] - 0s 421us/step - loss: 0.3665 - acc: 0.8177\n",
      "Epoch 143/160\n",
      "128/128 [==============================] - 0s 426us/step - loss: 0.3666 - acc: 0.8151\n",
      "Epoch 144/160\n",
      "128/128 [==============================] - 0s 328us/step - loss: 0.3576 - acc: 0.8255\n",
      "Epoch 145/160\n",
      "128/128 [==============================] - 0s 440us/step - loss: 0.3639 - acc: 0.8125\n",
      "Epoch 146/160\n",
      "128/128 [==============================] - 0s 398us/step - loss: 0.3590 - acc: 0.8333\n",
      "Epoch 147/160\n",
      "128/128 [==============================] - 0s 377us/step - loss: 0.3672 - acc: 0.8125\n",
      "Epoch 148/160\n",
      "128/128 [==============================] - 0s 452us/step - loss: 0.3787 - acc: 0.8151\n",
      "Epoch 149/160\n",
      "128/128 [==============================] - 0s 405us/step - loss: 0.3611 - acc: 0.8255\n",
      "Epoch 150/160\n",
      "128/128 [==============================] - 0s 401us/step - loss: 0.3920 - acc: 0.7943\n",
      "Epoch 151/160\n",
      "128/128 [==============================] - 0s 438us/step - loss: 0.3945 - acc: 0.8125\n",
      "Epoch 152/160\n",
      "128/128 [==============================] - 0s 425us/step - loss: 0.3718 - acc: 0.8229\n",
      "Epoch 153/160\n",
      "128/128 [==============================] - 0s 382us/step - loss: 0.4085 - acc: 0.8021\n",
      "Epoch 154/160\n",
      "128/128 [==============================] - 0s 383us/step - loss: 0.4070 - acc: 0.8047\n",
      "Epoch 155/160\n",
      "128/128 [==============================] - 0s 416us/step - loss: 0.3866 - acc: 0.8073\n",
      "Epoch 156/160\n",
      "128/128 [==============================] - 0s 400us/step - loss: 0.3787 - acc: 0.8203\n",
      "Epoch 157/160\n",
      "128/128 [==============================] - 0s 465us/step - loss: 0.3669 - acc: 0.8177\n",
      "Epoch 158/160\n",
      "128/128 [==============================] - 0s 373us/step - loss: 0.4137 - acc: 0.8255\n",
      "Epoch 159/160\n",
      "128/128 [==============================] - 0s 380us/step - loss: 0.3806 - acc: 0.8073\n",
      "Epoch 160/160\n",
      "128/128 [==============================] - 0s 431us/step - loss: 0.3695 - acc: 0.8229\n",
      "128/128 [==============================] - 1s 7ms/step\n",
      "\n",
      "acc: 82.81%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3c765cfe0f21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mk_3_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mk_3_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_3_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mk_4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mk_4_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mk_4_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_4_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='highway') & (df_k.Timelevel==3)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:highway and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "125/125 [==============================] - 1s 9ms/step - loss: 0.5495 - acc: 0.7500\n",
      "Epoch 2/160\n",
      "125/125 [==============================] - 0s 402us/step - loss: 0.5004 - acc: 0.7520\n",
      "Epoch 3/160\n",
      "125/125 [==============================] - 0s 410us/step - loss: 0.4803 - acc: 0.7660\n",
      "Epoch 4/160\n",
      "125/125 [==============================] - 0s 394us/step - loss: 0.4685 - acc: 0.7680\n",
      "Epoch 5/160\n",
      "125/125 [==============================] - 0s 363us/step - loss: 0.4692 - acc: 0.7680\n",
      "Epoch 6/160\n",
      "125/125 [==============================] - 0s 363us/step - loss: 0.4627 - acc: 0.7680\n",
      "Epoch 7/160\n",
      "125/125 [==============================] - 0s 331us/step - loss: 0.4586 - acc: 0.7640\n",
      "Epoch 8/160\n",
      "125/125 [==============================] - 0s 419us/step - loss: 0.4559 - acc: 0.7660\n",
      "Epoch 9/160\n",
      "125/125 [==============================] - 0s 410us/step - loss: 0.4471 - acc: 0.7760\n",
      "Epoch 10/160\n",
      "125/125 [==============================] - 0s 293us/step - loss: 0.4463 - acc: 0.7840\n",
      "Epoch 11/160\n",
      "125/125 [==============================] - 0s 332us/step - loss: 0.4466 - acc: 0.7580\n",
      "Epoch 12/160\n",
      "125/125 [==============================] - 0s 296us/step - loss: 0.4385 - acc: 0.7700\n",
      "Epoch 13/160\n",
      "125/125 [==============================] - 0s 289us/step - loss: 0.4417 - acc: 0.7880\n",
      "Epoch 14/160\n",
      "125/125 [==============================] - 0s 362us/step - loss: 0.4392 - acc: 0.7820\n",
      "Epoch 15/160\n",
      "125/125 [==============================] - 0s 383us/step - loss: 0.4378 - acc: 0.7760\n",
      "Epoch 16/160\n",
      "125/125 [==============================] - 0s 340us/step - loss: 0.4409 - acc: 0.7720\n",
      "Epoch 17/160\n",
      "125/125 [==============================] - 0s 420us/step - loss: 0.4306 - acc: 0.7860\n",
      "Epoch 18/160\n",
      "125/125 [==============================] - 0s 296us/step - loss: 0.4228 - acc: 0.7940\n",
      "Epoch 19/160\n",
      "125/125 [==============================] - 0s 382us/step - loss: 0.4192 - acc: 0.7920\n",
      "Epoch 20/160\n",
      "125/125 [==============================] - 0s 392us/step - loss: 0.4115 - acc: 0.8000\n",
      "Epoch 21/160\n",
      "125/125 [==============================] - 0s 394us/step - loss: 0.4200 - acc: 0.7820\n",
      "Epoch 22/160\n",
      "125/125 [==============================] - 0s 381us/step - loss: 0.4110 - acc: 0.8000\n",
      "Epoch 23/160\n",
      "125/125 [==============================] - 0s 393us/step - loss: 0.4056 - acc: 0.7960\n",
      "Epoch 24/160\n",
      "125/125 [==============================] - 0s 386us/step - loss: 0.4142 - acc: 0.7760\n",
      "Epoch 25/160\n",
      "125/125 [==============================] - 0s 427us/step - loss: 0.4094 - acc: 0.7980\n",
      "Epoch 26/160\n",
      "125/125 [==============================] - 0s 318us/step - loss: 0.3976 - acc: 0.8020\n",
      "Epoch 27/160\n",
      "125/125 [==============================] - 0s 350us/step - loss: 0.4000 - acc: 0.8100\n",
      "Epoch 28/160\n",
      "125/125 [==============================] - 0s 367us/step - loss: 0.4074 - acc: 0.7880\n",
      "Epoch 29/160\n",
      "125/125 [==============================] - 0s 354us/step - loss: 0.4068 - acc: 0.7920\n",
      "Epoch 30/160\n",
      "125/125 [==============================] - 0s 385us/step - loss: 0.3839 - acc: 0.8140\n",
      "Epoch 31/160\n",
      "125/125 [==============================] - 0s 425us/step - loss: 0.3950 - acc: 0.8120\n",
      "Epoch 32/160\n",
      "125/125 [==============================] - 0s 340us/step - loss: 0.3934 - acc: 0.7940\n",
      "Epoch 33/160\n",
      "125/125 [==============================] - 0s 342us/step - loss: 0.3986 - acc: 0.8000\n",
      "Epoch 34/160\n",
      "125/125 [==============================] - 0s 378us/step - loss: 0.4002 - acc: 0.8060\n",
      "Epoch 35/160\n",
      "125/125 [==============================] - 0s 378us/step - loss: 0.3913 - acc: 0.8140\n",
      "Epoch 36/160\n",
      "125/125 [==============================] - 0s 417us/step - loss: 0.3802 - acc: 0.8040\n",
      "Epoch 37/160\n",
      "125/125 [==============================] - 0s 348us/step - loss: 0.4054 - acc: 0.7820\n",
      "Epoch 38/160\n",
      "125/125 [==============================] - 0s 343us/step - loss: 0.3810 - acc: 0.8020\n",
      "Epoch 39/160\n",
      "125/125 [==============================] - 0s 323us/step - loss: 0.3937 - acc: 0.7980\n",
      "Epoch 40/160\n",
      "125/125 [==============================] - 0s 410us/step - loss: 0.3888 - acc: 0.7920\n",
      "Epoch 41/160\n",
      "125/125 [==============================] - 0s 441us/step - loss: 0.3808 - acc: 0.8020\n",
      "Epoch 42/160\n",
      "125/125 [==============================] - 0s 409us/step - loss: 0.3819 - acc: 0.8040\n",
      "Epoch 43/160\n",
      "125/125 [==============================] - 0s 360us/step - loss: 0.3842 - acc: 0.7920\n",
      "Epoch 44/160\n",
      "125/125 [==============================] - 0s 473us/step - loss: 0.3818 - acc: 0.8000\n",
      "Epoch 45/160\n",
      "125/125 [==============================] - 0s 462us/step - loss: 0.3743 - acc: 0.8120\n",
      "Epoch 46/160\n",
      "125/125 [==============================] - 0s 377us/step - loss: 0.3832 - acc: 0.8100\n",
      "Epoch 47/160\n",
      "125/125 [==============================] - 0s 402us/step - loss: 0.3667 - acc: 0.8180\n",
      "Epoch 48/160\n",
      "125/125 [==============================] - 0s 364us/step - loss: 0.3805 - acc: 0.8060\n",
      "Epoch 49/160\n",
      "125/125 [==============================] - 0s 368us/step - loss: 0.3756 - acc: 0.8160\n",
      "Epoch 50/160\n",
      "125/125 [==============================] - 0s 462us/step - loss: 0.3690 - acc: 0.8100\n",
      "Epoch 51/160\n",
      "125/125 [==============================] - 0s 401us/step - loss: 0.3624 - acc: 0.8240\n",
      "Epoch 52/160\n",
      "125/125 [==============================] - 0s 333us/step - loss: 0.3677 - acc: 0.7960\n",
      "Epoch 53/160\n",
      "125/125 [==============================] - 0s 431us/step - loss: 0.3663 - acc: 0.8140\n",
      "Epoch 54/160\n",
      "125/125 [==============================] - 0s 367us/step - loss: 0.3598 - acc: 0.8060\n",
      "Epoch 55/160\n",
      "125/125 [==============================] - 0s 424us/step - loss: 0.3713 - acc: 0.8000\n",
      "Epoch 56/160\n",
      "125/125 [==============================] - 0s 379us/step - loss: 0.3674 - acc: 0.8120\n",
      "Epoch 57/160\n",
      "125/125 [==============================] - 0s 401us/step - loss: 0.3570 - acc: 0.8120\n",
      "Epoch 58/160\n",
      "125/125 [==============================] - 0s 359us/step - loss: 0.3535 - acc: 0.8160\n",
      "Epoch 59/160\n",
      "125/125 [==============================] - 0s 418us/step - loss: 0.3607 - acc: 0.8040\n",
      "Epoch 60/160\n",
      "125/125 [==============================] - 0s 385us/step - loss: 0.3609 - acc: 0.8080\n",
      "Epoch 61/160\n",
      "125/125 [==============================] - 0s 404us/step - loss: 0.3595 - acc: 0.8080\n",
      "Epoch 62/160\n",
      "125/125 [==============================] - 0s 423us/step - loss: 0.3826 - acc: 0.8000\n",
      "Epoch 63/160\n",
      "125/125 [==============================] - 0s 352us/step - loss: 0.3691 - acc: 0.8200\n",
      "Epoch 64/160\n",
      "125/125 [==============================] - 0s 399us/step - loss: 0.3744 - acc: 0.8000\n",
      "Epoch 65/160\n",
      "125/125 [==============================] - 0s 426us/step - loss: 0.3741 - acc: 0.7980\n",
      "Epoch 66/160\n",
      "125/125 [==============================] - 0s 341us/step - loss: 0.3618 - acc: 0.7960\n",
      "Epoch 67/160\n",
      "125/125 [==============================] - 0s 354us/step - loss: 0.3608 - acc: 0.8080\n",
      "Epoch 68/160\n",
      "125/125 [==============================] - 0s 349us/step - loss: 0.3638 - acc: 0.7960\n",
      "Epoch 69/160\n",
      "125/125 [==============================] - 0s 419us/step - loss: 0.3587 - acc: 0.8160\n",
      "Epoch 70/160\n",
      "125/125 [==============================] - 0s 394us/step - loss: 0.3692 - acc: 0.8120\n",
      "Epoch 71/160\n",
      "125/125 [==============================] - 0s 428us/step - loss: 0.3525 - acc: 0.8100\n",
      "Epoch 72/160\n",
      "125/125 [==============================] - 0s 355us/step - loss: 0.3626 - acc: 0.8100\n",
      "Epoch 73/160\n",
      "125/125 [==============================] - 0s 368us/step - loss: 0.3681 - acc: 0.8140\n",
      "Epoch 74/160\n",
      "125/125 [==============================] - 0s 346us/step - loss: 0.3931 - acc: 0.8060\n",
      "Epoch 75/160\n",
      "125/125 [==============================] - 0s 370us/step - loss: 0.3725 - acc: 0.8040\n",
      "Epoch 76/160\n",
      "125/125 [==============================] - 0s 446us/step - loss: 0.3975 - acc: 0.7980\n",
      "Epoch 77/160\n",
      "125/125 [==============================] - 0s 403us/step - loss: 0.3978 - acc: 0.7880\n",
      "Epoch 78/160\n",
      "125/125 [==============================] - 0s 359us/step - loss: 0.3906 - acc: 0.7900\n",
      "Epoch 79/160\n",
      "125/125 [==============================] - 0s 423us/step - loss: 0.3838 - acc: 0.8060\n",
      "Epoch 80/160\n",
      "125/125 [==============================] - 0s 392us/step - loss: 0.3787 - acc: 0.7960\n",
      "Epoch 81/160\n",
      "125/125 [==============================] - 0s 388us/step - loss: 0.3758 - acc: 0.8100\n",
      "Epoch 82/160\n",
      "125/125 [==============================] - 0s 308us/step - loss: 0.3618 - acc: 0.8160\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 429us/step - loss: 0.3666 - acc: 0.8080\n",
      "Epoch 84/160\n",
      "125/125 [==============================] - 0s 409us/step - loss: 0.3620 - acc: 0.8140\n",
      "Epoch 85/160\n",
      "125/125 [==============================] - 0s 395us/step - loss: 0.3534 - acc: 0.8240\n",
      "Epoch 86/160\n",
      "125/125 [==============================] - 0s 389us/step - loss: 0.3595 - acc: 0.8060\n",
      "Epoch 87/160\n",
      "125/125 [==============================] - 0s 408us/step - loss: 0.3458 - acc: 0.8280\n",
      "Epoch 88/160\n",
      "125/125 [==============================] - 0s 374us/step - loss: 0.3527 - acc: 0.8160\n",
      "Epoch 89/160\n",
      "125/125 [==============================] - 0s 509us/step - loss: 0.3542 - acc: 0.8140\n",
      "Epoch 90/160\n",
      "125/125 [==============================] - 0s 448us/step - loss: 0.3544 - acc: 0.8160\n",
      "Epoch 91/160\n",
      "125/125 [==============================] - 0s 457us/step - loss: 0.3491 - acc: 0.8260\n",
      "Epoch 92/160\n",
      "125/125 [==============================] - 0s 421us/step - loss: 0.3492 - acc: 0.8140\n",
      "Epoch 93/160\n",
      "125/125 [==============================] - 0s 380us/step - loss: 0.3514 - acc: 0.8120\n",
      "Epoch 94/160\n",
      "125/125 [==============================] - 0s 406us/step - loss: 0.3413 - acc: 0.8300\n",
      "Epoch 95/160\n",
      "125/125 [==============================] - 0s 392us/step - loss: 0.3544 - acc: 0.8160\n",
      "Epoch 96/160\n",
      "125/125 [==============================] - 0s 373us/step - loss: 0.3439 - acc: 0.8220\n",
      "Epoch 97/160\n",
      "125/125 [==============================] - 0s 383us/step - loss: 0.3380 - acc: 0.8300\n",
      "Epoch 98/160\n",
      "125/125 [==============================] - 0s 395us/step - loss: 0.3649 - acc: 0.8160\n",
      "Epoch 99/160\n",
      "125/125 [==============================] - 0s 396us/step - loss: 0.3623 - acc: 0.7820\n",
      "Epoch 100/160\n",
      "125/125 [==============================] - 0s 425us/step - loss: 0.3623 - acc: 0.7900\n",
      "Epoch 101/160\n",
      "125/125 [==============================] - 0s 353us/step - loss: 0.3704 - acc: 0.7800\n",
      "Epoch 102/160\n",
      "125/125 [==============================] - 0s 322us/step - loss: 0.3461 - acc: 0.8160\n",
      "Epoch 103/160\n",
      "125/125 [==============================] - 0s 386us/step - loss: 0.3561 - acc: 0.8160\n",
      "Epoch 104/160\n",
      "125/125 [==============================] - 0s 423us/step - loss: 0.3523 - acc: 0.8140\n",
      "Epoch 105/160\n",
      "125/125 [==============================] - 0s 415us/step - loss: 0.3426 - acc: 0.8360\n",
      "Epoch 106/160\n",
      "125/125 [==============================] - 0s 374us/step - loss: 0.3563 - acc: 0.8140\n",
      "Epoch 107/160\n",
      "125/125 [==============================] - 0s 347us/step - loss: 0.3446 - acc: 0.8160\n",
      "Epoch 108/160\n",
      "125/125 [==============================] - 0s 432us/step - loss: 0.3517 - acc: 0.8100\n",
      "Epoch 109/160\n",
      "125/125 [==============================] - 0s 459us/step - loss: 0.3354 - acc: 0.8260\n",
      "Epoch 110/160\n",
      "125/125 [==============================] - 0s 370us/step - loss: 0.3455 - acc: 0.8080\n",
      "Epoch 111/160\n",
      "125/125 [==============================] - 0s 401us/step - loss: 0.3608 - acc: 0.8060\n",
      "Epoch 112/160\n",
      "125/125 [==============================] - 0s 370us/step - loss: 0.3360 - acc: 0.8120\n",
      "Epoch 113/160\n",
      "125/125 [==============================] - 0s 369us/step - loss: 0.3565 - acc: 0.8240\n",
      "Epoch 114/160\n",
      "125/125 [==============================] - 0s 419us/step - loss: 0.3470 - acc: 0.8160\n",
      "Epoch 115/160\n",
      "125/125 [==============================] - 0s 380us/step - loss: 0.3409 - acc: 0.8140\n",
      "Epoch 116/160\n",
      "125/125 [==============================] - 0s 376us/step - loss: 0.3401 - acc: 0.8220\n",
      "Epoch 117/160\n",
      "125/125 [==============================] - 0s 404us/step - loss: 0.3391 - acc: 0.8140\n",
      "Epoch 118/160\n",
      "125/125 [==============================] - 0s 398us/step - loss: 0.3288 - acc: 0.8340\n",
      "Epoch 119/160\n",
      "125/125 [==============================] - 0s 390us/step - loss: 0.3357 - acc: 0.8280\n",
      "Epoch 120/160\n",
      "125/125 [==============================] - 0s 406us/step - loss: 0.3308 - acc: 0.8180\n",
      "Epoch 121/160\n",
      "125/125 [==============================] - 0s 374us/step - loss: 0.3532 - acc: 0.8160\n",
      "Epoch 122/160\n",
      "125/125 [==============================] - 0s 358us/step - loss: 0.3432 - acc: 0.8200\n",
      "Epoch 123/160\n",
      "125/125 [==============================] - 0s 405us/step - loss: 0.4029 - acc: 0.8060\n",
      "Epoch 124/160\n",
      "125/125 [==============================] - 0s 458us/step - loss: 0.3889 - acc: 0.8020\n",
      "Epoch 125/160\n",
      "125/125 [==============================] - 0s 371us/step - loss: 0.3788 - acc: 0.7840\n",
      "Epoch 126/160\n",
      "125/125 [==============================] - 0s 374us/step - loss: 0.3659 - acc: 0.8060\n",
      "Epoch 127/160\n",
      "125/125 [==============================] - 0s 435us/step - loss: 0.3647 - acc: 0.8060\n",
      "Epoch 128/160\n",
      "125/125 [==============================] - 0s 420us/step - loss: 0.3484 - acc: 0.8180\n",
      "Epoch 129/160\n",
      "125/125 [==============================] - 0s 420us/step - loss: 0.3499 - acc: 0.8160\n",
      "Epoch 130/160\n",
      "125/125 [==============================] - 0s 357us/step - loss: 0.3467 - acc: 0.8220\n",
      "Epoch 131/160\n",
      "125/125 [==============================] - 0s 382us/step - loss: 0.3418 - acc: 0.8180\n",
      "Epoch 132/160\n",
      "125/125 [==============================] - 0s 376us/step - loss: 0.3402 - acc: 0.8140\n",
      "Epoch 133/160\n",
      "125/125 [==============================] - 0s 430us/step - loss: 0.3266 - acc: 0.8260\n",
      "Epoch 134/160\n",
      "125/125 [==============================] - 0s 460us/step - loss: 0.3413 - acc: 0.8200\n",
      "Epoch 135/160\n",
      "125/125 [==============================] - 0s 499us/step - loss: 0.3382 - acc: 0.8220\n",
      "Epoch 136/160\n",
      "125/125 [==============================] - 0s 414us/step - loss: 0.3446 - acc: 0.8100\n",
      "Epoch 137/160\n",
      "125/125 [==============================] - 0s 420us/step - loss: 0.3374 - acc: 0.8140\n",
      "Epoch 138/160\n",
      "125/125 [==============================] - 0s 459us/step - loss: 0.3366 - acc: 0.8280\n",
      "Epoch 139/160\n",
      "125/125 [==============================] - 0s 407us/step - loss: 0.3367 - acc: 0.8180\n",
      "Epoch 140/160\n",
      "125/125 [==============================] - 0s 385us/step - loss: 0.3304 - acc: 0.8300\n",
      "Epoch 141/160\n",
      "125/125 [==============================] - 0s 372us/step - loss: 0.3516 - acc: 0.8120\n",
      "Epoch 142/160\n",
      "125/125 [==============================] - 0s 404us/step - loss: 0.3376 - acc: 0.8240\n",
      "Epoch 143/160\n",
      "125/125 [==============================] - 0s 435us/step - loss: 0.3823 - acc: 0.8300\n",
      "Epoch 144/160\n",
      "125/125 [==============================] - 0s 380us/step - loss: 0.3757 - acc: 0.8240\n",
      "Epoch 145/160\n",
      "125/125 [==============================] - 0s 392us/step - loss: 0.3473 - acc: 0.8400\n",
      "Epoch 146/160\n",
      "125/125 [==============================] - 0s 400us/step - loss: 0.3437 - acc: 0.8220\n",
      "Epoch 147/160\n",
      "125/125 [==============================] - 0s 498us/step - loss: 0.3601 - acc: 0.8000\n",
      "Epoch 148/160\n",
      "125/125 [==============================] - 0s 374us/step - loss: 0.3452 - acc: 0.8260\n",
      "Epoch 149/160\n",
      "125/125 [==============================] - 0s 400us/step - loss: 0.3386 - acc: 0.8200\n",
      "Epoch 150/160\n",
      "125/125 [==============================] - 0s 364us/step - loss: 0.3380 - acc: 0.8160\n",
      "Epoch 151/160\n",
      "125/125 [==============================] - 0s 403us/step - loss: 0.3310 - acc: 0.8100\n",
      "Epoch 152/160\n",
      "125/125 [==============================] - 0s 460us/step - loss: 0.3318 - acc: 0.8380\n",
      "Epoch 153/160\n",
      "125/125 [==============================] - 0s 428us/step - loss: 0.3229 - acc: 0.8300\n",
      "Epoch 154/160\n",
      "125/125 [==============================] - 0s 351us/step - loss: 0.3421 - acc: 0.8180\n",
      "Epoch 155/160\n",
      "125/125 [==============================] - 0s 375us/step - loss: 0.3247 - acc: 0.8240\n",
      "Epoch 156/160\n",
      "125/125 [==============================] - 0s 412us/step - loss: 0.3270 - acc: 0.8180\n",
      "Epoch 157/160\n",
      "125/125 [==============================] - 0s 390us/step - loss: 0.3382 - acc: 0.8040\n",
      "Epoch 158/160\n",
      "125/125 [==============================] - 0s 406us/step - loss: 0.3234 - acc: 0.8300\n",
      "Epoch 159/160\n",
      "125/125 [==============================] - 0s 396us/step - loss: 0.3399 - acc: 0.8200\n",
      "Epoch 160/160\n",
      "125/125 [==============================] - 0s 367us/step - loss: 0.3337 - acc: 0.8180\n",
      "32/32 [==============================] - 0s 8ms/step\n",
      "125/125 [==============================] - 0s 103us/step\n",
      "\n",
      "acc: 70.31%\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "[[13  2  0  0]\n",
      " [ 2  4  0  0]\n",
      " [ 2  0  0  0]\n",
      " [ 4  0  0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.62      0.87      0.72        15\n",
      "      Normal       0.67      0.67      0.67         6\n",
      "        Slow       0.00      0.00      0.00         2\n",
      "   Very Fast       1.00      0.56      0.71         9\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.57      0.52      0.53        32\n",
      "weighted avg       0.70      0.69      0.66        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='highway') & (df_k.Timelevel==4)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: highway and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "265/265 [==============================] - 1s 5ms/step - loss: 0.4818 - acc: 0.7764\n",
      "Epoch 2/160\n",
      "265/265 [==============================] - 0s 381us/step - loss: 0.4091 - acc: 0.8321\n",
      "Epoch 3/160\n",
      "265/265 [==============================] - 0s 360us/step - loss: 0.4106 - acc: 0.8009\n",
      "Epoch 4/160\n",
      "265/265 [==============================] - 0s 403us/step - loss: 0.4060 - acc: 0.8406\n",
      "Epoch 5/160\n",
      "265/265 [==============================] - 0s 337us/step - loss: 0.4003 - acc: 0.8245\n",
      "Epoch 6/160\n",
      "265/265 [==============================] - 0s 385us/step - loss: 0.3905 - acc: 0.8368\n",
      "Epoch 7/160\n",
      "265/265 [==============================] - 0s 368us/step - loss: 0.3932 - acc: 0.8415\n",
      "Epoch 8/160\n",
      "265/265 [==============================] - 0s 401us/step - loss: 0.3791 - acc: 0.8415\n",
      "Epoch 9/160\n",
      "265/265 [==============================] - 0s 382us/step - loss: 0.3799 - acc: 0.8434\n",
      "Epoch 10/160\n",
      "265/265 [==============================] - 0s 342us/step - loss: 0.3742 - acc: 0.8425\n",
      "Epoch 11/160\n",
      "265/265 [==============================] - 0s 379us/step - loss: 0.3641 - acc: 0.8425\n",
      "Epoch 12/160\n",
      "265/265 [==============================] - 0s 339us/step - loss: 0.3695 - acc: 0.8387\n",
      "Epoch 13/160\n",
      "265/265 [==============================] - 0s 366us/step - loss: 0.3710 - acc: 0.8415\n",
      "Epoch 14/160\n",
      "265/265 [==============================] - 0s 369us/step - loss: 0.3714 - acc: 0.8443\n",
      "Epoch 15/160\n",
      "265/265 [==============================] - 0s 356us/step - loss: 0.3586 - acc: 0.8396\n",
      "Epoch 16/160\n",
      "265/265 [==============================] - 0s 347us/step - loss: 0.3576 - acc: 0.8453\n",
      "Epoch 17/160\n",
      "265/265 [==============================] - 0s 391us/step - loss: 0.3556 - acc: 0.8425\n",
      "Epoch 18/160\n",
      "265/265 [==============================] - 0s 351us/step - loss: 0.3450 - acc: 0.8462\n",
      "Epoch 19/160\n",
      "265/265 [==============================] - 0s 353us/step - loss: 0.3502 - acc: 0.8453\n",
      "Epoch 20/160\n",
      "265/265 [==============================] - 0s 352us/step - loss: 0.3623 - acc: 0.8415\n",
      "Epoch 21/160\n",
      "265/265 [==============================] - 0s 373us/step - loss: 0.3521 - acc: 0.8500\n",
      "Epoch 22/160\n",
      "265/265 [==============================] - 0s 368us/step - loss: 0.3469 - acc: 0.8472\n",
      "Epoch 23/160\n",
      "265/265 [==============================] - 0s 337us/step - loss: 0.3367 - acc: 0.8462\n",
      "Epoch 24/160\n",
      "265/265 [==============================] - 0s 426us/step - loss: 0.3494 - acc: 0.8358\n",
      "Epoch 25/160\n",
      "265/265 [==============================] - 0s 355us/step - loss: 0.3481 - acc: 0.8415\n",
      "Epoch 26/160\n",
      "265/265 [==============================] - 0s 319us/step - loss: 0.3474 - acc: 0.8538\n",
      "Epoch 27/160\n",
      "265/265 [==============================] - 0s 361us/step - loss: 0.3457 - acc: 0.8481\n",
      "Epoch 28/160\n",
      "265/265 [==============================] - 0s 334us/step - loss: 0.3572 - acc: 0.8415\n",
      "Epoch 29/160\n",
      "265/265 [==============================] - 0s 382us/step - loss: 0.3433 - acc: 0.8425\n",
      "Epoch 30/160\n",
      "265/265 [==============================] - 0s 346us/step - loss: 0.3529 - acc: 0.8425\n",
      "Epoch 31/160\n",
      "265/265 [==============================] - 0s 322us/step - loss: 0.3477 - acc: 0.8453\n",
      "Epoch 32/160\n",
      "265/265 [==============================] - 0s 346us/step - loss: 0.3483 - acc: 0.8434\n",
      "Epoch 33/160\n",
      "265/265 [==============================] - 0s 380us/step - loss: 0.3490 - acc: 0.8396\n",
      "Epoch 34/160\n",
      "265/265 [==============================] - 0s 370us/step - loss: 0.3424 - acc: 0.8434\n",
      "Epoch 35/160\n",
      "265/265 [==============================] - 0s 388us/step - loss: 0.3525 - acc: 0.8406\n",
      "Epoch 36/160\n",
      "265/265 [==============================] - 0s 317us/step - loss: 0.3366 - acc: 0.8396\n",
      "Epoch 37/160\n",
      "265/265 [==============================] - 0s 410us/step - loss: 0.3446 - acc: 0.8434\n",
      "Epoch 38/160\n",
      "265/265 [==============================] - 0s 359us/step - loss: 0.3314 - acc: 0.8500\n",
      "Epoch 39/160\n",
      "265/265 [==============================] - 0s 347us/step - loss: 0.3301 - acc: 0.8491\n",
      "Epoch 40/160\n",
      "265/265 [==============================] - 0s 390us/step - loss: 0.3360 - acc: 0.8425\n",
      "Epoch 41/160\n",
      "265/265 [==============================] - 0s 346us/step - loss: 0.3255 - acc: 0.8491\n",
      "Epoch 42/160\n",
      "265/265 [==============================] - 0s 361us/step - loss: 0.3340 - acc: 0.8500\n",
      "Epoch 43/160\n",
      "265/265 [==============================] - 0s 370us/step - loss: 0.3273 - acc: 0.8519\n",
      "Epoch 44/160\n",
      "265/265 [==============================] - 0s 343us/step - loss: 0.3336 - acc: 0.8509\n",
      "Epoch 45/160\n",
      "265/265 [==============================] - 0s 387us/step - loss: 0.3279 - acc: 0.8500\n",
      "Epoch 46/160\n",
      "265/265 [==============================] - 0s 336us/step - loss: 0.3330 - acc: 0.8509\n",
      "Epoch 47/160\n",
      "265/265 [==============================] - 0s 325us/step - loss: 0.3256 - acc: 0.8509\n",
      "Epoch 48/160\n",
      "265/265 [==============================] - 0s 399us/step - loss: 0.3215 - acc: 0.8528\n",
      "Epoch 49/160\n",
      "265/265 [==============================] - 0s 363us/step - loss: 0.3173 - acc: 0.8509\n",
      "Epoch 50/160\n",
      "265/265 [==============================] - 0s 386us/step - loss: 0.3218 - acc: 0.8566\n",
      "Epoch 51/160\n",
      "265/265 [==============================] - 0s 347us/step - loss: 0.3228 - acc: 0.8472\n",
      "Epoch 52/160\n",
      "265/265 [==============================] - 0s 339us/step - loss: 0.3470 - acc: 0.8434\n",
      "Epoch 53/160\n",
      "265/265 [==============================] - 0s 392us/step - loss: 0.3216 - acc: 0.8500\n",
      "Epoch 54/160\n",
      "265/265 [==============================] - 0s 350us/step - loss: 0.3328 - acc: 0.8481\n",
      "Epoch 55/160\n",
      "265/265 [==============================] - 0s 402us/step - loss: 0.3225 - acc: 0.8519 0s - loss: 0.3116 - acc: 0.856\n",
      "Epoch 56/160\n",
      "265/265 [==============================] - 0s 341us/step - loss: 0.3192 - acc: 0.8538\n",
      "Epoch 57/160\n",
      "265/265 [==============================] - 0s 344us/step - loss: 0.3114 - acc: 0.8462\n",
      "Epoch 58/160\n",
      "265/265 [==============================] - 0s 356us/step - loss: 0.3142 - acc: 0.8538\n",
      "Epoch 59/160\n",
      "265/265 [==============================] - 0s 330us/step - loss: 0.3239 - acc: 0.8538\n",
      "Epoch 60/160\n",
      "265/265 [==============================] - 0s 381us/step - loss: 0.3136 - acc: 0.8547\n",
      "Epoch 61/160\n",
      "265/265 [==============================] - 0s 370us/step - loss: 0.3199 - acc: 0.8491\n",
      "Epoch 62/160\n",
      "265/265 [==============================] - 0s 336us/step - loss: 0.3282 - acc: 0.8500\n",
      "Epoch 63/160\n",
      "265/265 [==============================] - 0s 366us/step - loss: 0.3089 - acc: 0.8575\n",
      "Epoch 64/160\n",
      "265/265 [==============================] - 0s 313us/step - loss: 0.3166 - acc: 0.8491\n",
      "Epoch 65/160\n",
      "265/265 [==============================] - 0s 380us/step - loss: 0.3106 - acc: 0.8528\n",
      "Epoch 66/160\n",
      "265/265 [==============================] - 0s 360us/step - loss: 0.3090 - acc: 0.8500\n",
      "Epoch 67/160\n",
      "265/265 [==============================] - 0s 365us/step - loss: 0.3139 - acc: 0.8566\n",
      "Epoch 68/160\n",
      "265/265 [==============================] - 0s 382us/step - loss: 0.3078 - acc: 0.8528\n",
      "Epoch 69/160\n",
      "265/265 [==============================] - 0s 339us/step - loss: 0.3212 - acc: 0.8547\n",
      "Epoch 70/160\n",
      "265/265 [==============================] - 0s 345us/step - loss: 0.3122 - acc: 0.8481\n",
      "Epoch 71/160\n",
      "265/265 [==============================] - 0s 387us/step - loss: 0.3105 - acc: 0.8557\n",
      "Epoch 72/160\n",
      "265/265 [==============================] - 0s 335us/step - loss: 0.3130 - acc: 0.8557\n",
      "Epoch 73/160\n",
      "265/265 [==============================] - 0s 408us/step - loss: 0.3004 - acc: 0.8575\n",
      "Epoch 74/160\n",
      "265/265 [==============================] - 0s 330us/step - loss: 0.3031 - acc: 0.8613\n",
      "Epoch 75/160\n",
      "265/265 [==============================] - 0s 341us/step - loss: 0.3008 - acc: 0.8575\n",
      "Epoch 76/160\n",
      "265/265 [==============================] - 0s 370us/step - loss: 0.3155 - acc: 0.8472\n",
      "Epoch 77/160\n",
      "265/265 [==============================] - 0s 344us/step - loss: 0.3053 - acc: 0.8528\n",
      "Epoch 78/160\n",
      "265/265 [==============================] - 0s 353us/step - loss: 0.3050 - acc: 0.8566\n",
      "Epoch 79/160\n",
      "265/265 [==============================] - 0s 346us/step - loss: 0.3026 - acc: 0.8509\n",
      "Epoch 80/160\n",
      "265/265 [==============================] - 0s 327us/step - loss: 0.3005 - acc: 0.8519\n",
      "Epoch 81/160\n",
      "265/265 [==============================] - 0s 401us/step - loss: 0.2958 - acc: 0.8604\n",
      "Epoch 82/160\n",
      "265/265 [==============================] - 0s 332us/step - loss: 0.3035 - acc: 0.8585\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265/265 [==============================] - 0s 315us/step - loss: 0.2988 - acc: 0.8604\n",
      "Epoch 84/160\n",
      "265/265 [==============================] - 0s 369us/step - loss: 0.3052 - acc: 0.8575\n",
      "Epoch 85/160\n",
      "265/265 [==============================] - 0s 343us/step - loss: 0.3012 - acc: 0.8509\n",
      "Epoch 86/160\n",
      "265/265 [==============================] - 0s 372us/step - loss: 0.2959 - acc: 0.8566\n",
      "Epoch 87/160\n",
      "265/265 [==============================] - 0s 480us/step - loss: 0.2991 - acc: 0.8670\n",
      "Epoch 88/160\n",
      "265/265 [==============================] - 0s 320us/step - loss: 0.3157 - acc: 0.8547\n",
      "Epoch 89/160\n",
      "265/265 [==============================] - 0s 375us/step - loss: 0.3005 - acc: 0.8670\n",
      "Epoch 90/160\n",
      "265/265 [==============================] - 0s 315us/step - loss: 0.2932 - acc: 0.8660\n",
      "Epoch 91/160\n",
      "265/265 [==============================] - 0s 369us/step - loss: 0.2964 - acc: 0.8566\n",
      "Epoch 92/160\n",
      "265/265 [==============================] - 0s 339us/step - loss: 0.3003 - acc: 0.8500\n",
      "Epoch 93/160\n",
      "265/265 [==============================] - 0s 365us/step - loss: 0.2907 - acc: 0.8547\n",
      "Epoch 94/160\n",
      "265/265 [==============================] - 0s 403us/step - loss: 0.2963 - acc: 0.8566\n",
      "Epoch 95/160\n",
      "265/265 [==============================] - 0s 354us/step - loss: 0.2902 - acc: 0.8660\n",
      "Epoch 96/160\n",
      "265/265 [==============================] - 0s 330us/step - loss: 0.2870 - acc: 0.8736\n",
      "Epoch 97/160\n",
      "265/265 [==============================] - 0s 353us/step - loss: 0.2963 - acc: 0.8538\n",
      "Epoch 98/160\n",
      "265/265 [==============================] - 0s 338us/step - loss: 0.3186 - acc: 0.8538\n",
      "Epoch 99/160\n",
      "265/265 [==============================] - 0s 356us/step - loss: 0.3054 - acc: 0.8557\n",
      "Epoch 100/160\n",
      "265/265 [==============================] - 0s 310us/step - loss: 0.3162 - acc: 0.8566\n",
      "Epoch 101/160\n",
      "265/265 [==============================] - 0s 349us/step - loss: 0.3106 - acc: 0.8462\n",
      "Epoch 102/160\n",
      "265/265 [==============================] - 0s 391us/step - loss: 0.2991 - acc: 0.8566\n",
      "Epoch 103/160\n",
      "265/265 [==============================] - 0s 354us/step - loss: 0.2962 - acc: 0.8604\n",
      "Epoch 104/160\n",
      "265/265 [==============================] - 0s 339us/step - loss: 0.2920 - acc: 0.8623\n",
      "Epoch 105/160\n",
      "265/265 [==============================] - 0s 412us/step - loss: 0.2844 - acc: 0.8689\n",
      "Epoch 106/160\n",
      "265/265 [==============================] - 0s 346us/step - loss: 0.2895 - acc: 0.8642\n",
      "Epoch 107/160\n",
      "265/265 [==============================] - 0s 360us/step - loss: 0.2963 - acc: 0.8632\n",
      "Epoch 108/160\n",
      "265/265 [==============================] - 0s 338us/step - loss: 0.2896 - acc: 0.8698\n",
      "Epoch 109/160\n",
      "265/265 [==============================] - 0s 320us/step - loss: 0.2905 - acc: 0.8594\n",
      "Epoch 110/160\n",
      "265/265 [==============================] - 0s 329us/step - loss: 0.3025 - acc: 0.8557\n",
      "Epoch 111/160\n",
      "265/265 [==============================] - 0s 369us/step - loss: 0.3036 - acc: 0.8604\n",
      "Epoch 112/160\n",
      "265/265 [==============================] - 0s 354us/step - loss: 0.2973 - acc: 0.8594\n",
      "Epoch 113/160\n",
      "265/265 [==============================] - 0s 341us/step - loss: 0.2850 - acc: 0.8764\n",
      "Epoch 114/160\n",
      "265/265 [==============================] - 0s 325us/step - loss: 0.2846 - acc: 0.8679\n",
      "Epoch 115/160\n",
      "265/265 [==============================] - 0s 359us/step - loss: 0.2904 - acc: 0.8604\n",
      "Epoch 116/160\n",
      "265/265 [==============================] - 0s 347us/step - loss: 0.2817 - acc: 0.8745\n",
      "Epoch 117/160\n",
      "265/265 [==============================] - 0s 373us/step - loss: 0.2902 - acc: 0.8717\n",
      "Epoch 118/160\n",
      "265/265 [==============================] - 0s 371us/step - loss: 0.2940 - acc: 0.8670\n",
      "Epoch 119/160\n",
      "265/265 [==============================] - 0s 306us/step - loss: 0.3183 - acc: 0.8613\n",
      "Epoch 120/160\n",
      "265/265 [==============================] - 0s 327us/step - loss: 0.3056 - acc: 0.8604\n",
      "Epoch 121/160\n",
      "265/265 [==============================] - 0s 391us/step - loss: 0.2897 - acc: 0.8717\n",
      "Epoch 122/160\n",
      "265/265 [==============================] - 0s 360us/step - loss: 0.2861 - acc: 0.8642\n",
      "Epoch 123/160\n",
      "265/265 [==============================] - 0s 423us/step - loss: 0.2857 - acc: 0.8594\n",
      "Epoch 124/160\n",
      "265/265 [==============================] - 0s 392us/step - loss: 0.2850 - acc: 0.8500\n",
      "Epoch 125/160\n",
      "265/265 [==============================] - 0s 363us/step - loss: 0.2709 - acc: 0.8783\n",
      "Epoch 126/160\n",
      "265/265 [==============================] - 0s 433us/step - loss: 0.2807 - acc: 0.8679\n",
      "Epoch 127/160\n",
      "265/265 [==============================] - 0s 455us/step - loss: 0.2731 - acc: 0.8726\n",
      "Epoch 128/160\n",
      "265/265 [==============================] - 0s 336us/step - loss: 0.2750 - acc: 0.8736\n",
      "Epoch 129/160\n",
      "265/265 [==============================] - 0s 385us/step - loss: 0.2820 - acc: 0.8708\n",
      "Epoch 130/160\n",
      "265/265 [==============================] - 0s 367us/step - loss: 0.2681 - acc: 0.8887\n",
      "Epoch 131/160\n",
      "265/265 [==============================] - 0s 357us/step - loss: 0.2788 - acc: 0.8755\n",
      "Epoch 132/160\n",
      "265/265 [==============================] - 0s 382us/step - loss: 0.2696 - acc: 0.8726\n",
      "Epoch 133/160\n",
      "265/265 [==============================] - 0s 374us/step - loss: 0.2824 - acc: 0.8726\n",
      "Epoch 134/160\n",
      "265/265 [==============================] - 0s 356us/step - loss: 0.2762 - acc: 0.8774\n",
      "Epoch 135/160\n",
      "265/265 [==============================] - 0s 395us/step - loss: 0.2746 - acc: 0.8736\n",
      "Epoch 136/160\n",
      "265/265 [==============================] - 0s 317us/step - loss: 0.2898 - acc: 0.8783\n",
      "Epoch 137/160\n",
      "265/265 [==============================] - 0s 378us/step - loss: 0.2777 - acc: 0.8679\n",
      "Epoch 138/160\n",
      "265/265 [==============================] - 0s 397us/step - loss: 0.2738 - acc: 0.8774\n",
      "Epoch 139/160\n",
      "265/265 [==============================] - 0s 337us/step - loss: 0.2887 - acc: 0.8736\n",
      "Epoch 140/160\n",
      "265/265 [==============================] - 0s 396us/step - loss: 0.2965 - acc: 0.8632\n",
      "Epoch 141/160\n",
      "265/265 [==============================] - 0s 353us/step - loss: 0.2982 - acc: 0.8623\n",
      "Epoch 142/160\n",
      "265/265 [==============================] - 0s 336us/step - loss: 0.2860 - acc: 0.8755\n",
      "Epoch 143/160\n",
      "265/265 [==============================] - 0s 366us/step - loss: 0.2874 - acc: 0.8764\n",
      "Epoch 144/160\n",
      "265/265 [==============================] - 0s 398us/step - loss: 0.2810 - acc: 0.8755\n",
      "Epoch 145/160\n",
      "265/265 [==============================] - 0s 431us/step - loss: 0.2706 - acc: 0.8849\n",
      "Epoch 146/160\n",
      "265/265 [==============================] - 0s 383us/step - loss: 0.2712 - acc: 0.8792\n",
      "Epoch 147/160\n",
      "265/265 [==============================] - 0s 392us/step - loss: 0.2701 - acc: 0.8717\n",
      "Epoch 148/160\n",
      "265/265 [==============================] - 0s 405us/step - loss: 0.2672 - acc: 0.8755\n",
      "Epoch 149/160\n",
      "265/265 [==============================] - 0s 327us/step - loss: 0.2741 - acc: 0.8755\n",
      "Epoch 150/160\n",
      "265/265 [==============================] - 0s 366us/step - loss: 0.2692 - acc: 0.8792\n",
      "Epoch 151/160\n",
      "265/265 [==============================] - 0s 331us/step - loss: 0.2583 - acc: 0.8783\n",
      "Epoch 152/160\n",
      "265/265 [==============================] - 0s 363us/step - loss: 0.2689 - acc: 0.8792\n",
      "Epoch 153/160\n",
      "265/265 [==============================] - 0s 364us/step - loss: 0.2772 - acc: 0.8642\n",
      "Epoch 154/160\n",
      "265/265 [==============================] - 0s 309us/step - loss: 0.2692 - acc: 0.8783\n",
      "Epoch 155/160\n",
      "265/265 [==============================] - 0s 348us/step - loss: 0.2616 - acc: 0.8830\n",
      "Epoch 156/160\n",
      "265/265 [==============================] - 0s 356us/step - loss: 0.2581 - acc: 0.8821\n",
      "Epoch 157/160\n",
      "265/265 [==============================] - 0s 349us/step - loss: 0.2721 - acc: 0.8811\n",
      "Epoch 158/160\n",
      "265/265 [==============================] - 0s 339us/step - loss: 0.2681 - acc: 0.8764\n",
      "Epoch 159/160\n",
      "265/265 [==============================] - 0s 346us/step - loss: 0.2618 - acc: 0.8887\n",
      "Epoch 160/160\n",
      "265/265 [==============================] - 0s 382us/step - loss: 0.2631 - acc: 0.8840\n",
      "67/67 [==============================] - 0s 5ms/step\n",
      "265/265 [==============================] - 0s 102us/step\n",
      "\n",
      "acc: 82.09%\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "[[ 7  7  0  1]\n",
      " [ 4 38  0  0]\n",
      " [ 0  0  7  0]\n",
      " [ 0  1  0  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.64      0.47      0.54        15\n",
      "      Normal       0.83      0.90      0.86        42\n",
      "        Slow       1.00      1.00      1.00         7\n",
      "   Very Fast       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.81        67\n",
      "   macro avg       0.78      0.76      0.77        67\n",
      "weighted avg       0.79      0.81      0.80        67\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8059701492537313"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='market') & (df_k.Timelevel==1)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: market and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "633/633 [==============================] - 2s 4ms/step - loss: 0.4661 - acc: 0.7911\n",
      "Epoch 2/160\n",
      "633/633 [==============================] - 0s 323us/step - loss: 0.3907 - acc: 0.8152\n",
      "Epoch 3/160\n",
      "633/633 [==============================] - 0s 330us/step - loss: 0.3720 - acc: 0.8298\n",
      "Epoch 4/160\n",
      "633/633 [==============================] - 0s 417us/step - loss: 0.3767 - acc: 0.8274\n",
      "Epoch 5/160\n",
      "633/633 [==============================] - 0s 418us/step - loss: 0.3616 - acc: 0.8258\n",
      "Epoch 6/160\n",
      "633/633 [==============================] - 0s 390us/step - loss: 0.3631 - acc: 0.8298\n",
      "Epoch 7/160\n",
      "633/633 [==============================] - 0s 335us/step - loss: 0.3536 - acc: 0.8420\n",
      "Epoch 8/160\n",
      "633/633 [==============================] - 0s 355us/step - loss: 0.3529 - acc: 0.8381\n",
      "Epoch 9/160\n",
      "633/633 [==============================] - 0s 330us/step - loss: 0.3501 - acc: 0.8408\n",
      "Epoch 10/160\n",
      "633/633 [==============================] - 0s 336us/step - loss: 0.3502 - acc: 0.8353\n",
      "Epoch 11/160\n",
      "633/633 [==============================] - 0s 352us/step - loss: 0.3467 - acc: 0.8424\n",
      "Epoch 12/160\n",
      "633/633 [==============================] - 0s 331us/step - loss: 0.3418 - acc: 0.8452\n",
      "Epoch 13/160\n",
      "633/633 [==============================] - 0s 348us/step - loss: 0.3345 - acc: 0.8503\n",
      "Epoch 14/160\n",
      "633/633 [==============================] - 0s 344us/step - loss: 0.3451 - acc: 0.8416\n",
      "Epoch 15/160\n",
      "633/633 [==============================] - 0s 349us/step - loss: 0.3398 - acc: 0.8452\n",
      "Epoch 16/160\n",
      "633/633 [==============================] - 0s 381us/step - loss: 0.3401 - acc: 0.8448\n",
      "Epoch 17/160\n",
      "633/633 [==============================] - 0s 363us/step - loss: 0.3321 - acc: 0.8432\n",
      "Epoch 18/160\n",
      "633/633 [==============================] - 0s 341us/step - loss: 0.3432 - acc: 0.8491\n",
      "Epoch 19/160\n",
      "633/633 [==============================] - 0s 351us/step - loss: 0.3294 - acc: 0.8523\n",
      "Epoch 20/160\n",
      "633/633 [==============================] - 0s 336us/step - loss: 0.3259 - acc: 0.8515\n",
      "Epoch 21/160\n",
      "633/633 [==============================] - 0s 376us/step - loss: 0.3250 - acc: 0.8507\n",
      "Epoch 22/160\n",
      "633/633 [==============================] - 0s 351us/step - loss: 0.3197 - acc: 0.8543\n",
      "Epoch 23/160\n",
      "633/633 [==============================] - 0s 345us/step - loss: 0.3246 - acc: 0.8503\n",
      "Epoch 24/160\n",
      "633/633 [==============================] - 0s 421us/step - loss: 0.3244 - acc: 0.8495\n",
      "Epoch 25/160\n",
      "633/633 [==============================] - 0s 366us/step - loss: 0.3209 - acc: 0.8566\n",
      "Epoch 26/160\n",
      "633/633 [==============================] - 0s 371us/step - loss: 0.3186 - acc: 0.8539\n",
      "Epoch 27/160\n",
      "633/633 [==============================] - 0s 362us/step - loss: 0.3135 - acc: 0.8610\n",
      "Epoch 28/160\n",
      "633/633 [==============================] - 0s 355us/step - loss: 0.3171 - acc: 0.8590\n",
      "Epoch 29/160\n",
      "633/633 [==============================] - 0s 338us/step - loss: 0.3280 - acc: 0.8558\n",
      "Epoch 30/160\n",
      "633/633 [==============================] - 0s 337us/step - loss: 0.3190 - acc: 0.8495\n",
      "Epoch 31/160\n",
      "633/633 [==============================] - 0s 342us/step - loss: 0.3123 - acc: 0.8539\n",
      "Epoch 32/160\n",
      "633/633 [==============================] - 0s 449us/step - loss: 0.3193 - acc: 0.8468\n",
      "Epoch 33/160\n",
      "633/633 [==============================] - 0s 427us/step - loss: 0.3185 - acc: 0.8570\n",
      "Epoch 34/160\n",
      "633/633 [==============================] - 0s 363us/step - loss: 0.3211 - acc: 0.8511\n",
      "Epoch 35/160\n",
      "633/633 [==============================] - 0s 407us/step - loss: 0.3141 - acc: 0.8574\n",
      "Epoch 36/160\n",
      "633/633 [==============================] - 0s 401us/step - loss: 0.3126 - acc: 0.8574\n",
      "Epoch 37/160\n",
      "633/633 [==============================] - 0s 417us/step - loss: 0.2962 - acc: 0.8673\n",
      "Epoch 38/160\n",
      "633/633 [==============================] - 0s 452us/step - loss: 0.3033 - acc: 0.8626\n",
      "Epoch 39/160\n",
      "633/633 [==============================] - 0s 393us/step - loss: 0.3026 - acc: 0.8677\n",
      "Epoch 40/160\n",
      "633/633 [==============================] - 0s 351us/step - loss: 0.3124 - acc: 0.8582\n",
      "Epoch 41/160\n",
      "633/633 [==============================] - 0s 380us/step - loss: 0.3078 - acc: 0.8633\n",
      "Epoch 42/160\n",
      "633/633 [==============================] - 0s 344us/step - loss: 0.3036 - acc: 0.8653\n",
      "Epoch 43/160\n",
      "633/633 [==============================] - 0s 462us/step - loss: 0.3102 - acc: 0.8586\n",
      "Epoch 44/160\n",
      "633/633 [==============================] - 0s 381us/step - loss: 0.3004 - acc: 0.8626\n",
      "Epoch 45/160\n",
      "633/633 [==============================] - 0s 358us/step - loss: 0.2969 - acc: 0.8697\n",
      "Epoch 46/160\n",
      "633/633 [==============================] - 0s 367us/step - loss: 0.3017 - acc: 0.8622\n",
      "Epoch 47/160\n",
      "633/633 [==============================] - 0s 373us/step - loss: 0.3000 - acc: 0.8618\n",
      "Epoch 48/160\n",
      "633/633 [==============================] - 0s 368us/step - loss: 0.2985 - acc: 0.8622\n",
      "Epoch 49/160\n",
      "633/633 [==============================] - 0s 365us/step - loss: 0.2985 - acc: 0.8649\n",
      "Epoch 50/160\n",
      "633/633 [==============================] - 0s 369us/step - loss: 0.2934 - acc: 0.8645\n",
      "Epoch 51/160\n",
      "633/633 [==============================] - 0s 407us/step - loss: 0.2976 - acc: 0.8657\n",
      "Epoch 52/160\n",
      "633/633 [==============================] - 0s 414us/step - loss: 0.2889 - acc: 0.8681\n",
      "Epoch 53/160\n",
      "633/633 [==============================] - 0s 353us/step - loss: 0.2959 - acc: 0.8633\n",
      "Epoch 54/160\n",
      "633/633 [==============================] - 0s 361us/step - loss: 0.2883 - acc: 0.8689\n",
      "Epoch 55/160\n",
      "633/633 [==============================] - 0s 341us/step - loss: 0.2940 - acc: 0.8673\n",
      "Epoch 56/160\n",
      "633/633 [==============================] - 0s 363us/step - loss: 0.2933 - acc: 0.8657\n",
      "Epoch 57/160\n",
      "633/633 [==============================] - 0s 421us/step - loss: 0.2989 - acc: 0.8633\n",
      "Epoch 58/160\n",
      "633/633 [==============================] - 0s 355us/step - loss: 0.2931 - acc: 0.8697\n",
      "Epoch 59/160\n",
      "633/633 [==============================] - 0s 375us/step - loss: 0.2993 - acc: 0.8633\n",
      "Epoch 60/160\n",
      "633/633 [==============================] - 0s 344us/step - loss: 0.2849 - acc: 0.8705\n",
      "Epoch 61/160\n",
      "633/633 [==============================] - 0s 384us/step - loss: 0.2870 - acc: 0.8697\n",
      "Epoch 62/160\n",
      "633/633 [==============================] - 0s 358us/step - loss: 0.2884 - acc: 0.8693\n",
      "Epoch 63/160\n",
      "633/633 [==============================] - 0s 367us/step - loss: 0.2875 - acc: 0.8657\n",
      "Epoch 64/160\n",
      "633/633 [==============================] - 0s 362us/step - loss: 0.2910 - acc: 0.8677\n",
      "Epoch 65/160\n",
      "633/633 [==============================] - 0s 351us/step - loss: 0.2855 - acc: 0.8728\n",
      "Epoch 66/160\n",
      "633/633 [==============================] - 0s 363us/step - loss: 0.2823 - acc: 0.8772\n",
      "Epoch 67/160\n",
      "633/633 [==============================] - 0s 360us/step - loss: 0.2858 - acc: 0.8705\n",
      "Epoch 68/160\n",
      "633/633 [==============================] - 0s 361us/step - loss: 0.2907 - acc: 0.8685\n",
      "Epoch 69/160\n",
      "633/633 [==============================] - 0s 367us/step - loss: 0.2879 - acc: 0.8677\n",
      "Epoch 70/160\n",
      "633/633 [==============================] - 0s 352us/step - loss: 0.2840 - acc: 0.8649\n",
      "Epoch 71/160\n",
      "633/633 [==============================] - 0s 340us/step - loss: 0.2942 - acc: 0.8614\n",
      "Epoch 72/160\n",
      "633/633 [==============================] - 0s 386us/step - loss: 0.2857 - acc: 0.8709\n",
      "Epoch 73/160\n",
      "633/633 [==============================] - 0s 345us/step - loss: 0.2857 - acc: 0.8685\n",
      "Epoch 74/160\n",
      "633/633 [==============================] - 0s 357us/step - loss: 0.2780 - acc: 0.8740\n",
      "Epoch 75/160\n",
      "633/633 [==============================] - 0s 370us/step - loss: 0.3080 - acc: 0.8610\n",
      "Epoch 76/160\n",
      "633/633 [==============================] - 0s 371us/step - loss: 0.2870 - acc: 0.8732\n",
      "Epoch 77/160\n",
      "633/633 [==============================] - 0s 411us/step - loss: 0.2882 - acc: 0.8689\n",
      "Epoch 78/160\n",
      "633/633 [==============================] - 0s 521us/step - loss: 0.2824 - acc: 0.8685\n",
      "Epoch 79/160\n",
      "633/633 [==============================] - 0s 412us/step - loss: 0.2876 - acc: 0.8677\n",
      "Epoch 80/160\n",
      "633/633 [==============================] - 0s 415us/step - loss: 0.2725 - acc: 0.8764\n",
      "Epoch 81/160\n",
      "633/633 [==============================] - 0s 408us/step - loss: 0.2760 - acc: 0.8788\n",
      "Epoch 82/160\n",
      "633/633 [==============================] - 0s 414us/step - loss: 0.2740 - acc: 0.8772\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - 0s 372us/step - loss: 0.2792 - acc: 0.8661\n",
      "Epoch 84/160\n",
      "633/633 [==============================] - 0s 326us/step - loss: 0.2846 - acc: 0.8748\n",
      "Epoch 85/160\n",
      "633/633 [==============================] - 0s 364us/step - loss: 0.2721 - acc: 0.8697\n",
      "Epoch 86/160\n",
      "633/633 [==============================] - 0s 391us/step - loss: 0.2761 - acc: 0.8756\n",
      "Epoch 87/160\n",
      "633/633 [==============================] - 0s 439us/step - loss: 0.2756 - acc: 0.8689\n",
      "Epoch 88/160\n",
      "633/633 [==============================] - 0s 400us/step - loss: 0.2797 - acc: 0.8693\n",
      "Epoch 89/160\n",
      "633/633 [==============================] - 0s 365us/step - loss: 0.2678 - acc: 0.8776\n",
      "Epoch 90/160\n",
      "633/633 [==============================] - 0s 357us/step - loss: 0.2686 - acc: 0.8752\n",
      "Epoch 91/160\n",
      "633/633 [==============================] - 0s 347us/step - loss: 0.2724 - acc: 0.8712\n",
      "Epoch 92/160\n",
      "633/633 [==============================] - 0s 352us/step - loss: 0.2728 - acc: 0.8748\n",
      "Epoch 93/160\n",
      "633/633 [==============================] - 0s 339us/step - loss: 0.2780 - acc: 0.8736\n",
      "Epoch 94/160\n",
      "633/633 [==============================] - 0s 354us/step - loss: 0.2657 - acc: 0.8760\n",
      "Epoch 95/160\n",
      "633/633 [==============================] - 0s 422us/step - loss: 0.2726 - acc: 0.8736\n",
      "Epoch 96/160\n",
      "633/633 [==============================] - 0s 504us/step - loss: 0.2645 - acc: 0.8776\n",
      "Epoch 97/160\n",
      "633/633 [==============================] - 0s 399us/step - loss: 0.2799 - acc: 0.8732\n",
      "Epoch 98/160\n",
      "633/633 [==============================] - 0s 346us/step - loss: 0.2718 - acc: 0.8764\n",
      "Epoch 99/160\n",
      "633/633 [==============================] - 0s 383us/step - loss: 0.2662 - acc: 0.8776\n",
      "Epoch 100/160\n",
      "633/633 [==============================] - 0s 371us/step - loss: 0.2571 - acc: 0.8772\n",
      "Epoch 101/160\n",
      "633/633 [==============================] - 0s 347us/step - loss: 0.2621 - acc: 0.8760\n",
      "Epoch 102/160\n",
      "633/633 [==============================] - 0s 326us/step - loss: 0.2530 - acc: 0.8835\n",
      "Epoch 103/160\n",
      "633/633 [==============================] - 0s 345us/step - loss: 0.2711 - acc: 0.8760\n",
      "Epoch 104/160\n",
      "633/633 [==============================] - 0s 352us/step - loss: 0.2601 - acc: 0.8795\n",
      "Epoch 105/160\n",
      "633/633 [==============================] - 0s 435us/step - loss: 0.2578 - acc: 0.8795\n",
      "Epoch 106/160\n",
      "633/633 [==============================] - 0s 389us/step - loss: 0.2624 - acc: 0.8807\n",
      "Epoch 107/160\n",
      "633/633 [==============================] - 0s 450us/step - loss: 0.2691 - acc: 0.8780\n",
      "Epoch 108/160\n",
      "633/633 [==============================] - 0s 362us/step - loss: 0.2789 - acc: 0.8681\n",
      "Epoch 109/160\n",
      "633/633 [==============================] - 0s 334us/step - loss: 0.2729 - acc: 0.8705\n",
      "Epoch 110/160\n",
      "633/633 [==============================] - 0s 351us/step - loss: 0.2601 - acc: 0.8795\n",
      "Epoch 111/160\n",
      "633/633 [==============================] - 0s 337us/step - loss: 0.2491 - acc: 0.8823\n",
      "Epoch 112/160\n",
      "633/633 [==============================] - 0s 335us/step - loss: 0.2535 - acc: 0.8752\n",
      "Epoch 113/160\n",
      "633/633 [==============================] - 0s 363us/step - loss: 0.2558 - acc: 0.8819\n",
      "Epoch 114/160\n",
      "633/633 [==============================] - 0s 433us/step - loss: 0.2522 - acc: 0.8874\n",
      "Epoch 115/160\n",
      "633/633 [==============================] - 0s 437us/step - loss: 0.2496 - acc: 0.8788\n",
      "Epoch 116/160\n",
      "633/633 [==============================] - 0s 357us/step - loss: 0.2503 - acc: 0.8878\n",
      "Epoch 117/160\n",
      "633/633 [==============================] - 0s 338us/step - loss: 0.2584 - acc: 0.8768\n",
      "Epoch 118/160\n",
      "633/633 [==============================] - 0s 370us/step - loss: 0.2533 - acc: 0.8835\n",
      "Epoch 119/160\n",
      "633/633 [==============================] - 0s 325us/step - loss: 0.2604 - acc: 0.8835\n",
      "Epoch 120/160\n",
      "633/633 [==============================] - 0s 406us/step - loss: 0.2523 - acc: 0.8799\n",
      "Epoch 121/160\n",
      "633/633 [==============================] - 0s 405us/step - loss: 0.2455 - acc: 0.8859\n",
      "Epoch 122/160\n",
      "633/633 [==============================] - 0s 405us/step - loss: 0.2489 - acc: 0.8855\n",
      "Epoch 123/160\n",
      "633/633 [==============================] - 0s 400us/step - loss: 0.2468 - acc: 0.8859\n",
      "Epoch 124/160\n",
      "633/633 [==============================] - 0s 363us/step - loss: 0.2457 - acc: 0.8898\n",
      "Epoch 125/160\n",
      "633/633 [==============================] - 0s 344us/step - loss: 0.2421 - acc: 0.8819\n",
      "Epoch 126/160\n",
      "633/633 [==============================] - 0s 351us/step - loss: 0.2422 - acc: 0.8890\n",
      "Epoch 127/160\n",
      "633/633 [==============================] - 0s 316us/step - loss: 0.2497 - acc: 0.8851\n",
      "Epoch 128/160\n",
      "633/633 [==============================] - 0s 348us/step - loss: 0.2464 - acc: 0.8795\n",
      "Epoch 129/160\n",
      "633/633 [==============================] - 0s 342us/step - loss: 0.2399 - acc: 0.8874\n",
      "Epoch 130/160\n",
      "633/633 [==============================] - 0s 363us/step - loss: 0.2603 - acc: 0.8823\n",
      "Epoch 131/160\n",
      "633/633 [==============================] - 0s 369us/step - loss: 0.2627 - acc: 0.8791\n",
      "Epoch 132/160\n",
      "633/633 [==============================] - 0s 376us/step - loss: 0.2668 - acc: 0.8768\n",
      "Epoch 133/160\n",
      "633/633 [==============================] - 0s 384us/step - loss: 0.2444 - acc: 0.8839\n",
      "Epoch 134/160\n",
      "633/633 [==============================] - 0s 323us/step - loss: 0.2472 - acc: 0.8839\n",
      "Epoch 135/160\n",
      "633/633 [==============================] - 0s 346us/step - loss: 0.2483 - acc: 0.8819\n",
      "Epoch 136/160\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2417 - acc: 0.884 - 0s 319us/step - loss: 0.2471 - acc: 0.8764\n",
      "Epoch 137/160\n",
      "633/633 [==============================] - 0s 329us/step - loss: 0.2482 - acc: 0.8819\n",
      "Epoch 138/160\n",
      "633/633 [==============================] - 0s 426us/step - loss: 0.2307 - acc: 0.8898\n",
      "Epoch 139/160\n",
      "633/633 [==============================] - 0s 376us/step - loss: 0.2386 - acc: 0.8847\n",
      "Epoch 140/160\n",
      "633/633 [==============================] - 0s 370us/step - loss: 0.2329 - acc: 0.8906\n",
      "Epoch 141/160\n",
      "633/633 [==============================] - 0s 352us/step - loss: 0.2524 - acc: 0.8839\n",
      "Epoch 142/160\n",
      "633/633 [==============================] - 0s 370us/step - loss: 0.2336 - acc: 0.8890\n",
      "Epoch 143/160\n",
      "633/633 [==============================] - 0s 346us/step - loss: 0.2460 - acc: 0.8795\n",
      "Epoch 144/160\n",
      "633/633 [==============================] - 0s 373us/step - loss: 0.2391 - acc: 0.8867\n",
      "Epoch 145/160\n",
      "633/633 [==============================] - 0s 357us/step - loss: 0.2417 - acc: 0.8811\n",
      "Epoch 146/160\n",
      "633/633 [==============================] - 0s 388us/step - loss: 0.2425 - acc: 0.8855\n",
      "Epoch 147/160\n",
      "633/633 [==============================] - 0s 417us/step - loss: 0.2349 - acc: 0.8847\n",
      "Epoch 148/160\n",
      "633/633 [==============================] - 0s 425us/step - loss: 0.2311 - acc: 0.8874\n",
      "Epoch 149/160\n",
      "633/633 [==============================] - 0s 330us/step - loss: 0.2374 - acc: 0.8819\n",
      "Epoch 150/160\n",
      "633/633 [==============================] - 0s 365us/step - loss: 0.2231 - acc: 0.8851\n",
      "Epoch 151/160\n",
      "633/633 [==============================] - 0s 334us/step - loss: 0.2339 - acc: 0.8945\n",
      "Epoch 152/160\n",
      "633/633 [==============================] - 0s 326us/step - loss: 0.2619 - acc: 0.8819\n",
      "Epoch 153/160\n",
      "633/633 [==============================] - 0s 332us/step - loss: 0.2502 - acc: 0.8859\n",
      "Epoch 154/160\n",
      "633/633 [==============================] - 0s 344us/step - loss: 0.2407 - acc: 0.8894\n",
      "Epoch 155/160\n",
      "633/633 [==============================] - 0s 342us/step - loss: 0.2456 - acc: 0.8788\n",
      "Epoch 156/160\n",
      "633/633 [==============================] - 0s 339us/step - loss: 0.2380 - acc: 0.8878\n",
      "Epoch 157/160\n",
      "633/633 [==============================] - 0s 353us/step - loss: 0.2423 - acc: 0.8807\n",
      "Epoch 158/160\n",
      "633/633 [==============================] - 0s 370us/step - loss: 0.2326 - acc: 0.8906\n",
      "Epoch 159/160\n",
      "633/633 [==============================] - 0s 364us/step - loss: 0.2223 - acc: 0.8874\n",
      "Epoch 160/160\n",
      "633/633 [==============================] - 0s 325us/step - loss: 0.2189 - acc: 0.8949\n",
      "633/633 [==============================] - 1s 1ms/step\n",
      "\n",
      "acc: 89.10%\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "0 0 0 1\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[23 12  0  1]\n",
      " [ 4 86  3  0]\n",
      " [ 3  6 21  0]\n",
      " [ 0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       0.77      0.64      0.70        36\n",
      "      Normal       0.83      0.92      0.87        93\n",
      "        Slow       0.88      0.70      0.78        30\n",
      "   Very Fast       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82       159\n",
      "   macro avg       0.62      0.57      0.59       159\n",
      "weighted avg       0.82      0.82      0.82       159\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijit/.local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8176100628930818"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='market') & (df_k.Timelevel==2)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        #if y_test_2.iloc[j][3]==1:\n",
    "         #   y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: market and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "675/675 [==============================] - 4s 5ms/step - loss: 0.4866 - acc: 0.7985\n",
      "Epoch 2/160\n",
      "675/675 [==============================] - 0s 402us/step - loss: 0.4364 - acc: 0.8267\n",
      "Epoch 3/160\n",
      "675/675 [==============================] - 0s 401us/step - loss: 0.4170 - acc: 0.8262\n",
      "Epoch 4/160\n",
      "675/675 [==============================] - 0s 377us/step - loss: 0.4274 - acc: 0.8247\n",
      "Epoch 5/160\n",
      "675/675 [==============================] - 0s 378us/step - loss: 0.4049 - acc: 0.8306\n",
      "Epoch 6/160\n",
      "675/675 [==============================] - 0s 386us/step - loss: 0.4030 - acc: 0.8277\n",
      "Epoch 7/160\n",
      "675/675 [==============================] - 0s 375us/step - loss: 0.4031 - acc: 0.8242\n",
      "Epoch 8/160\n",
      "675/675 [==============================] - 0s 358us/step - loss: 0.4212 - acc: 0.8321\n",
      "Epoch 9/160\n",
      "675/675 [==============================] - 0s 353us/step - loss: 0.3922 - acc: 0.8331\n",
      "Epoch 10/160\n",
      "675/675 [==============================] - 0s 389us/step - loss: 0.3977 - acc: 0.8331\n",
      "Epoch 11/160\n",
      "675/675 [==============================] - 0s 373us/step - loss: 0.4002 - acc: 0.8296\n",
      "Epoch 12/160\n",
      "675/675 [==============================] - 0s 395us/step - loss: 0.3997 - acc: 0.8242\n",
      "Epoch 13/160\n",
      "675/675 [==============================] - 0s 390us/step - loss: 0.4005 - acc: 0.8360\n",
      "Epoch 14/160\n",
      "675/675 [==============================] - 0s 365us/step - loss: 0.3931 - acc: 0.8286\n",
      "Epoch 15/160\n",
      "675/675 [==============================] - 0s 346us/step - loss: 0.3888 - acc: 0.8301\n",
      "Epoch 16/160\n",
      "675/675 [==============================] - 0s 376us/step - loss: 0.3975 - acc: 0.8281\n",
      "Epoch 17/160\n",
      "675/675 [==============================] - 0s 343us/step - loss: 0.3928 - acc: 0.8395\n",
      "Epoch 18/160\n",
      "675/675 [==============================] - 0s 341us/step - loss: 0.3897 - acc: 0.8464\n",
      "Epoch 19/160\n",
      "675/675 [==============================] - 0s 376us/step - loss: 0.3972 - acc: 0.8405\n",
      "Epoch 20/160\n",
      "675/675 [==============================] - 0s 390us/step - loss: 0.3807 - acc: 0.8405\n",
      "Epoch 21/160\n",
      "675/675 [==============================] - 0s 393us/step - loss: 0.3898 - acc: 0.8425\n",
      "Epoch 22/160\n",
      "675/675 [==============================] - 0s 363us/step - loss: 0.3836 - acc: 0.8415\n",
      "Epoch 23/160\n",
      "675/675 [==============================] - 0s 375us/step - loss: 0.3796 - acc: 0.8444\n",
      "Epoch 24/160\n",
      "675/675 [==============================] - 0s 396us/step - loss: 0.3708 - acc: 0.8494\n",
      "Epoch 25/160\n",
      "675/675 [==============================] - 0s 385us/step - loss: 0.3723 - acc: 0.8464\n",
      "Epoch 26/160\n",
      "675/675 [==============================] - 0s 379us/step - loss: 0.3902 - acc: 0.8420\n",
      "Epoch 27/160\n",
      "675/675 [==============================] - 0s 396us/step - loss: 0.3771 - acc: 0.8360\n",
      "Epoch 28/160\n",
      "675/675 [==============================] - 0s 428us/step - loss: 0.3750 - acc: 0.8375\n",
      "Epoch 29/160\n",
      "675/675 [==============================] - 0s 430us/step - loss: 0.3671 - acc: 0.8444\n",
      "Epoch 30/160\n",
      "675/675 [==============================] - 0s 366us/step - loss: 0.3676 - acc: 0.8454\n",
      "Epoch 31/160\n",
      "675/675 [==============================] - 0s 370us/step - loss: 0.3653 - acc: 0.8494\n",
      "Epoch 32/160\n",
      "675/675 [==============================] - 0s 346us/step - loss: 0.3764 - acc: 0.8430\n",
      "Epoch 33/160\n",
      "675/675 [==============================] - 0s 324us/step - loss: 0.3793 - acc: 0.8449\n",
      "Epoch 34/160\n",
      "675/675 [==============================] - 0s 332us/step - loss: 0.3558 - acc: 0.8578\n",
      "Epoch 35/160\n",
      "675/675 [==============================] - 0s 326us/step - loss: 0.3610 - acc: 0.8514\n",
      "Epoch 36/160\n",
      "675/675 [==============================] - 0s 327us/step - loss: 0.3750 - acc: 0.8365\n",
      "Epoch 37/160\n",
      "675/675 [==============================] - 0s 335us/step - loss: 0.3598 - acc: 0.8528\n",
      "Epoch 38/160\n",
      "675/675 [==============================] - 0s 328us/step - loss: 0.3653 - acc: 0.8459\n",
      "Epoch 39/160\n",
      "675/675 [==============================] - 0s 344us/step - loss: 0.3616 - acc: 0.8469\n",
      "Epoch 40/160\n",
      "675/675 [==============================] - 0s 341us/step - loss: 0.3694 - acc: 0.8479\n",
      "Epoch 41/160\n",
      "675/675 [==============================] - 0s 332us/step - loss: 0.3687 - acc: 0.8405\n",
      "Epoch 42/160\n",
      "675/675 [==============================] - 0s 350us/step - loss: 0.3570 - acc: 0.8533\n",
      "Epoch 43/160\n",
      "675/675 [==============================] - 0s 355us/step - loss: 0.3502 - acc: 0.8563\n",
      "Epoch 44/160\n",
      "675/675 [==============================] - 0s 295us/step - loss: 0.3550 - acc: 0.8533\n",
      "Epoch 45/160\n",
      "675/675 [==============================] - 0s 337us/step - loss: 0.3510 - acc: 0.8568\n",
      "Epoch 46/160\n",
      "675/675 [==============================] - 0s 361us/step - loss: 0.3598 - acc: 0.8479\n",
      "Epoch 47/160\n",
      "675/675 [==============================] - 0s 379us/step - loss: 0.3545 - acc: 0.8479\n",
      "Epoch 48/160\n",
      "675/675 [==============================] - 0s 362us/step - loss: 0.3567 - acc: 0.8499\n",
      "Epoch 49/160\n",
      "675/675 [==============================] - 0s 366us/step - loss: 0.3644 - acc: 0.8494\n",
      "Epoch 50/160\n",
      "675/675 [==============================] - 0s 346us/step - loss: 0.3504 - acc: 0.8548\n",
      "Epoch 51/160\n",
      "675/675 [==============================] - 0s 377us/step - loss: 0.3588 - acc: 0.8553\n",
      "Epoch 52/160\n",
      "675/675 [==============================] - 0s 389us/step - loss: 0.3540 - acc: 0.8548\n",
      "Epoch 53/160\n",
      "675/675 [==============================] - 0s 391us/step - loss: 0.3476 - acc: 0.8598\n",
      "Epoch 54/160\n",
      "675/675 [==============================] - 0s 388us/step - loss: 0.3620 - acc: 0.8474\n",
      "Epoch 55/160\n",
      "675/675 [==============================] - 0s 356us/step - loss: 0.3610 - acc: 0.8420\n",
      "Epoch 56/160\n",
      "675/675 [==============================] - 0s 327us/step - loss: 0.3670 - acc: 0.8454\n",
      "Epoch 57/160\n",
      "675/675 [==============================] - 0s 326us/step - loss: 0.3553 - acc: 0.8444\n",
      "Epoch 58/160\n",
      "675/675 [==============================] - 0s 340us/step - loss: 0.3616 - acc: 0.8479\n",
      "Epoch 59/160\n",
      "675/675 [==============================] - 0s 331us/step - loss: 0.3691 - acc: 0.8494\n",
      "Epoch 60/160\n",
      "675/675 [==============================] - 0s 355us/step - loss: 0.3512 - acc: 0.8558\n",
      "Epoch 61/160\n",
      "675/675 [==============================] - 0s 323us/step - loss: 0.3461 - acc: 0.8573\n",
      "Epoch 62/160\n",
      "675/675 [==============================] - 0s 365us/step - loss: 0.3405 - acc: 0.8588\n",
      "Epoch 63/160\n",
      "675/675 [==============================] - 0s 367us/step - loss: 0.3510 - acc: 0.8593\n",
      "Epoch 64/160\n",
      "675/675 [==============================] - 0s 385us/step - loss: 0.3490 - acc: 0.8533\n",
      "Epoch 65/160\n",
      "675/675 [==============================] - 0s 359us/step - loss: 0.3358 - acc: 0.8573\n",
      "Epoch 66/160\n",
      "675/675 [==============================] - 0s 341us/step - loss: 0.3536 - acc: 0.8548\n",
      "Epoch 67/160\n",
      "675/675 [==============================] - 0s 313us/step - loss: 0.3426 - acc: 0.8528\n",
      "Epoch 68/160\n",
      "675/675 [==============================] - 0s 343us/step - loss: 0.3374 - acc: 0.8583\n",
      "Epoch 69/160\n",
      "675/675 [==============================] - 0s 393us/step - loss: 0.3405 - acc: 0.8523\n",
      "Epoch 70/160\n",
      "675/675 [==============================] - 0s 400us/step - loss: 0.3434 - acc: 0.8578\n",
      "Epoch 71/160\n",
      "675/675 [==============================] - 0s 293us/step - loss: 0.3470 - acc: 0.8548\n",
      "Epoch 72/160\n",
      "675/675 [==============================] - 0s 274us/step - loss: 0.3381 - acc: 0.8553\n",
      "Epoch 73/160\n",
      "675/675 [==============================] - 0s 293us/step - loss: 0.3339 - acc: 0.8622\n",
      "Epoch 74/160\n",
      "675/675 [==============================] - 0s 271us/step - loss: 0.3384 - acc: 0.8588\n",
      "Epoch 75/160\n",
      "675/675 [==============================] - 0s 271us/step - loss: 0.3291 - acc: 0.8553\n",
      "Epoch 76/160\n",
      "675/675 [==============================] - 0s 331us/step - loss: 0.3246 - acc: 0.8647\n",
      "Epoch 77/160\n",
      "675/675 [==============================] - 0s 349us/step - loss: 0.3407 - acc: 0.8548\n",
      "Epoch 78/160\n",
      "675/675 [==============================] - 0s 355us/step - loss: 0.3380 - acc: 0.8578\n",
      "Epoch 79/160\n",
      "675/675 [==============================] - 0s 335us/step - loss: 0.3444 - acc: 0.8494\n",
      "Epoch 80/160\n",
      "675/675 [==============================] - 0s 412us/step - loss: 0.3432 - acc: 0.8533\n",
      "Epoch 81/160\n",
      "675/675 [==============================] - 0s 373us/step - loss: 0.3505 - acc: 0.8494\n",
      "Epoch 82/160\n",
      "675/675 [==============================] - 0s 366us/step - loss: 0.3451 - acc: 0.8533\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 0s 369us/step - loss: 0.3263 - acc: 0.8607\n",
      "Epoch 84/160\n",
      "675/675 [==============================] - 0s 342us/step - loss: 0.3241 - acc: 0.8647\n",
      "Epoch 85/160\n",
      "675/675 [==============================] - 0s 349us/step - loss: 0.3318 - acc: 0.8627\n",
      "Epoch 86/160\n",
      "675/675 [==============================] - 0s 348us/step - loss: 0.3276 - acc: 0.8598\n",
      "Epoch 87/160\n",
      "675/675 [==============================] - 0s 349us/step - loss: 0.3323 - acc: 0.8568\n",
      "Epoch 88/160\n",
      "675/675 [==============================] - 0s 351us/step - loss: 0.3384 - acc: 0.8514\n",
      "Epoch 89/160\n",
      "675/675 [==============================] - 0s 347us/step - loss: 0.3270 - acc: 0.8617\n",
      "Epoch 90/160\n",
      "675/675 [==============================] - 0s 337us/step - loss: 0.3230 - acc: 0.8622\n",
      "Epoch 91/160\n",
      "675/675 [==============================] - 0s 347us/step - loss: 0.3418 - acc: 0.8607\n",
      "Epoch 92/160\n",
      "675/675 [==============================] - 0s 317us/step - loss: 0.3293 - acc: 0.8588\n",
      "Epoch 93/160\n",
      "675/675 [==============================] - 0s 338us/step - loss: 0.3182 - acc: 0.8652\n",
      "Epoch 94/160\n",
      "675/675 [==============================] - 0s 324us/step - loss: 0.3251 - acc: 0.8602\n",
      "Epoch 95/160\n",
      "675/675 [==============================] - 0s 345us/step - loss: 0.3458 - acc: 0.8528\n",
      "Epoch 96/160\n",
      "675/675 [==============================] - 0s 344us/step - loss: 0.3331 - acc: 0.8632\n",
      "Epoch 97/160\n",
      "675/675 [==============================] - 0s 333us/step - loss: 0.3310 - acc: 0.8627\n",
      "Epoch 98/160\n",
      "675/675 [==============================] - 0s 343us/step - loss: 0.3264 - acc: 0.8637\n",
      "Epoch 99/160\n",
      "675/675 [==============================] - 0s 336us/step - loss: 0.3344 - acc: 0.8686\n",
      "Epoch 100/160\n",
      "675/675 [==============================] - 0s 369us/step - loss: 0.3175 - acc: 0.8632\n",
      "Epoch 101/160\n",
      "675/675 [==============================] - 0s 325us/step - loss: 0.3170 - acc: 0.8578\n",
      "Epoch 102/160\n",
      "675/675 [==============================] - 0s 370us/step - loss: 0.3161 - acc: 0.8657\n",
      "Epoch 103/160\n",
      "675/675 [==============================] - 0s 372us/step - loss: 0.3309 - acc: 0.8598\n",
      "Epoch 104/160\n",
      "675/675 [==============================] - 0s 383us/step - loss: 0.3212 - acc: 0.8642\n",
      "Epoch 105/160\n",
      "675/675 [==============================] - 0s 360us/step - loss: 0.3151 - acc: 0.8627\n",
      "Epoch 106/160\n",
      "675/675 [==============================] - 0s 372us/step - loss: 0.3240 - acc: 0.8627\n",
      "Epoch 107/160\n",
      "675/675 [==============================] - 0s 339us/step - loss: 0.3131 - acc: 0.8622\n",
      "Epoch 108/160\n",
      "675/675 [==============================] - 0s 340us/step - loss: 0.3278 - acc: 0.8672\n",
      "Epoch 109/160\n",
      "675/675 [==============================] - 0s 321us/step - loss: 0.3209 - acc: 0.8652\n",
      "Epoch 110/160\n",
      "675/675 [==============================] - 0s 333us/step - loss: 0.3291 - acc: 0.8612\n",
      "Epoch 111/160\n",
      "675/675 [==============================] - 0s 325us/step - loss: 0.3151 - acc: 0.8612\n",
      "Epoch 112/160\n",
      "675/675 [==============================] - 0s 339us/step - loss: 0.3035 - acc: 0.8726\n",
      "Epoch 113/160\n",
      "675/675 [==============================] - 0s 344us/step - loss: 0.3055 - acc: 0.8652\n",
      "Epoch 114/160\n",
      "675/675 [==============================] - 0s 325us/step - loss: 0.3199 - acc: 0.8538\n",
      "Epoch 115/160\n",
      "675/675 [==============================] - 0s 334us/step - loss: 0.3205 - acc: 0.8588\n",
      "Epoch 116/160\n",
      "675/675 [==============================] - 0s 340us/step - loss: 0.3144 - acc: 0.8686\n",
      "Epoch 117/160\n",
      "675/675 [==============================] - 0s 331us/step - loss: 0.3151 - acc: 0.8706\n",
      "Epoch 118/160\n",
      "675/675 [==============================] - 0s 333us/step - loss: 0.3180 - acc: 0.8573\n",
      "Epoch 119/160\n",
      "675/675 [==============================] - 0s 323us/step - loss: 0.3236 - acc: 0.8632\n",
      "Epoch 120/160\n",
      "675/675 [==============================] - 0s 328us/step - loss: 0.3391 - acc: 0.8607\n",
      "Epoch 121/160\n",
      "675/675 [==============================] - 0s 345us/step - loss: 0.3244 - acc: 0.8622\n",
      "Epoch 122/160\n",
      "675/675 [==============================] - 0s 305us/step - loss: 0.3036 - acc: 0.8667\n",
      "Epoch 123/160\n",
      "675/675 [==============================] - 0s 327us/step - loss: 0.3079 - acc: 0.8583\n",
      "Epoch 124/160\n",
      "675/675 [==============================] - 0s 334us/step - loss: 0.3128 - acc: 0.8667\n",
      "Epoch 125/160\n",
      "675/675 [==============================] - 0s 331us/step - loss: 0.3038 - acc: 0.8736\n",
      "Epoch 126/160\n",
      "675/675 [==============================] - 0s 332us/step - loss: 0.3044 - acc: 0.8672\n",
      "Epoch 127/160\n",
      "675/675 [==============================] - 0s 346us/step - loss: 0.3133 - acc: 0.8627\n",
      "Epoch 128/160\n",
      "675/675 [==============================] - 0s 355us/step - loss: 0.3132 - acc: 0.8677\n",
      "Epoch 129/160\n",
      "675/675 [==============================] - 0s 347us/step - loss: 0.3049 - acc: 0.8637\n",
      "Epoch 130/160\n",
      "675/675 [==============================] - 0s 330us/step - loss: 0.3080 - acc: 0.8726\n",
      "Epoch 131/160\n",
      "675/675 [==============================] - 0s 337us/step - loss: 0.2999 - acc: 0.8657\n",
      "Epoch 132/160\n",
      "675/675 [==============================] - 0s 333us/step - loss: 0.2945 - acc: 0.8731\n",
      "Epoch 133/160\n",
      "675/675 [==============================] - 0s 320us/step - loss: 0.2937 - acc: 0.8746\n",
      "Epoch 134/160\n",
      "675/675 [==============================] - 0s 324us/step - loss: 0.2938 - acc: 0.8672\n",
      "Epoch 135/160\n",
      "675/675 [==============================] - 0s 321us/step - loss: 0.3066 - acc: 0.8647\n",
      "Epoch 136/160\n",
      "675/675 [==============================] - 0s 350us/step - loss: 0.3186 - acc: 0.8543\n",
      "Epoch 137/160\n",
      "675/675 [==============================] - 0s 341us/step - loss: 0.3197 - acc: 0.8583\n",
      "Epoch 138/160\n",
      "675/675 [==============================] - 0s 348us/step - loss: 0.2954 - acc: 0.8691\n",
      "Epoch 139/160\n",
      "675/675 [==============================] - 0s 334us/step - loss: 0.3002 - acc: 0.8711\n",
      "Epoch 140/160\n",
      "675/675 [==============================] - 0s 338us/step - loss: 0.3247 - acc: 0.8612\n",
      "Epoch 141/160\n",
      "675/675 [==============================] - 0s 333us/step - loss: 0.3192 - acc: 0.8637\n",
      "Epoch 142/160\n",
      "675/675 [==============================] - 0s 329us/step - loss: 0.2967 - acc: 0.8716\n",
      "Epoch 143/160\n",
      "675/675 [==============================] - 0s 330us/step - loss: 0.2937 - acc: 0.8721\n",
      "Epoch 144/160\n",
      "675/675 [==============================] - 0s 343us/step - loss: 0.2909 - acc: 0.8746\n",
      "Epoch 145/160\n",
      "675/675 [==============================] - 0s 330us/step - loss: 0.2911 - acc: 0.8751\n",
      "Epoch 146/160\n",
      "675/675 [==============================] - 0s 337us/step - loss: 0.3016 - acc: 0.8632\n",
      "Epoch 147/160\n",
      "675/675 [==============================] - 0s 331us/step - loss: 0.2866 - acc: 0.8701\n",
      "Epoch 148/160\n",
      "675/675 [==============================] - 0s 338us/step - loss: 0.3056 - acc: 0.8721\n",
      "Epoch 149/160\n",
      "675/675 [==============================] - 0s 330us/step - loss: 0.2948 - acc: 0.8681\n",
      "Epoch 150/160\n",
      "675/675 [==============================] - 0s 340us/step - loss: 0.3119 - acc: 0.8593\n",
      "Epoch 151/160\n",
      "675/675 [==============================] - 0s 320us/step - loss: 0.3110 - acc: 0.8637\n",
      "Epoch 152/160\n",
      "675/675 [==============================] - 0s 341us/step - loss: 0.3121 - acc: 0.8657\n",
      "Epoch 153/160\n",
      "675/675 [==============================] - 0s 351us/step - loss: 0.3090 - acc: 0.8637\n",
      "Epoch 154/160\n",
      "675/675 [==============================] - 0s 345us/step - loss: 0.3023 - acc: 0.8701\n",
      "Epoch 155/160\n",
      "675/675 [==============================] - 0s 346us/step - loss: 0.2938 - acc: 0.8686\n",
      "Epoch 156/160\n",
      "675/675 [==============================] - 0s 375us/step - loss: 0.3008 - acc: 0.8681\n",
      "Epoch 157/160\n",
      "675/675 [==============================] - 0s 353us/step - loss: 0.3086 - acc: 0.8765\n",
      "Epoch 158/160\n",
      "675/675 [==============================] - 0s 337us/step - loss: 0.3117 - acc: 0.8627\n",
      "Epoch 159/160\n",
      "675/675 [==============================] - 0s 349us/step - loss: 0.3188 - acc: 0.8652\n",
      "Epoch 160/160\n",
      "675/675 [==============================] - 0s 319us/step - loss: 0.3095 - acc: 0.8627\n",
      "675/675 [==============================] - 1s 1ms/step\n",
      "\n",
      "acc: 87.31%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-74b0d7e5dbb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mk_3_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mk_3_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_3_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mk_4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mk_4_i\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mk_4_s\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_4_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='market') & (df_k.Timelevel==3)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy:market and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Epoch 1/160\n",
      "698/698 [==============================] - 2s 3ms/step - loss: 0.4147 - acc: 0.8295\n",
      "Epoch 2/160\n",
      "698/698 [==============================] - 0s 313us/step - loss: 0.3150 - acc: 0.8779\n",
      "Epoch 3/160\n",
      "698/698 [==============================] - 0s 323us/step - loss: 0.3122 - acc: 0.8764\n",
      "Epoch 4/160\n",
      "698/698 [==============================] - 0s 330us/step - loss: 0.3151 - acc: 0.8807\n",
      "Epoch 5/160\n",
      "698/698 [==============================] - 0s 340us/step - loss: 0.3044 - acc: 0.8757\n",
      "Epoch 6/160\n",
      "698/698 [==============================] - 0s 342us/step - loss: 0.2938 - acc: 0.8807\n",
      "Epoch 7/160\n",
      "698/698 [==============================] - 0s 321us/step - loss: 0.2974 - acc: 0.8779\n",
      "Epoch 8/160\n",
      "698/698 [==============================] - 0s 314us/step - loss: 0.2971 - acc: 0.8811\n",
      "Epoch 9/160\n",
      "698/698 [==============================] - 0s 284us/step - loss: 0.2952 - acc: 0.8768\n",
      "Epoch 10/160\n",
      "698/698 [==============================] - 0s 287us/step - loss: 0.2965 - acc: 0.8818\n",
      "Epoch 11/160\n",
      "698/698 [==============================] - 0s 329us/step - loss: 0.2960 - acc: 0.8800\n",
      "Epoch 12/160\n",
      "698/698 [==============================] - 0s 311us/step - loss: 0.3012 - acc: 0.8804\n",
      "Epoch 13/160\n",
      "698/698 [==============================] - 0s 318us/step - loss: 0.2913 - acc: 0.8829\n",
      "Epoch 14/160\n",
      "698/698 [==============================] - 0s 297us/step - loss: 0.2865 - acc: 0.8822\n",
      "Epoch 15/160\n",
      "698/698 [==============================] - 0s 330us/step - loss: 0.2873 - acc: 0.8836\n",
      "Epoch 16/160\n",
      "698/698 [==============================] - 0s 333us/step - loss: 0.2820 - acc: 0.8793\n",
      "Epoch 17/160\n",
      "698/698 [==============================] - 0s 316us/step - loss: 0.2779 - acc: 0.8818\n",
      "Epoch 18/160\n",
      "698/698 [==============================] - 0s 318us/step - loss: 0.2823 - acc: 0.8829\n",
      "Epoch 19/160\n",
      "698/698 [==============================] - 0s 318us/step - loss: 0.2824 - acc: 0.8832\n",
      "Epoch 20/160\n",
      "698/698 [==============================] - 0s 346us/step - loss: 0.2832 - acc: 0.8886\n",
      "Epoch 21/160\n",
      "698/698 [==============================] - 0s 314us/step - loss: 0.2824 - acc: 0.8832\n",
      "Epoch 22/160\n",
      "698/698 [==============================] - 0s 323us/step - loss: 0.2865 - acc: 0.8840\n",
      "Epoch 23/160\n",
      "698/698 [==============================] - 0s 296us/step - loss: 0.2784 - acc: 0.8836\n",
      "Epoch 24/160\n",
      "698/698 [==============================] - 0s 321us/step - loss: 0.2756 - acc: 0.8843\n",
      "Epoch 25/160\n",
      "698/698 [==============================] - 0s 316us/step - loss: 0.2823 - acc: 0.8825\n",
      "Epoch 26/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2856 - acc: 0.8789\n",
      "Epoch 27/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2793 - acc: 0.8829\n",
      "Epoch 28/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2815 - acc: 0.8832\n",
      "Epoch 29/160\n",
      "698/698 [==============================] - 0s 335us/step - loss: 0.2859 - acc: 0.8789\n",
      "Epoch 30/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2786 - acc: 0.8800\n",
      "Epoch 31/160\n",
      "698/698 [==============================] - 0s 309us/step - loss: 0.2800 - acc: 0.8850\n",
      "Epoch 32/160\n",
      "698/698 [==============================] - 0s 329us/step - loss: 0.2792 - acc: 0.8782\n",
      "Epoch 33/160\n",
      "698/698 [==============================] - 0s 340us/step - loss: 0.2755 - acc: 0.8843\n",
      "Epoch 34/160\n",
      "698/698 [==============================] - 0s 338us/step - loss: 0.2743 - acc: 0.8850\n",
      "Epoch 35/160\n",
      "698/698 [==============================] - 0s 298us/step - loss: 0.2759 - acc: 0.8818\n",
      "Epoch 36/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2726 - acc: 0.8854\n",
      "Epoch 37/160\n",
      "698/698 [==============================] - 0s 326us/step - loss: 0.2745 - acc: 0.8840\n",
      "Epoch 38/160\n",
      "698/698 [==============================] - 0s 314us/step - loss: 0.2768 - acc: 0.8836\n",
      "Epoch 39/160\n",
      "698/698 [==============================] - 0s 313us/step - loss: 0.2732 - acc: 0.8825\n",
      "Epoch 40/160\n",
      "698/698 [==============================] - 0s 283us/step - loss: 0.2746 - acc: 0.8854\n",
      "Epoch 41/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2734 - acc: 0.8857\n",
      "Epoch 42/160\n",
      "698/698 [==============================] - 0s 308us/step - loss: 0.2686 - acc: 0.8854\n",
      "Epoch 43/160\n",
      "698/698 [==============================] - 0s 314us/step - loss: 0.2689 - acc: 0.8825\n",
      "Epoch 44/160\n",
      "698/698 [==============================] - 0s 322us/step - loss: 0.2661 - acc: 0.8825\n",
      "Epoch 45/160\n",
      "698/698 [==============================] - 0s 323us/step - loss: 0.2708 - acc: 0.8825\n",
      "Epoch 46/160\n",
      "698/698 [==============================] - 0s 310us/step - loss: 0.2774 - acc: 0.8811\n",
      "Epoch 47/160\n",
      "698/698 [==============================] - 0s 318us/step - loss: 0.2759 - acc: 0.8818\n",
      "Epoch 48/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2683 - acc: 0.8872\n",
      "Epoch 49/160\n",
      "698/698 [==============================] - 0s 305us/step - loss: 0.2690 - acc: 0.8829\n",
      "Epoch 50/160\n",
      "698/698 [==============================] - 0s 310us/step - loss: 0.2711 - acc: 0.8814\n",
      "Epoch 51/160\n",
      "698/698 [==============================] - 0s 324us/step - loss: 0.2842 - acc: 0.8818\n",
      "Epoch 52/160\n",
      "698/698 [==============================] - 0s 323us/step - loss: 0.2790 - acc: 0.8825\n",
      "Epoch 53/160\n",
      "698/698 [==============================] - 0s 311us/step - loss: 0.2737 - acc: 0.8857\n",
      "Epoch 54/160\n",
      "698/698 [==============================] - 0s 315us/step - loss: 0.2692 - acc: 0.8854\n",
      "Epoch 55/160\n",
      "698/698 [==============================] - 0s 308us/step - loss: 0.2720 - acc: 0.8829\n",
      "Epoch 56/160\n",
      "698/698 [==============================] - 0s 332us/step - loss: 0.2676 - acc: 0.8900\n",
      "Epoch 57/160\n",
      "698/698 [==============================] - 0s 300us/step - loss: 0.2656 - acc: 0.8818\n",
      "Epoch 58/160\n",
      "698/698 [==============================] - 0s 341us/step - loss: 0.2675 - acc: 0.8857\n",
      "Epoch 59/160\n",
      "698/698 [==============================] - 0s 322us/step - loss: 0.2670 - acc: 0.8857\n",
      "Epoch 60/160\n",
      "698/698 [==============================] - 0s 313us/step - loss: 0.2658 - acc: 0.8933\n",
      "Epoch 61/160\n",
      "698/698 [==============================] - 0s 329us/step - loss: 0.2721 - acc: 0.8890\n",
      "Epoch 62/160\n",
      "698/698 [==============================] - 0s 310us/step - loss: 0.2675 - acc: 0.8865\n",
      "Epoch 63/160\n",
      "698/698 [==============================] - 0s 303us/step - loss: 0.2659 - acc: 0.8886\n",
      "Epoch 64/160\n",
      "698/698 [==============================] - 0s 357us/step - loss: 0.2648 - acc: 0.8829\n",
      "Epoch 65/160\n",
      "698/698 [==============================] - 0s 357us/step - loss: 0.2633 - acc: 0.8847\n",
      "Epoch 66/160\n",
      "698/698 [==============================] - 0s 334us/step - loss: 0.2594 - acc: 0.8908\n",
      "Epoch 67/160\n",
      "698/698 [==============================] - 0s 324us/step - loss: 0.2652 - acc: 0.8861\n",
      "Epoch 68/160\n",
      "698/698 [==============================] - 0s 304us/step - loss: 0.2588 - acc: 0.8879\n",
      "Epoch 69/160\n",
      "698/698 [==============================] - 0s 315us/step - loss: 0.2542 - acc: 0.8875\n",
      "Epoch 70/160\n",
      "698/698 [==============================] - 0s 319us/step - loss: 0.2632 - acc: 0.8854\n",
      "Epoch 71/160\n",
      "698/698 [==============================] - 0s 315us/step - loss: 0.2564 - acc: 0.8886\n",
      "Epoch 72/160\n",
      "698/698 [==============================] - 0s 310us/step - loss: 0.2568 - acc: 0.8883\n",
      "Epoch 73/160\n",
      "698/698 [==============================] - 0s 310us/step - loss: 0.2626 - acc: 0.8890\n",
      "Epoch 74/160\n",
      "698/698 [==============================] - 0s 311us/step - loss: 0.2669 - acc: 0.8872\n",
      "Epoch 75/160\n",
      "698/698 [==============================] - 0s 324us/step - loss: 0.2698 - acc: 0.8868\n",
      "Epoch 76/160\n",
      "698/698 [==============================] - 0s 318us/step - loss: 0.2574 - acc: 0.8879\n",
      "Epoch 77/160\n",
      "698/698 [==============================] - 0s 303us/step - loss: 0.2541 - acc: 0.8908\n",
      "Epoch 78/160\n",
      "698/698 [==============================] - 0s 327us/step - loss: 0.2729 - acc: 0.8797\n",
      "Epoch 79/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2621 - acc: 0.8854\n",
      "Epoch 80/160\n",
      "698/698 [==============================] - 0s 322us/step - loss: 0.2608 - acc: 0.8850\n",
      "Epoch 81/160\n",
      "698/698 [==============================] - 0s 324us/step - loss: 0.2565 - acc: 0.8800\n",
      "Epoch 82/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2467 - acc: 0.8875\n",
      "Epoch 83/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698/698 [==============================] - 0s 320us/step - loss: 0.2548 - acc: 0.8857\n",
      "Epoch 84/160\n",
      "698/698 [==============================] - 0s 328us/step - loss: 0.2672 - acc: 0.8865\n",
      "Epoch 85/160\n",
      "698/698 [==============================] - 0s 316us/step - loss: 0.2654 - acc: 0.8911\n",
      "Epoch 86/160\n",
      "698/698 [==============================] - 0s 309us/step - loss: 0.2490 - acc: 0.8929\n",
      "Epoch 87/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2475 - acc: 0.8904\n",
      "Epoch 88/160\n",
      "698/698 [==============================] - 0s 291us/step - loss: 0.2513 - acc: 0.8961\n",
      "Epoch 89/160\n",
      "698/698 [==============================] - 0s 297us/step - loss: 0.2500 - acc: 0.8904\n",
      "Epoch 90/160\n",
      "698/698 [==============================] - 0s 309us/step - loss: 0.2436 - acc: 0.8968\n",
      "Epoch 91/160\n",
      "698/698 [==============================] - 0s 300us/step - loss: 0.2469 - acc: 0.8922\n",
      "Epoch 92/160\n",
      "698/698 [==============================] - 0s 328us/step - loss: 0.2515 - acc: 0.8965\n",
      "Epoch 93/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2434 - acc: 0.8922\n",
      "Epoch 94/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2505 - acc: 0.8900\n",
      "Epoch 95/160\n",
      "698/698 [==============================] - 0s 292us/step - loss: 0.2486 - acc: 0.8911\n",
      "Epoch 96/160\n",
      "698/698 [==============================] - 0s 308us/step - loss: 0.2415 - acc: 0.8926\n",
      "Epoch 97/160\n",
      "698/698 [==============================] - 0s 298us/step - loss: 0.2374 - acc: 0.8994\n",
      "Epoch 98/160\n",
      "698/698 [==============================] - 0s 307us/step - loss: 0.2428 - acc: 0.8929\n",
      "Epoch 99/160\n",
      "698/698 [==============================] - 0s 319us/step - loss: 0.2332 - acc: 0.9004\n",
      "Epoch 100/160\n",
      "698/698 [==============================] - 0s 294us/step - loss: 0.2414 - acc: 0.8943\n",
      "Epoch 101/160\n",
      "698/698 [==============================] - 0s 300us/step - loss: 0.2295 - acc: 0.8979\n",
      "Epoch 102/160\n",
      "698/698 [==============================] - 0s 293us/step - loss: 0.2363 - acc: 0.8968\n",
      "Epoch 103/160\n",
      "698/698 [==============================] - 0s 294us/step - loss: 0.2343 - acc: 0.8900\n",
      "Epoch 104/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2293 - acc: 0.8968\n",
      "Epoch 105/160\n",
      "698/698 [==============================] - 0s 290us/step - loss: 0.2255 - acc: 0.8990\n",
      "Epoch 106/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2426 - acc: 0.8983\n",
      "Epoch 107/160\n",
      "698/698 [==============================] - 0s 295us/step - loss: 0.2444 - acc: 0.8972\n",
      "Epoch 108/160\n",
      "698/698 [==============================] - 0s 317us/step - loss: 0.2407 - acc: 0.9015\n",
      "Epoch 109/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2302 - acc: 0.8954\n",
      "Epoch 110/160\n",
      "698/698 [==============================] - 0s 321us/step - loss: 0.2395 - acc: 0.8958\n",
      "Epoch 111/160\n",
      "698/698 [==============================] - 0s 301us/step - loss: 0.2534 - acc: 0.8865\n",
      "Epoch 112/160\n",
      "698/698 [==============================] - 0s 299us/step - loss: 0.2351 - acc: 0.8943\n",
      "Epoch 113/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2217 - acc: 0.9015\n",
      "Epoch 114/160\n",
      "698/698 [==============================] - 0s 298us/step - loss: 0.2173 - acc: 0.9044\n",
      "Epoch 115/160\n",
      "698/698 [==============================] - 0s 338us/step - loss: 0.2216 - acc: 0.9119\n",
      "Epoch 116/160\n",
      "698/698 [==============================] - 0s 288us/step - loss: 0.2275 - acc: 0.9058\n",
      "Epoch 117/160\n",
      "698/698 [==============================] - 0s 325us/step - loss: 0.2414 - acc: 0.9008\n",
      "Epoch 118/160\n",
      "698/698 [==============================] - 0s 289us/step - loss: 0.2471 - acc: 0.8897\n",
      "Epoch 119/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2180 - acc: 0.9026\n",
      "Epoch 120/160\n",
      "698/698 [==============================] - 0s 292us/step - loss: 0.2202 - acc: 0.9033\n",
      "Epoch 121/160\n",
      "698/698 [==============================] - 0s 314us/step - loss: 0.2184 - acc: 0.8994\n",
      "Epoch 122/160\n",
      "698/698 [==============================] - 0s 297us/step - loss: 0.2314 - acc: 0.9072\n",
      "Epoch 123/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2413 - acc: 0.8936\n",
      "Epoch 124/160\n",
      "698/698 [==============================] - 0s 315us/step - loss: 0.2355 - acc: 0.8968\n",
      "Epoch 125/160\n",
      "698/698 [==============================] - 0s 318us/step - loss: 0.2183 - acc: 0.9040\n",
      "Epoch 126/160\n",
      "698/698 [==============================] - 0s 309us/step - loss: 0.2280 - acc: 0.8994\n",
      "Epoch 127/160\n",
      "698/698 [==============================] - 0s 296us/step - loss: 0.2247 - acc: 0.8972\n",
      "Epoch 128/160\n",
      "698/698 [==============================] - 0s 325us/step - loss: 0.2214 - acc: 0.9015\n",
      "Epoch 129/160\n",
      "698/698 [==============================] - 0s 308us/step - loss: 0.2266 - acc: 0.9047\n",
      "Epoch 130/160\n",
      "698/698 [==============================] - 0s 300us/step - loss: 0.2243 - acc: 0.8994\n",
      "Epoch 131/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2124 - acc: 0.9019\n",
      "Epoch 132/160\n",
      "698/698 [==============================] - 0s 311us/step - loss: 0.2136 - acc: 0.9004\n",
      "Epoch 133/160\n",
      "698/698 [==============================] - 0s 323us/step - loss: 0.2280 - acc: 0.9047\n",
      "Epoch 134/160\n",
      "698/698 [==============================] - 0s 318us/step - loss: 0.2343 - acc: 0.8965\n",
      "Epoch 135/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2207 - acc: 0.8997\n",
      "Epoch 136/160\n",
      "698/698 [==============================] - 0s 296us/step - loss: 0.2075 - acc: 0.9051\n",
      "Epoch 137/160\n",
      "698/698 [==============================] - 0s 301us/step - loss: 0.2061 - acc: 0.9040\n",
      "Epoch 138/160\n",
      "698/698 [==============================] - 0s 327us/step - loss: 0.2125 - acc: 0.9026\n",
      "Epoch 139/160\n",
      "698/698 [==============================] - 0s 418us/step - loss: 0.2341 - acc: 0.8994\n",
      "Epoch 140/160\n",
      "698/698 [==============================] - 0s 426us/step - loss: 0.2286 - acc: 0.9029\n",
      "Epoch 141/160\n",
      "698/698 [==============================] - 0s 411us/step - loss: 0.2187 - acc: 0.9019\n",
      "Epoch 142/160\n",
      "698/698 [==============================] - 0s 430us/step - loss: 0.2097 - acc: 0.8990\n",
      "Epoch 143/160\n",
      "698/698 [==============================] - 0s 422us/step - loss: 0.2168 - acc: 0.9004\n",
      "Epoch 144/160\n",
      "698/698 [==============================] - 0s 399us/step - loss: 0.2202 - acc: 0.9022\n",
      "Epoch 145/160\n",
      "698/698 [==============================] - 0s 433us/step - loss: 0.2172 - acc: 0.9008\n",
      "Epoch 146/160\n",
      "698/698 [==============================] - 0s 435us/step - loss: 0.2042 - acc: 0.9044\n",
      "Epoch 147/160\n",
      "698/698 [==============================] - 0s 432us/step - loss: 0.2033 - acc: 0.9069\n",
      "Epoch 148/160\n",
      "698/698 [==============================] - 0s 442us/step - loss: 0.2072 - acc: 0.9019\n",
      "Epoch 149/160\n",
      "698/698 [==============================] - 0s 466us/step - loss: 0.2040 - acc: 0.9051\n",
      "Epoch 150/160\n",
      "698/698 [==============================] - 0s 360us/step - loss: 0.2049 - acc: 0.9008\n",
      "Epoch 151/160\n",
      "698/698 [==============================] - 0s 340us/step - loss: 0.2055 - acc: 0.9047\n",
      "Epoch 152/160\n",
      "698/698 [==============================] - 0s 319us/step - loss: 0.2083 - acc: 0.9083\n",
      "Epoch 153/160\n",
      "698/698 [==============================] - 0s 332us/step - loss: 0.2018 - acc: 0.9112\n",
      "Epoch 154/160\n",
      "698/698 [==============================] - 0s 317us/step - loss: 0.2056 - acc: 0.9047\n",
      "Epoch 155/160\n",
      "698/698 [==============================] - 0s 333us/step - loss: 0.2016 - acc: 0.9051\n",
      "Epoch 156/160\n",
      "698/698 [==============================] - 0s 341us/step - loss: 0.2157 - acc: 0.8997\n",
      "Epoch 157/160\n",
      "698/698 [==============================] - 0s 306us/step - loss: 0.2441 - acc: 0.8904\n",
      "Epoch 158/160\n",
      "698/698 [==============================] - 0s 339us/step - loss: 0.2423 - acc: 0.8911\n",
      "Epoch 159/160\n",
      "698/698 [==============================] - 0s 312us/step - loss: 0.2314 - acc: 0.8922\n",
      "Epoch 160/160\n",
      "698/698 [==============================] - 0s 314us/step - loss: 0.2096 - acc: 0.9062\n",
      "698/698 [==============================] - 1s 921us/step\n",
      "\n",
      "acc: 82.09%\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "1 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 0 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 0 1 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "0 1 0 0\n",
      "[[  7   5   0   0]\n",
      " [  0 130   5   0]\n",
      " [  0   6  21   0]\n",
      " [  0   0   0   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fast       1.00      0.58      0.74        12\n",
      "      Normal       0.92      0.96      0.94       135\n",
      "        Slow       0.81      0.78      0.79        27\n",
      "   Very Fast       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.91       175\n",
      "   macro avg       0.93      0.83      0.87       175\n",
      "weighted avg       0.91      0.91      0.91       175\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9085714285714286"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_k=pd.read_csv('6mar.csv')\n",
    "df=df_k[(df_k.Zone=='market') & (df_k.Timelevel==4)]\n",
    "\n",
    "model=Sequential()\n",
    "#print(len(df))\n",
    "\n",
    "#TRain\n",
    "X=df[['Honk_duration','Road_surface','Intersection density','WiFi density','Timelevel']].values\n",
    "X_d=pd.DataFrame(X)\n",
    "y=df[['Class','Mean_speed_kmph']].values\n",
    "y_d=pd.DataFrame(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test_k = train_test_split(X_d,y_d,test_size=0.2,random_state=42)\n",
    "new_y_2=y_train[0].copy()\n",
    "new_y_d_2=pd.DataFrame(new_y_2)\n",
    "new_y=y_test_k[0].copy()\n",
    "\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "\n",
    "y_test=pd.DataFrame(new_y)\n",
    "\n",
    "y_train_2=pd.get_dummies(new_y_d_2)\n",
    "y_test_2=pd.get_dummies(new_y)\n",
    "n_cols=X_train.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(600, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "#model.add(Dense(1200, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "#X_d_2=to_categorical(X_d)\n",
    "#y_d_2=to_categorical(y_d)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train_2, epochs=160, callbacks=[early_stopping_monitor],batch_size=50)\n",
    "\n",
    "\n",
    "#3\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(X_test, y_test_2)\n",
    "scores_2 = model.evaluate(X_train, y_train_2)\n",
    "#print(X_test)\n",
    "#print(y_test)\n",
    "#new_y_2=y_train[0].copy()\n",
    "#new_y_d_2=pd.DataFrame(new_y_2)\n",
    "#new_y=y_test[0].copy()\n",
    "predictions=model.predict(X_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores_2[1]*100))\n",
    "#value_check=new_y.tolist()\n",
    "#print(value_check)\n",
    "#print(value_check)\n",
    "\n",
    "#---------------------#\n",
    "#new_y_d=pd.DataFrame(new_y)\n",
    "#----------------------#\n",
    "speed_check=y_test_k[1].copy()\n",
    "#speed_check_d=pd.DataFrame(speed_check)\n",
    "speed_check_l=speed_check.tolist()     #\n",
    "y_test_l=[]\n",
    "\n",
    "l=len(y_test_2)\n",
    "j=0\n",
    "while j<l:\n",
    "   # if j not in all_zero:\n",
    "        if y_test_2.iloc[j][0]==1:\n",
    "            y_test_l.append('Fast')\n",
    "        if y_test_2.iloc[j][1]==1:\n",
    "            y_test_l.append('Normal')\n",
    "        if y_test_2.iloc[j][2]==1:\n",
    "            y_test_l.append('Slow')\n",
    "        if y_test_2.iloc[j][3]==1:\n",
    "            y_test_l.append('Very Fast')\n",
    "        j=j+1\n",
    "prediction_l=[]\n",
    "count=0\n",
    "all_zero=[]\n",
    "#print(len(predictions))\n",
    "for x in predictions:\n",
    "    k_1=round(x[0])\n",
    "    k_1_i=int(k_1)\n",
    "    k_1_s=str(k_1_i)\n",
    "    k_2=round(x[1])\n",
    "    k_2_i=int(k_2)\n",
    "    k_2_s=str(k_2_i)\n",
    "    k_3=round(x[2])\n",
    "    k_3_i=int(k_3)\n",
    "    k_3_s=str(k_3_i)\n",
    "    k_4=round(x[3])\n",
    "    k_4_i=int(k_4)\n",
    "    k_4_s=str(k_4_i)\n",
    "    print(k_1_s+' '+k_2_s+' '+k_3_s+' '+k_4_s)\n",
    "    \n",
    "    if k_1_i==0 and k_2_i==0 and k_3_i==0 and k_4_i==0:\n",
    "        all_zero.append(count)\n",
    "        prediction_l.append(y_test_l[count])\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        if k_1_i==1:\n",
    "            prediction_l.append('Fast')\n",
    "        if k_2_i==1:\n",
    "            prediction_l.append('Normal')\n",
    "        if k_3_i==1:\n",
    "            prediction_l.append('Slow')\n",
    "        if k_4_i==1:\n",
    "            prediction_l.append('Very Fast')\n",
    "    count=count+1\n",
    "    \n",
    "#print(all_zero)\n",
    "#print(len(all_zero))\n",
    "#print(prediction_l)\n",
    "#print(len(prediction_l))\n",
    "\n",
    "\n",
    "l_2=len(y_test_l)\n",
    "j=0\n",
    "while j<l_2:\n",
    "    if speed_check_l[j]>=17 and speed_check_l[j]<=23 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Slow':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Slow' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=32 and speed_check_l[j]<=38 :\n",
    "        if y_test_l[j]=='Normal' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Normal':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    if speed_check_l[j]>=47 and speed_check_l[j]<=53 :\n",
    "        if y_test_l[j]=='Very Fast' and prediction_l[j]=='Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "        if y_test_l[j]=='Fast' and prediction_l[j]=='Very Fast':\n",
    "            prediction_l[j]=y_test_l[j]\n",
    "    j=j+1\n",
    "#print(y_test_l)\n",
    "j=0\n",
    "right=0\n",
    "while j<l_2:\n",
    "    if y_test_l[j]==prediction_l[j]:\n",
    "        right=right+1\n",
    "    j=j+1;\n",
    "    #print(j)\n",
    "#print(right)\n",
    "#print(right/len(y_test))\n",
    "a=confusion_matrix(y_test_l,prediction_l)\n",
    "print(a)\n",
    "\n",
    "print(classification_report(y_test_l,prediction_l))\n",
    "accuracy_score(y_test_l,prediction_l)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: market and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d_acc={'Timelevel':[79.28,81.87,84.97,82.07]}\n",
    "d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "ax=d_acc_d.plot.bar(rot=30,figsize=(10,8),color=(0,0,0,0),edgecolor='black',linewidth=3)\n",
    "#ax.set_xticklabels(['1','2','3','4'])\n",
    "#ax.set(xlabel='TimeLevel',ylabel='Accuracy')\n",
    "ax.set_yticklabels(['0','10','20','30','40','50','60','70','80'],{'fontsize':19,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['morning','mid_day','evening','night'],{'fontsize':19,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('TimeLevel',fontsize=22,fontweight='bold')\n",
    "ax.set_ylabel('Accuracy',fontsize=22,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d_acc={'Zone':[79.89,86.12,77.19]}\n",
    "d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "ax=d_acc_d.plot.bar(rot=30,figsize=(10,8),color=(0,0,0,0),edgecolor='black',linewidth=3)\n",
    "#ax.set_xticklabels(['1','2','3','4'])\n",
    "#ax.set(xlabel='TimeLevel',ylabel='Accuracy')\n",
    "ax.set_yticklabels(['0','20','40','60','80'],{'fontsize':19,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['normal_city','market','highway'],{'fontsize':19,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Zone',fontsize=22,fontweight='bold')\n",
    "ax.set_ylabel('Accuracy',fontsize=22,fontweight='bold')\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d={'1':[60,56,87.73],'2':[75.55,81.51,62.4],'3':[85.09,91.7,64],'4':[68.7,87.78,58.33]}\n",
    "d_data=pd.DataFrame(d)\n",
    "d_1={'Timelevel_1':[79.26,82.09,83.97]}\n",
    "d_1_d=pd.DataFrame(d_1)\n",
    "d_2={'Timelevel_2':[72.78,75.89,87.31]}\n",
    "d_2_d=pd.DataFrame(d_2)\n",
    "d_3={'Timelevel_3':[85.4,82.81,89.10]}\n",
    "d_3_d=pd.DataFrame(d_3)\n",
    "d_4={'Timelevel_4':[84.69,70.31,82.09]}\n",
    "d_4_d=pd.DataFrame(d_4)\n",
    "#d_acc={'Timelevel':[74,78,84,77]}\n",
    "#d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "ax = d_1_d.plot.bar(rot=30,figsize=(10,10))\n",
    "#ax.set_xticklabels(['MARKET','HIGHWAY','NORMAL CITY'])\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_yticklabels(['0','10','20','30','40','50','60','70','80'],{'fontsize':17,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['NORMAL CITY','HIGHWAY','MARKET'],{'fontsize':17,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Zone',fontsize=17,fontweight='bold')\n",
    "ax.set_ylabel('Accuracy',fontsize=17,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d={'1':[60,56,87.73],'2':[75.55,81.51,62.4],'3':[85.09,91.7,64],'4':[68.7,87.78,58.33]}\n",
    "d_data=pd.DataFrame(d)\n",
    "d_1={'Timelevel_1':[79.26,82.09,83.97]}\n",
    "d_1_d=pd.DataFrame(d_1)\n",
    "d_2={'Timelevel_2':[72.78,75.89,87.31]}\n",
    "d_2_d=pd.DataFrame(d_2)\n",
    "d_3={'Timelevel_3':[85.4,82.81,89.10]}\n",
    "d_3_d=pd.DataFrame(d_3)\n",
    "d_4={'Timelevel_4':[84.69,70.31,82.09]}\n",
    "d_4_d=pd.DataFrame(d_4)\n",
    "#d_acc={'Timelevel':[74,78,84,77]}\n",
    "#d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "ax = d_2_d.plot.bar(rot=30,figsize=(10,10))\n",
    "#ax.set_xticklabels(['MARKET','HIGHWAY','NORMAL CITY'])\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_yticklabels(['0','20','40','60','80'],{'fontsize':17,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['NORMAL CITY','HIGHWAY','MARKET'],{'fontsize':17,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Zone',fontsize=17,fontweight='bold')\n",
    "ax.set_ylabel('Accuracy',fontsize=17,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d={'1':[60,56,87.73],'2':[75.55,81.51,62.4],'3':[85.09,91.7,64],'4':[68.7,87.78,58.33]}\n",
    "d_data=pd.DataFrame(d)\n",
    "d_1={'Timelevel_1':[79.26,82.09,83.97]}\n",
    "d_1_d=pd.DataFrame(d_1)\n",
    "d_2={'Timelevel_2':[72.78,75.89,87.31]}\n",
    "d_2_d=pd.DataFrame(d_2)\n",
    "d_3={'Timelevel_3':[85.4,82.81,89.10]}\n",
    "d_3_d=pd.DataFrame(d_3)\n",
    "d_4={'Timelevel_4':[84.69,70.31,82.09]}\n",
    "d_4_d=pd.DataFrame(d_4)\n",
    "#d_acc={'Timelevel':[74,78,84,77]}\n",
    "#d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "ax = d_3_d.plot.bar(rot=30,figsize=(10,10))\n",
    "#ax.set_xticklabels(['MARKET','HIGHWAY','NORMAL CITY'])\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_yticklabels(['0','20','40','60','80'],{'fontsize':17,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['NORMAL CITY','HIGHWAY','MARKET'],{'fontsize':17,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Zone',fontsize=17,fontweight='bold')\n",
    "ax.set_ylabel('Accuracy',fontsize=17,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d={'1':[60,56,87.73],'2':[75.55,81.51,62.4],'3':[85.09,91.7,64],'4':[68.7,87.78,58.33]}\n",
    "d_data=pd.DataFrame(d)\n",
    "d_1={'Timelevel_1':[79.26,82.09,83.97]}\n",
    "d_1_d=pd.DataFrame(d_1)\n",
    "d_2={'Timelevel_2':[72.78,75.89,87.31]}\n",
    "d_2_d=pd.DataFrame(d_2)\n",
    "d_3={'Timelevel_3':[85.4,82.81,89.10]}\n",
    "d_3_d=pd.DataFrame(d_3)\n",
    "d_4={'Timelevel_4':[84.69,70.31,82.09]}\n",
    "d_4_d=pd.DataFrame(d_4)\n",
    "#d_acc={'Timelevel':[74,78,84,77]}\n",
    "#d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "ax = d_4_d.plot.bar(rot=30,figsize=(10,10))\n",
    "#ax.set_xticklabels(['MARKET','HIGHWAY','NORMAL CITY'])\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_yticklabels(['0','20','40','60','80'],{'fontsize':17,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['NORMAL CITY','HIGHWAY','MARKET'],{'fontsize':17,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Zone',fontsize=17,fontweight='bold')\n",
    "ax.set_ylabel('Accuracy',fontsize=17,fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "d={'1':[60,56,87.73],'2':[75.55,81.51,62.4],'3':[85.09,91.7,64],'4':[68.7,87.78,58.33]}\n",
    "d_data=pd.DataFrame(d)\n",
    "d_1={'Timelevel_1':[60,56,87.73]}\n",
    "d_1_d=pd.DataFrame(d_1)\n",
    "\n",
    "d_2={'Timelevel_2':[75.55,81.51,62.4]}\n",
    "d_2_d=pd.DataFrame(d_2)\n",
    "\n",
    "\n",
    "d_3={'Timelevel_3':[85.09,91.7,64]}\n",
    "d_3_d=pd.DataFrame(d_3)\n",
    "d_4={'Timelevel_4':[68.7,87.78,58.33]}\n",
    "d_4_d=pd.DataFrame(d_4)\n",
    "d_acc={'Timelevel':[74,78,84,77]}\n",
    "d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "d_total=[[60,72.78,85.4,84.69],[75.55,81.51,62.4],[85.09,91.7,64],[68.7,87.78,58.33]]\n",
    "d_total=[[60,75.55,85.09,68.7],[56,81,91.7,87.78],[87.73,62.4,64,58.33]]\n",
    "d_total_d=pd.DataFrame(d_total)\n",
    "d_m=[82.09,87.31,89.09,82.09]\n",
    "d_m_d=pd.DataFrame(d_m)\n",
    "d_h=[83.97,75.89,82.81,70.31]\n",
    "d_h_d=pd.DataFrame(d_h)\n",
    "d_n=[79.26,72.78,85.4,84.69]\n",
    "d_n_d=pd.DataFrame(d_n)\n",
    "\n",
    "m_mean=d_m_d.mean()\n",
    "m_std=d_m_d.std()\n",
    "\n",
    "h_mean=d_h_d.mean()\n",
    "h_std=d_h_d.std()\n",
    "\n",
    "n_mean=d_n_d.mean()\n",
    "n_std=d_n_d.std()\n",
    "\n",
    "total_mean=d_total_d.mean()\n",
    "total_mean_d=pd.DataFrame(total_mean)\n",
    "total_std=d_total_d.std()\n",
    "total_std_d=pd.DataFrame(total_std)\n",
    "\n",
    "#print(total_mean)\n",
    "#rint(total_std)\n",
    "#print(m_mean)\n",
    "#print(h_mean)\n",
    "#print(n_mean)\n",
    "\n",
    "#print(m_std)\n",
    "#print(h_std)\n",
    "#print(n_std)\n",
    "\n",
    "\n",
    "d_total_d=pd.DataFrame(d_total)\n",
    "\n",
    "\n",
    "ax=total_mean_d.plot.bar(yerr=total_std_d,rot=30,figsize=(10,8),color=(0,0,0,0),edgecolor='black',linewidth=3,error_kw=dict(lw=3,capsize=5,capthick=3))\n",
    "\n",
    "#ax.set_xticklabels(['1','2','3','4'])\n",
    "#ax.set(xlabel='TimeLevel',ylabel='Mean Accuracy')\n",
    "ax.set_yticklabels(['0','20','40','60','80'],{'fontsize':19,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['morning','mid_day','evening','night'],{'fontsize':19,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Timelevel',fontsize=24,fontweight='bold')\n",
    "ax.set_ylabel('Accuracy',fontsize=24,fontweight='bold')\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  5.850865\n",
      "1  5.866569\n",
      "2  3.170167\n",
      "         0\n",
      "0  80.5325\n",
      "1  77.7750\n",
      "2  85.6175\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "d={'1':[60,56,87.73],'2':[75.55,81.51,62.4],'3':[85.09,91.7,64],'4':[68.7,87.78,58.33]}\n",
    "d_data=pd.DataFrame(d)\n",
    "d_1={'Timelevel_1':[60,56,87.73]}\n",
    "d_1_d=pd.DataFrame(d_1)\n",
    "\n",
    "d_2={'Timelevel_2':[75.55,81.51,62.4]}\n",
    "d_2_d=pd.DataFrame(d_2)\n",
    "\n",
    "\n",
    "d_3={'Timelevel_3':[85.09,91.7,64]}\n",
    "d_3_d=pd.DataFrame(d_3)\n",
    "d_4={'Timelevel_4':[68.7,87.78,58.33]}\n",
    "d_4_d=pd.DataFrame(d_4)\n",
    "d_acc={'Timelevel':[74,78,84,77]}\n",
    "d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "d_total=[[79.26,82.09,83.97],[72.78,75.89,87.31],[85.4,82.81,89.10],[84.69,70.31,82.09]]\n",
    "#d_total=[[60,75.55,85.09,68.7],[56,81,91.7,87.78],[87.73,62.4,64,58.33]]\n",
    "d_total_d=pd.DataFrame(d_total)\n",
    "d_m=[88,82,91,87]\n",
    "d_m_d=pd.DataFrame(d_m)\n",
    "d_h=[56,63,64,59]\n",
    "d_h_d=pd.DataFrame(d_h)\n",
    "d_n=[60,76,88,69]\n",
    "d_n_d=pd.DataFrame(d_n)\n",
    "\n",
    "m_mean=d_m_d.mean()\n",
    "m_std=d_m_d.std()\n",
    "\n",
    "h_mean=d_h_d.mean()\n",
    "h_std=d_h_d.std()\n",
    "\n",
    "n_mean=d_n_d.mean()\n",
    "n_std=d_n_d.std()\n",
    "\n",
    "total_mean=d_total_d.mean()\n",
    "total_mean_d=pd.DataFrame(total_mean)\n",
    "total_std=d_total_d.std()\n",
    "total_std_d=pd.DataFrame(total_std)\n",
    "print(total_std_d)\n",
    "\n",
    "print(total_mean_d)\n",
    "\n",
    "#print(total_mean)\n",
    "#rint(total_std)\n",
    "#print(m_mean)\n",
    "#print(h_mean)\n",
    "#print(n_mean)\n",
    "\n",
    "#print(m_std)\n",
    "#print(h_std)\n",
    "#print(n_std)\n",
    "\n",
    "\n",
    "d_total_d=pd.DataFrame(d_total)\n",
    "\n",
    "\n",
    "ax=total_mean_d.plot.bar(yerr=total_std_d,rot=30,figsize=(10,8),color=(0,0,0,0),edgecolor='black',linewidth=3,error_kw=dict(lw=3,capsize=5,capthick=5))\n",
    "\n",
    "#ax.set_xticklabels(['Normal_city','Market','Highway'])\n",
    "ax.set_yticklabels(['0','20','40','60','80'],{'fontsize':19,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['NORMAL_CITY','HIGHWAY','MARKET'],{'fontsize':19,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Zone',fontsize=24,fontweight='bold')\n",
    "ax.set_ylabel('Mean Accuracy',fontsize=24,fontweight='bold')\n",
    "ax.get_legend().remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "d={'1':[60,56,87.73],'2':[75.55,81.51,62.4],'3':[85.09,91.7,64],'4':[68.7,87.78,58.33]}\n",
    "d_data=pd.DataFrame(d)\n",
    "d_1={'Timelevel_1':[60,56,87.73]}\n",
    "d_1_d=pd.DataFrame(d_1)\n",
    "\n",
    "d_2={'Timelevel_2':[75.55,81.51,62.4]}\n",
    "d_2_d=pd.DataFrame(d_2)\n",
    "\n",
    "\n",
    "d_3={'Timelevel_3':[85.09,91.7,64]}\n",
    "d_3_d=pd.DataFrame(d_3)\n",
    "d_4={'Timelevel_4':[68.7,87.78,58.33]}\n",
    "d_4_d=pd.DataFrame(d_4)\n",
    "d_acc={'Timelevel':[74,78,84,77]}\n",
    "d_acc_d=pd.DataFrame(d_acc)\n",
    "\n",
    "d_total=[[60,56,87.73],[75.55,81.51,62.4],[85.09,91.7,64],[68.7,87.78,58.33]]\n",
    "d_total=[[79.26,72.78,85.4,84.69],[83.97,75.89,82.81,70.31],[82.09,87.31,89.09,82.09]]\n",
    "d_total_d=pd.DataFrame(d_total)\n",
    "d_m=[88,82,91,87]\n",
    "d_m_d=pd.DataFrame(d_m)\n",
    "d_h=[56,63,64,59]\n",
    "d_h_d=pd.DataFrame(d_h)\n",
    "d_n=[60,76,88,69]\n",
    "d_n_d=pd.DataFrame(d_n)\n",
    "\n",
    "m_mean=d_m_d.mean()\n",
    "m_std=d_m_d.std()\n",
    "\n",
    "h_mean=d_h_d.mean()\n",
    "h_std=d_h_d.std()\n",
    "\n",
    "n_mean=d_n_d.mean()\n",
    "n_std=d_n_d.std()\n",
    "\n",
    "total_mean=d_total_d.mean()\n",
    "total_mean_d=pd.DataFrame(total_mean)\n",
    "total_std=d_total_d.std()\n",
    "total_std_d=pd.DataFrame(total_std)\n",
    "\n",
    "#print(total_mean)\n",
    "#rint(total_std)\n",
    "#print(m_mean)\n",
    "#print(h_mean)\n",
    "#print(n_mean)\n",
    "\n",
    "#print(m_std)\n",
    "#print(h_std)\n",
    "#print(n_std)\n",
    "\n",
    "\n",
    "d_total_d=pd.DataFrame(d_total)\n",
    "\n",
    "\n",
    "ax=total_mean_d.plot.bar(yerr=total_std_d,rot=30,figsize=(10,8),legend='none',color=(0,0,0,0),edgecolor='black',linewidth=3,error_kw=dict(lw=3,capsize=5,capthick=3))\n",
    "\n",
    "#ax.set_xticklabels(['1','2','3','4'])\n",
    "#ax.set(xlabel='TimeLevel',ylabel='Mean Accuracy')\n",
    "ax.set_yticklabels(['0','20','40','60','80'],{'fontsize':19,'fontweight':'bold'})\n",
    "ax.set_xticklabels(['morning','mid_day','evening','night'],{'fontsize':19,'fontweight':'bold'})\n",
    "#ax.set(xlabel='Zone',ylabel='Accuracy')\n",
    "ax.set_xlabel('Timelevel',fontsize=24,fontweight='bold')\n",
    "ax.set_ylabel('Mean Accuracy',fontsize=24,fontweight='bold')\n",
    "ax.get_legend().remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
